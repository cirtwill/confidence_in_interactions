\documentclass[12pt]{letter}

\usepackage[britdate]{LiU-letter}
\usepackage{times}
\usepackage{letterbib}
\usepackage{geometry}
\usepackage[round]{natbib}
\usepackage{graphicx}
\geometry{a4paper}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage[running]{lineno}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}

%\usepackage{natbib}
% \bibpunct[; ]{(}{)}{;}{a}{,}{;}

\newenvironment{refquote}{\bigskip \begin{it}}{\end{it}\smallskip}

\newenvironment{figure}{}


\begin{document}



\newpage

\setcounter{page}{1}


Changes: reducing discussion of different sources of uncertainty, increasing description of priors, added a bunch of refs, trying to frame our study more clearly.

Still to do: framing, expand discussion of network metrics from sampled vs. predicted vs. expert knowledge networks... (ours reflect about 50\% of links observed, doesn't seem super out of line). Make clearer that we are modelling L but could also model X|L with independent $n$ and $k$ data within a single site. Maybe in the section introducing the model or introducing the case study?

Ask for help: how would we expand this to interaction frequencies? Still with the Bernoulli? Worthwhile to add a demo of Jensen's inequality?
% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
{\Large \bf Reply to Associate Editor}
% ---------------------------------------


	\begin{refquote}
	Your manuscript has been assessed by four different referees who agree that you touch upon a very important problem. However, they all feel your manuscript needs substantial improvements. They provide excellent advise on how to revise your manuscript and you should carefully consider all their comments. Overall, you do not acknowledge important past contributions and do not clearly explain the importance of the methodological issues you cover in your study. Importantly, referee 1 feels the real novelty of your study is the consideration of the importance and complexity of choosing prior information in constructing networks. Obviously, this is an issue in the context of Bayesian approaches, which are not necessarily well understood by empiricists, precisely the audience your manuscript should address. Please, follow very closely the suggestions of the referees when revising your manuscript.

	\end{refquote}

	\textbf{R:} We appreciate the thoughtful feedback by the four referees. We take particular note of the comments regarding the structure and grounding of our introduction and have worked to address this. Reviewer 2's comments take a different view of the purpose and scope of the manuscript than the other reviewers; we respect their ideas but feel that some are beyond the scope of the present manuscript. In particular, we do not feel that a full simulation study is necessary given the simplicity of our framework. We emphasize that we are not introducing a software package (although we do provide simple code to aid those who are new to the field), nor are we introducing an entirely new framework (as the other Reviewers point out, many components of our approach have been touched on by previous work). The novelty and impact of our work lies in connecting a Bayesian statistical approach to the problem of limited and uneven sampling (driven by difference in species abundances, detectabilities, constrained time and budgets, etc.) and, we hope, in making this method more accessable to those without extensive statistical or modelling experience. Because of the difference between Reviewer 2 and the other Reviewers, we have opted to prioritise the majority view and focused first on comments by Reviewers 1, 3, and 4. We hope that, in the course of these revisions, we have at least partially adressed Reviewer 2's concertns as well. 

\newpage


% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Reviewer \#1}
% ---------------------------------------

	1. Suggestion to refocus on prior selection [[not done]]

		\begin{refquote}
			Below I offer my thoughts on this well-written manuscript. Normally I condense my review into a few key points, but I found myself uncharacteristically divided with the paper as presented. At first, the introduction covers ground very well-trod by prior works and doesn’t really address its contribution. I was mostly frustrated by the rehashing of topics made by many previous papers, include many by the authors themselves. But then the paper seems to morph and pick up steam on L248. Rather than reaching towards an amorphous and grandiose “quantitative framework”, the authors briefly zoom into a very concise, and hugely important, question of choosing prior distributions for harnessing information among networks. This has been completely unexplored and merits attention. In ecology more broadly, priors are treated with timidity, as if we couldn’t dare to leverage past work on our current understanding. Personally, I have always felt limited by this standard. I applaud the authors for taking on this challenge, and I would like to see an introduction that merits and debates this question in much more detail. When should we use prior information? How do we go about constructing informed priors for networks? When can we use priors from the data in question? This is sometimes called approximate bayes (http://andrewgelman.com/2016/03/25/28321/), or empirical bayes, perhaps alluded to in the title, but not fully explained in the introduction. Should empirical priors be drawn from hyperpriors or fixed for each interaction? Can we combine qualitative information and quantitative information? This is all exciting ground that will open up new avenues for networks. Walking the reader through flat priors, informed priors and empirical priors is crucial for the importance of analysis to be understood by the reader. The use of empirical priors can be quite controversial, and should be atleast touched on in the discussion. \\
			I’ve left my comments below on the introduction, but in my opinion, it should be almost wholly rewritten in favor of a more targeted question constructing networks using priors, which is the key novelty of the work and is mostly hidden by the current introduction. I’m not convinced any new analysis needs to be done, which speaks to the conflict between the current introduction and the actual data presented. I see the makings of a really nice paper here, and I’m confident the authors will be able to achieve this text revision.
			\medskip
			At the same time, the paper is clear and very readable. I wholly support the method and I think it is something critical that needs to be adopted by the community. \\
			Having read the paper several times, I think that the authors are trying to cast their net too widely, even starting from the title. From that perspective, they don’t meet the expectation of new insight. However!! I was extremely interested in the brief discussion on using prior knowledge, especially the delicacy of trying to transfer information among networks (L248). My recommendation is to drastically reduce the grandiose attempt at a “quantitative framework for networks” (L1 – L246) and really zoom in on the contribution of transferring information among networks through informed priors.	Again L278, this is very well covered in concept by recent papers in MEE that include the authors of this work, as well as several by Weinstein, Bartomeus and others.
			\end{refquote}


		\textbf{R:} We thank the Reviewer for the suggestion to expand our discussion of prior selection, particularly with regard to approxmimate/empirical bayes. [[Expand refs to this]] We now walk through flat, informed, and empirical priors as suggested (lines XX-XX) and refer to the controversy surrounding empirical priors in our discussion (lines XX-XX).\\
			We also appreciate the Reviewer's comments on our introduction. We feel that understanding the problem of uncertain detection of interactions is important motivation for a reader not already familiar with Bayesian procedures to wade through a larger discussion on priors. Therefore we have revised and, hopefully, streamlined our discussion but do not jump straight in to priors. We have, however, taken care to introduce our analysis as a worked example (lines XX-XX) and hope that this helps to reduce the conflict between the introduction and our data. [[Add something else about different priors? Add different priors to our analyses?]]
			[[Definitely should expand this, but do we want to really focus on those?]][[not quite done]]

			We thank the Reviewer for their compliments and accept their suggestion that we are somewhat overexcited about our approach. We have refined the introduction to be more specific about the problem we are attempting to solve. We have also expanded our treatment of prior selection and hope that our paper now reads as achieving its goal.


	2. Suggestion to add more literature [[done]]

		\begin{refquote}
		The introduction flows well and is thoughtfully laid out. Given the enormous amount of literature in the field, it is not possible to provide a full set of citations. However, it seems remiss to not consider Jordano (2016) in the sampling section.
		\end{refquote}

		\textbf{R:} We thank the Reviewer for their compliments to our introduction and for the recommendation of Jordano 2016. We have incorporated this reference as suggested. Following comments from other reviewers, we have refined and slightly restructured our introduction in the hope of more clearly establishing the goal of our manuscript ('narrowing our net'). We hope that this revised introduction will also meet with the Reviewer's approval. [[done]]


	3. Suggestion to de-emphasize MLE estimate and get straight to Bayes [[done]]

		\begin{refquote}
		It’s a bit confusing to lead the reader towards a Bayesian analysis, and then immediately start with the MLE estimate. Why is this needed at all? (L162-186). Just start at 187?
		\end{refquote}

		\textbf{R:} The section on the MLE estimate was designed to illustrate the large sample sizes needed in the absence of a Bayesian framework. Upon reflection, we see have moved this demonstration to a box dealing specifically with sampling. We now begin with the Bayesian beta distribution as suggested. [[I think done?]]


	4. Suggestion to remove moments of the beta distribution [[done]]

		\begin{refquote}
		I think a bit of space is wasted on defining the moments of the beta distribution. This is very googleable, and almost too thorough. I think the space is better utilized aligning the ecological challenge and the quantitative method.
		\end{refquote}

		\textbf{R:} While we feel that a short introduction to the beta distribution is important to bring researchers new to Bayesian statistics up to speed (and give them some keywords to Google), we accept the Reviewer's suggestion to reduce the amount of space given to the beta. We have therefore moved the description of basic properties to Appendix S2. The remaining paragraph introducing the beta distribution now leads directly into the section describing prior selection.


	5. Novelty of the study not clear in current framing [[done]]

		\begin{refquote}
		I’m wrestling with the novelty of the work as presented and whether it reaches the standard for publication at MEE. Certainly, much of this logic is laid out in other works. The authors are well aware of this and have made significant contributions to this topic in the last few years. In particular, the authors should try to be much more explicit about the contribution they hope to offer that hasn’t been covered. ...
		While it is true that none of the [suggested] papers do the exact same thing as this manuscript, they all	orbit the same topic. 
		\end{refquote}


		\textbf{R:} We thank the Reviewer for the literature suggestions and now include them in our introduction and/or discussion. We emphasize the board applicability of our approach across network types and systems with varying degrees of prior knowledge. We also emphasize that our approach is not restricted to species observed X times (as many predictive models are) and can include species not yet observed at a site (e.g., potential invaders). We hope that the contribution our manuscript makes is now clearer.


	6. Potential contradiction [[done]]

		\begin{refquote}
		L89 for example, seems to conflict with the two paragraphs immediately following it?
		\end{refquote}


		\textbf{R:} We have now address questions relating to sampling in a dedicated box. We hope that the revisions make our stance on repeated sampling clearer and that there are no longer apparent contradictions.


	% 	Literature suggestions:
		% Jordano, P. (2016). Sampling networks of ecological interactions. Functional Ecology, 30(12), 1883–1893. doi:10.1111/1365-2435.12763
		% Bartomeus, I. (2013). Understanding Linkage Rules in Plant-Pollinator Networks by Using Hierarchical Models That Incorporate Pollinator Detectability and Plant Traits. PLoS ONE, 8(7), 1–9. doi:10.1371/journal.pone.0069200
		% Poisot, T., Cirtwill, A. R., Cazelles, K., Gravel, D., Fortin, M.-J., & Stouffer, D. B. (2016). The structure of probabilistic networks. Methods in Ecology and Evolution, 7(3), 303–312. doi:10.1111/2041-210X.12468
		% Poisot, T., Stouffer, D. B., & Gravel, D. (2015). Beyond species: why ecological interaction networks vary through space and time. Oikos, 124(3), 243–251. doi:10.1111/oik.01719
		% Graham, C. H., & Weinstein, B. G. (2018). Towards a predictive model of species interaction beta diversity. Ecology Letters. doi:10.1111/ele.13084
		% Gravel, D., Poisot, T., Albouy, C., Velez, L., & Mouillot, D. (2013). Inferring food web structure from predator-prey body size relationships. Methods in Ecology and Evolution, 4(11), 1083–1090. doi:10.1111/2041-210X.12103
		% Wells, K., & O’Hara, R. B. (2013). Species interactions: Estimating per-individual interaction strength and covariates before simplifying data into per-species ecological networks. Methods in Ecology and Evolution, 4(1), 1–8. doi:10.1111/j.2041-210x.2012.00249.x


% ----------------------------------------------------------------------
% ---------------------------------------------------------------------
{\Large \bf Reply to Referee \#2}
% ---------------------------------------

	I do not know what to do with this.

	\begin{refquote}
	The paper by A.Cirtwill and colleagues tackles a very interesting problem, quantifying the uncertainity of interactions, using three levels of nested uncertainity. The authors proposed a bayesian framework to obtain estimate of the parameters of the model and show the results of their approach on a recent dataset. The question of disentangling the true presence/absence of an interaction given a series of observations (replicates) is of primary interest and, seen in this light, the paper is tackling one of the hottest topics in the field.

	The introduction is particularly pleasant to read and the problematic is well stated. However, the paper has also a number of weaknesses that I enumerate in the following :

	1/ lack of references: the fundamental question about predicting interactions given some incertainity has been and is debated in many papers (see the seminal paper by Roger Guimerà and Marta Sales-Pardo, PNAS, 2009). Even if the proposed framework is probably not stated in its exact terms in the literature, bridges between existing approaches (beyond Ecology) and the one in the paper would be very welcomed. An appropriate discussion between points of convergence and difference would help the reader to appreciate the significance and the impact of the proposed methodology.

	2/ network oversight: the approach considers that the interactions are independent, which is not the case in real data. Indeed, the paper is supposed to be “network-oriented“ but the methodology deals with independent interactions (e.g. the variables L,T,X and D introduced lines 62,77,101 are for instance not indexed by ij which could have suggested that the interactions were seen as a whole). Consequently, the mathematical framework remains quite simple and may not reflect nor model the processes governing the actual detection of interactions. Despite of this drawback, the proposed method is interesting but at least the authors should add some discussion on the limits of dealing with independent interactions,

	3/ identifiability: the reader would appreciate that the authors discuss and prove the identifiability of the model. Indeed, the three levels of uncertainity are nested but one could wonder whether different parameters at the three levels can fit the same data with the same quality (i.e. no identifiability).  I would suggest this point to be addressed in a specific section.

	4/ absence of simulations: the authors proposed an original approach based on a bayesian framework. Beyond the identifiability question (see above), the reader can question the power of the method. Usually, a methodological proposal comes with a complete simulation study that is supposed to show  the proposed model is adapted/suitable to the question and efficient to solve it. In the paper in its present form, the authors assume that the reader will be convinced by the results obtained on a single real dataset… In my opinion, the reader can’t be fairly convinced: how powerfull is the method? what can we say about the priors? how much data (n, k) is necessary to expect good results? An so on… Only a well-conducted simulation study can answer these questions.

	5/ results&discussion too short: the reader is surprised to read 27 lines of raw results only… Given the amount of new methodology that is proposed, one can expect a complete description of its pros and cons. Obvisouly, a simulation study (see above) would enrich the results part. Forgetting about the length of these parts, it is still difficult to catch the key messages from the text, and it is not obvious to relate discussion and the obtained results (for instance,from l.343 to l.351).

	6/ lack of rigorous notations: it is possible to understand the approach with the present notations but some improvements can help the reader because there are a series of inconsistencies. Here are some suggestions. The authors chose upper case letters L,T ,X,D for single entities whereas the mathematician is used to expect matrices or constants in upper case. Traditionaly, given species i and j, we would consider interaction L_ij, feasibility X_ij, detectionability D_ij...
	Still, what is T?? not defined, never reused: is it a characteristics on i, on j, on both?
	How can be D<1 on l.169? D=0 or 1 since it says if an interaction is detectable or not...
	Moreover, L is reused later but is the number of interactions (l.100 supp.mat)…
	What is “N” in Figure 4? is it “n”? What is n_ij and k_ij l.266? Never defined, never reused.
	In the beginning of the paper, \lambda is a probability (l.62) but it becomes a random variable (l.164): it would be more consistent to introduce before the notion of hyperparameters  (l.209-213) and to explain we consider that \lambda is drawn into its distribution.

	\end{refquote}

	Minor points:

	-l.62: define formally T
	-l.244: this is weird to mention that the analysis has been done on another dataset but that the results will not be discussed… What is the interest for the reader?
	-l.149: since the authors consider the interactions are independent, there is morally no network in the approach (except the result)
	-l.252: not clear. Why this choice?
	-l.259: not clear
	-l.278: the authors investigate the consequence of uncertainity on network metrics. This question is of peculiar interest, but here it is restricted to the connectance and nestedness. Why these two metrics? Why not others? What is the impact of integrating incertainity into the metrics computation? (we guess the answers but we could expect the authors develop these points).
	l.291: explain better the simulation procedure
	l.306: given the shape of the distribution (exponential), the mean is not an appropriate indicator.
	l.327: what does it mean? How is it possible?


% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#3}
% ---------------------------------------

	\begin{refquote}
		Comments to the Corresponding Author
		Overall, I think this is a very good paper and makes an important contribution.  I think there are three main ways it can be improved: 1.      The simplest – do a better job of acknowledging what else has been done in the field – much of which has actually been done by the authors and their collaborators. ... 2.      Provide more clarity in descriptions making sure to consider how terms and ideas have been used previously. ... 3.      The set up (introduction) to the case study is quite odd and somehow seems off topic – or at least not logical based on what the reader has read up to that point.
		I hope this review is helpful.  


		More generally, the introduction does not really do justice to what has been done already – even the authors own work.  The problem in my view is that the community using better statistics – of which the authors are very important members – has not managed to communicate to most people studying networks and better methods are simply not being adopted.  The current paper is a very nice attempt to show the broader community that the Bayesian approach is not so complex and has many advantages.  I think this is a very important message and is what makes this paper an important contribution.  Further, the approach to parse out different types of uncertainty and suggestions for how to come-up with informative priors – is very useful.  The theory/method is well developed overall and provides an example – which is great.

		\end{refquote}

		\textbf{R:} We than the Reviewer for their literature suggestions and for demonstrating that our desire not to criticise hard-working empiricists could be misinterpreted as suggesting reduced sampling effort. We had not realised that anyone would consider such a possibility and have revised our manuscript to make it clearer that our approach is a complement to extensive sampling, not an excuse for poor sampling. 


	1. Add more references to the literature [[done]]

		\begin{refquote}
		1.      The simplest – do a better job of acknowledging what else has been done in the field – much of which has actually been done by the authors and their collaborators.  Given that they know there work I won’t point that out (but they are under-siting this literature a bit) but they could consider Graham and Weinstein on-line early 2018 (I realize that this was just out when the author’s submitted but it has some very similar messages) and the empirical example of Weinstein and Graham in Ecology letters 2017.  I don’t think this would in any way diminish the importance of the current paper because I think the challenge in network ecology is to get people to use better quantitative methods.
		\end{refquote}

		\textbf{R:} We had not intended to write a review paper and did not wish to over-cite ourselves, but we take the Reviewer's point and have expanded our references to the literature. We have taken particular care to add references to Graham/Weinsten papers as two of the reviewers suggested work by these authors. We hope that the introduction now presents a more thorough sample of previous work.

		\begin{refquote}
		Line 7.  It is certainly true that most networks are snapshots in time but there is a growing realization – including some nice examples (including those by the authors) that address this issue.  Maybe what you want to say is that we know that networks should not be considered static but we lack the tools – or ability to collect data – or whatever you think is the cause – to correct this situation. 
		\end{refquote}

		\textbf{R:} We have softened this statement to say that empirical networks are "often limited" and hope that this rephrasing will not offend those who are working to include variation in their descriptions.

			\begin{quotation}
				Despite this additional information, empirical descriptions of ecological networks are still often limited by a lack of data or tools to adequately incorporate variation in interactions into networks.
			\end{quotation}


		\begin{refquote}
		Line 30.  There are several conceptual and empirical attempts to consider detection probability – why aren’t these cited (work by Bartomeus comes to mind).\\
		\end{refquote}

			\textbf{R:} We have added a citation to Bartomeus as requested.

		\begin{refquote}
			Line 36.  I certainly see value in the approach and the general ideas of these authors in particular but they should acknowledge the work that has been done by themselves and others!\\
		\end{refquote}

		\textbf{R:} We have rephrased the end of this paragraph to mention previous predictive models dealing with uncertainty in interaction matrices.

		\begin{refquote}
		Line 89.  In Weinstein and Graham (Ecology Letters) the processes modeled were trait matching (which you place in interaction uncertainty) and abundance (which is perhaps your process uncertainty??).  I find myself quite confused based on how you describe things in this MS (See text above) and how you cite the literature.
		\end{refquote}

		\textbf{R:} We have revised this section and now no longer refer to the specifics of Weinstein and Graham at all. Instead, we discuss repeated sampling in a box dedicated to the question of whether sampling is useful (of course it is) and whether it can completely solve problems of uncertainty in ecological networks (almost certinaly not). We hope that this is less confusing.

		\begin{refquote}
		Line 148.  Please note that a paper with a very similar aim was recently published (Graham and Weinstein).  This does not to diminish the value of this study in any way, as multiple perspectives on quantitative solutions in network ecology are urgently needed….. but the other work should be considered. 
		\end{refquote}

		\textbf{R:} We had not seen the Graham and Weinstein paper when we first submitted our manuscript, but now cite it in the introduction. We have also revised this section in hopes of making the uniqueness of our framework (its simplicity and adaptability) clear. 

		\begin{refquote}
		Line 288.  I am pretty sure this idea is in the literature several times and should be cited.  Isn’t this the same as drawing a probability of interaction from a distribution where the distribution of each interaction is an output of the Bayesian method?\\
		\end{refquote}

		\textbf{R:} Yes, that is exactly the idea. We are also sure that this is a common approach and therefore hadn't cited it (in the same way one would not be likely to cite the prior users of common statistical tests). We have added a citation to~\citet{Vazquez2005,Guimera2009} as two examples and hope that this is sufficient.

		\begin{refquote}
		Line 352 – 358.  Citations are needed in this section as this has been suggested before.
		\end{refquote}

		\textbf{R:} Most of these lines refer specifically to our results, making it somewhat difficult to add citations. We have added citations where possible and rephrased this section to make it clearer when we are referring to work done in the present manuscript.


	2. Confusing terminology [[done]]

		\begin{refquote}
		2.      Provide more clarity in descriptions making sure to consider how terms and ideas have been used previously.  Two things come to mind – the use of terms and distinction between interaction and process uncertainty; and the somewhat contradictory sounding statements about if sampling more is actually good.
		\medskip
		Line 86.  So, similar factors (i.e., trait matching) can be used to detect different kinds of uncertainty.  Should this be stated?  You might also consider a different word that process as “observation models” and “process models” are commonly used terms in Bayesian stats and in this case “process” often considers what you call “interaction”.  There are some interesting to attempts to model co-evolution that consider similar ideas (i.e., a barrier to interaction and then trait-matching; but maybe outside of the scope of this MS). While I appreciate that your naming has merit, I think if your hope is that more ecologists use these methods then the terminology should be consistent across papers/approaches to the greatest extent possible.
		\end{refquote}


		\textbf{R:} We have revised this section of the introduction to both avoid introducing rigid terminology and make it clear that our model is not concerned with partitioning different sources of variation (indeed, we state that in many cases this is not possible using empirical data). Hopefully this will discourage readers from getting bogged down in trying to isolate which external factors cause which types of uncertainty (there is almost certainly overlap - e.g., bad weather could both reduce the probability that species will be active and interact and the probability that an interaction is observed if visibility is poor). We have also added a section (lines XX-XX) referring to "forbidden links" which address aspects of whether species can interact (which we had previously called interaction uncertainty) and whether they do interact at a particular site (previously process uncertainty). We hope that this addition clarifies the agreement of our manuscript with previous works listing sources of uncertainty.

			\begin{quotation}

        \textbf{Forbidden links}

            Both of the above sources of uncertainty (i.e., whether species would be able to interact given their traits and whether they are able to interact at a particular place and time) are addressed in the concept of "forbidden links"~\citep{Jordano2016}. In this framework, all links which are prevented by spatio-temporal uncoupling~\citep{Jordano1987}, physiological constraints~\citep{Jordano1987,More2012}, etc. are considered "structural zeros" that cannot be observed~\citep{Jordano2016}. We conceptually distinguish between physiological constraints and spatio-temporal uncoupling to allow for cases in which a species is introduced to a new habitat, expands its range, or shifts phenology~\citep{Gravel2013}. In such cases, links which are forbidden due to physiological constraints remain forbidden but links previously forbidden due to spatio-temporal mismatch could potentially occur. 

      \end{quotation}


	3. Introduction of the case study seems off-topic and illogical. [[done]]

		\begin{refquote}
		3.      The set up (introduction) to the case study is quite odd and somehow seems off topic – or at least not logical based on what the reader has read up to that point.
		\medskip
		Line 240.  I found the justification for the system a bit odd.  Is the goal to show the gaps in sampling or to apply the model described thus far to consider the 3 different types of uncertainty outlined?  At this point the reader is confused about the goal…
		\medskip
		Line 249.  The statement about training data is redundant with what is stated above – adjust writing.
		\end{refquote}

		\textbf{R:} We have expanded our introduction of the case study (lines XX-XX) to make it clear that we are using the highest-quality empirical network we can find as even such networks have uncertainty about unobserved interactions. This relates back to our point that urging increased sampling effort is not likely to solve problems of uncertainty as long as sampling is limited in number of methodologies, biased towards abundant or easy-to-identify species, restricted to particular spatial sites and/or environmental conditions (if the network is intended to be more general), or all of the above. We repeat this point in the discussion to ensure that the case study is relevant. We have also clarified our statement that strict Bayes does not allow empirical priors, but that they are an option for researchers that are more concerned about matching their prior to their study system than with strict formalism (lines XX-XX). As Reviewer 1 points out, this is somewhat controversial and we feel it is important to note the potential objection.

		\begin{quotation}

 			To illustrate the process of constructing a Bayesian network to quantify uncertainty about interactions, we use the comprehensively-sampled system of willows (\emph{Salix}), herbivorous gallers, and their natural enemies described by~\citet{Kopelke2017}. This dataset consists of a single community type sampled across Europe over 29 years and at 374 unique locations. The meta-network consists of 1,173 different interactions between 52 \emph{Salix} nodes, 92 herbivore nodes, and 126 natural enemy nodes (see \emph{Appendix S4} for details). 
      The high spatiotemporal resolution of this dataset make it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, we anticipate that there will be many pairs of species which were rarely or never observed together. To show the gaps in sampling, we compared the frequencies of observed co-occurrences and interactions. We then calculated an empirical prior and computed the posterior distribution of the probability of observing each as-yet-unobserved interaction in the future.
      \medskip
			While a strict Bayesian framework requires a prior distribution that does not rely on any information from the study at hand, such data are not always available. In that case, researchers must choose between using a less-informative prior (e.g., one based on distributions of links across a large set of networks) or an empirical prior based on some "training data" from the study. 
		\end{quotation}


	4. Misunderstanding of our point about sampling effort [[maybe done? in progress]]

		\textbf{R:} We believe that the Reviewer has badly misunderstood the point of our comments on sampling effort. Several of their comments suggest that we are advocating for reducing sampling effort. This is emphatically not the case. Rather, we assumed that field researchers already sample to the maximum extent possible given their time and resource constraints and so a call to "sample more" would not be helpful. We now address this assumption explicitly in a box dedicated to the potential for sampling effort to reduce uncertainty about interactions. Below, we address the Reviewer's sampling-related comments one by one.


		\begin{refquote}
		Line 94.  I find this a very odd argument against sampling multiple times.  So, if you sample more you might see more then understand the system less?  The logic does not make sense to me. 
		\end{refquote}

		\textbf{R:} Of course sampling more does not lead to less understanding. It can, however, reveal knowledge gaps (as when a rare species is detected, revealing our ignorance of its interactions). This is not an argument against multiple sampling but a statement that increased sampling is likely to lead to the addition of more "false zeros" as species about which we know little are added to the network.

		\begin{refquote}
		Line 107.  There is a lot of literature in wildlife ecology emphasizing the importance of repeat sampling for estimating detection probability.  Is this just wrong?  If so this does need more explanation in the context of this literature.
		\end{refquote}

		\textbf{R:} I do not know how the Reviewer assumes that we are against repeat sampling when this is, in fact, one of the core parts of our approach. Our point here is that some species (e.g., cryptic or difficult-to-identify species) and interactions (e.g., brief visits of pollinators to plants) are difficult to detect and may be missed even with multiple sampling. If a rare species is only detected in one sampling round, then the repeated sampling necessarily tells us little about its interactions. For species which are frequently detected, we absolutely learn about the detection probability of their interactions with repeated sampling.

		\begin{refquote}
		Line 130.  The ideas here are largely a repeat from those above.  Further, while it may be true that we can sample too much – I think it is dangerous to suggest we should sample less – do the authors think that sampling across most network studies is sufficient (the opposite is stated in the discussion)?  I wonder if the argument is a bit more statistical than biological.
		\end{refquote}

		\textbf{R:} We agree that it is dangerous to suggest that anyone sample less, that is why we have not done so. We argue only that the amount of sampling required to be confident that co-occurring species do not interact is large -- likely beyond what is feasible for speciose systems given the limited resources available to many researchers. Sampling across most network studies is almost certainly not sufficient, but data which would allow readers to judge this (i.e., number of times each species is observed, independent of numbers of observed interactions) is not generally provided. We chose to be more charitable than the Reviewer and assume that those compiling empirical networks are sampling as much as possible given the constraints of their system and available resources. Infinite sampling would, of course, be the best option but it is unlikely that researchers will be able to perpetually increase sampling.

		\begin{refquote}
		Line 144.  I am much more comfortable with this statement than how sampling effort should be considered and I would suggest moving this up and then explaining how even if we sample well we need to consider uncertainty for the reasons you mention in the previous section.  Please note that you make the same point in your discussion on line 338.
		\end{refquote}


		\begin{refquote}
		Line 319.  It is clear that these are large samples but if interaction among co-occurring species was greater than you need lower samples – correct?  Should this be made clear?  Otherwise, we maybe can just never get enough data!
		\end{refquote}

		\begin{refquote}
		Line 338 to 342.  Throughout I am confused if the authors suggest more sampling is good or bad…  At the end of the paragraph it seems it isn’t so great to sample more because you end up with these annoying “0” values…??????
		\end{refquote}


	5. Eliminate redundant "because" on line 23 [[done]]

		\textbf{R:} Done.


	6. Reduce repetition of inevitable uncertainty [[done]]

		\begin{refquote}
		Line 73, 87.  Maybe the idea that some uncertainty is “inevitable” should not be repeated in multiple sections.  Either find a different way of saying it – or state it in your introductory paragraph and then don’t keep repeating.
		\end{refquote}

		\textbf{R:} We have rephrased the paragraph about detection uncertainty. The last line now reads:
			
			\begin{quotation}

				Until these gaps are filled, some interaction uncertainty will remain.

			\end{quotation}


	7. Why not always model probabilities of co-occurrence? [[done]]

		\begin{refquote}
		Line 142.  But shouldn’t you model the probability of two species co-occurring?  The authors have a paper doing this…. Is that not a good idea?
		\end{refquote}

		\textbf{R:} Of course modelling the probability of co-occurrence is an option for many systems (e.g., aquatic food webs where ranges of fish species are fairly well-known, as in~\citet{Gravel2013}). In some systems, however, the factors affecting probabilities of co-occurrence may not be known. We therefore cannot suggest modelling co-occurrence as a panacea. Instead, we now emphasize that co-occurrence probabilities are one thing that could be included in a prior (lines XX-XX - section Informative priors). 
		\smallskip
		The fact remains that a lack of observed interactions between species which do not co-occur tells us nothing about whether these species \emph{could} interact if they should begin to co-occur (e.g., following a range shift). Following the Revewier's suggestion, we have revised our manuscript to clarify our technology. In particular, we have taken care to specify which level of uncertainty we are addressing at different points in the manuscript. We hope that this will remove some of the confusion about whether or not modelling different components of uncertainty/sampling more is a good idea. 


	8. Issue of testing hypotheses based on inputs into models [[done]]

		\begin{refquote}
		Line 121.  I think one of the reason non-Bayesians’ are not comfortable with the approach is that if you put in prior information on something like trait matching and test for trait matching and then discover trait matching is important – what does it mean?  Maybe this is too obvious (I realize there are tons of papers on how to choose priors) but I wonder if it is worth explaining (would a box or something be worthwhile?  I leave it up to the authors/editor)?  Maybe the issue could be acknowledged and an appropriate paper cited?
		\end{refquote}

		\textbf{R:} Following suggestions by this Reviewer and another, we have substantially expanded our discussion of different options for priors (including the trait-based and co-occurrence models the Reviewer points out). It seems fairly obvious that discovering that trait-matching is important in a model framework which relies of trait-matching as a starting assumption does not mean very much... but we also recognize that researchers unfamiliar with Bayesian approaches might prioritize reducing uncertainty and therefore include all available information even when it conflicts with the study question. We have therefore added an explicit statement that researchers wishing to test the influence of a particular trait (for example) should \emph{not} include that trait in their prior (lines XX-XX). We hope that this statement, and the expanded discussion of different types of priors more generally, allay the Reviewer's concerns. 

		\begin{quotation}
			Similarly, if detailed information is available but refers to the question at hand, it is best to use a less informative prior so as not to force a particular result. For example, if researchers are interested in testing whether body-size ratios affect probabilities of interaction they should not use a prior which predicts interactions based on body sizes.
		\end{quotation}


	9. Redundancy in line 235 [[done]]

		\textbf{R:} The redundant line has been removed. Thank you for pointing this out.


	10. Unsure about the point of filtering networks [[done]]

		\begin{refquote}
		Line 295 to 302.  I would think that this second step (i.e., filtered networks) is to explore sampling not to determine how networks will be influenced by uncertainty?  Do you need the filtering step to evaluate uncertainty (as written it seems that this is the case)?
		\end{refquote}

		\textbf{R:} The filtering was intended to show how uncertainty likely warps our current understanding of network properties like connectance. If we do not observe 20-50\% of the interactions in a network, then many network properties in the published literature will be inaccurate. Even worse, networks compiled under different levels of uncertainty (e.g., species with more or less variable traits, or studies with multiple sampling methods or only one) or with different sampling efforts will have network structure metrics that are inaccurate to different degrees. Filtering networks in the way that we do could give an idea of how many networks are missing, but we do not think it is necessary to evaluate uncertainty (we believe that examining the posterior distributions directly is a better approach there). We have rephrased these lines (XX-XX) to emphasize that the filtered networks are intended to demonstrate the consequences of uncertainty more than anything else.

		\begin{quotation}
			Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. 
		\end{quotation}


	11. Skepticism about sampling requirements to be sure interactions do not occur [[done]]

		\begin{refquote}
		Line 361.  I find the statement that 30-50 individuals need to be evaluated a bit strong.  This statement is based on this study – are all systems like the gall system?  If species are specialized or bound to interact for some other reason (i.e., co-occurring when there are few other resources) wouldn’t you need to observe fewer individuals?  The point of the method is that you can estimate how many individuals are needed…. This is great!  But given that this can be estimated from any given system why give a value from one system and state that is what is required?  It defeats the point of the very nice method proposed…??
		\end{refquote}

		\textbf{R:} The point of our method is not actually to quantify the amount of sampling needed. Although the ideal sampling effort \emph{can} be calculated using the framework we put forward (as we demonstrate), the real point is to quantify how uncertain we are that an interaction we do not observe really does not occur. Given this, we do not think that recommending uncertainty be explicitly stated undermines our point at all. 
		\smallskip
		The Reviewer's suggestion that we might need fewer samples for species that are "specialized or bound to interact for some other reason" reflects a very strong prior. In this case, yes we would need fewer samples for the species concerned. With sufficiently strong priors, it is not necessary to sample at all! For example, in most food webs it is assumed that basal resources will never consume prey even if a given resource and a given animal are never observed co-occurring and it is generally accepted that there is very low uncertainty about these zeros. In many cases, the assumptions involved in excluding interactions are less clear-cut and different researchers may disagree about which species are "bound to interact" (or not to interact). The concept of pollination syndromes is one example - many flower visitors are less rigidly specialized on particular flower types than initially thought~\citep{}. To address such "forbidden links", we now suggest that researchers explicitly state both the uncertainty about data-based zeros and the assumptions by which they create structural zeros. This will allow future researchers to evaluate the uncertainty about all interactions in a network as the state of expert knowledge changes. We hope that this expanded recommendation (lines XX-XX) is clearer.


		\begin{quotation}

			Second, researchers should acknowledge the varying levels of confidence surrounding interactions between species pairs. In the absence of strong prior information a very high level of sampling (i.e., 30-50 observations in our example) is needed \emph{for each species pair}. This is not likely to be possible for most studies. including the $n$ and $k$ values for each interaction will clearly indicate which unobserved interactions are most likely to be observed with further sampling and which estimates are more reliable. Where there are strong prior expectations about pairs of species that will not interact, these should be explicitly stated so that readers know which zeros in an interaction matrix are based on observed data and which are based primarily upon expert knowledge.

		\end{quotation}


\newpage

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#4}
% ---------------------------------------

	\begin{refquote}
		Comments to the Corresponding Author
		I have been surprised how little that sampling effects have been formally considered in the analysis of networks, so I welcome this contribution that provides a theoretical framework. Overall, I felt that this contribution was really helpful, and that it provides both a theoretical framework and a practical example.

		Overall, I fear that this review is rather meandering, but I think that reflects some of the challenges I have with the paper. Currently I do not think the paper would be used by empirical network ecologists because they either would not understand its relevance or would not be able to apply it practically. This would be a great shame. I hope that the comments are clear enough to allow the authors to improve the paper – the paper has the potential to be important and very useful.
		\end{refquote}

		\textbf{R:} As we did not intend to write a review, we understand the Reviewer's complaint. This shows that we did not clearly establish the purpose of our manuscript, and we hope that our revision corrects this. In particular, we hope that we have established the relevance of our method and offered enough of an explanation that empiricists will be able to apply it. Our goal is to increase access to a statistical technique which we see as complementary to high-quality field work, and we believe that the Reviewer's comments will help us to achieve this.


	1. Paper is poorly structured [[not done]]

		\begin{refquote}
		However, I felt that the structuring of the paper made it a challenge to understand and apply. It felt like the paper itself had been written in different sections (by different authors?) with not enough links between the sections. I also felt that there was a strong theoretical component, which is important, but there needed to be a stronger link with the issues around empirical ecology, as explained below.
		\end{refquote}

		\textbf{R:}


	2. Add more citations [[done]]

		\begin{refquote}
		Introduction – T. Poisot and colleagues have done a lot of relevant work in this area, but I felt there was undue reference to their work in comparison with other relevant work. There were some obvious papers (e.g. sampling by Jordano, forbidden links by various others) that were not cited. A broader perspective on the literature would, I think, help the authors appreciate the value of their paper and the need to ensure that it is fully understandable and of practical use.
		\end{refquote}

		\textbf{R:} We have cited addition literature as recommended by Reviewer 1, including a paper by Jordano. If the Reviewer has any suggestions of specific papers that they feel are missing, we would be happy to consider them as well. Note, however, that we do not intend our manuscript to be a complete review of the literature surrounding interaction probabilities. We hope that the citations we have added appear more balanced to the Reviewer.


	3. Comment on weighted metrics [[done]]

		\begin{refquote}
		L36ff The authors should note the value of weighted metrics in taking account of sampling biases.
		\end{refquote}

		\textbf{R:} We do not see how weighted metrics (which we infer mean metrics including interaction strength/frequencies based on the Reviewer's comment below) account for sampling biases. It seems to us that measures of interaction strength should be \emph{more} susceptible to sampling biases, not less, as abundant species are both more likely to have their interactions recorded and more likely to have these interactions recorded as strong/frequent. We have rephrased the introduction so that the original line 36 no longer appears. If the Reviewer strongly feels that weighted metrics somehow do sampling biases, we must ask for clarification as to why. We are willing to add a note as requested, but only if we are convinced that weighted metrics are indeed useful in this regard.


	4. Demand for extension to weighted networks [[not done]]

		\begin{refquote}
		L45 It is a shame not to give some idea of how the method could be extended (or is this the intention of the authors?). For empirical analysis of networks it is rare to use binary networks given the value of weighted networks for taking account of sampling biases. Indeed, I am much less concerned about whether an interaction never occurs, and much more concerned with the frequency of occurrence.
		\end{refquote}

		\textbf{R:} As stated above, we do not agree that weighted networks reduce sampling biases. Moreover, we disagree that it is rare to use binary networks as most food webs (for example) are still binary. It takes an even greater sampling effort to quantify interaction strengths than the presence and absence of links, so for species-rich systems in particular there simply are not many high-quality weighted networks published. If the Reviewer is only concerned about weighted interactions, we congratulate them on their tractable study system. Nevertheless, we do not wish to exclude the many researchers who are not so fortunate.
		\smallskip
		To model frequencies of interactions, ...
			 [[Do we want to add a bit of non-binary stuff or just make it clearer that we are talking about feasibility and that probabilities of occurrance could be layered on later?]]


	5. Description of causes of uncertainty poorly integrated with the case study [[done]]

		\begin{refquote}
		L50 This is a nice and clearly explained description of the problem that many network ecologists ignore, or are unaware of.
		Section from L50. This section is valuable, but had very weak links with the empirical analysis later in the paper. For instance in the example of the gall-formers, there was not formal discussion about the different sources of uncertainty. 
		\end{refquote}

		\textbf{R:} As we state in the section \textbf{Estimating uncertainty}, we usually cannot distinguish different sources of uncertainty in empirical data. Those studies which attempt to do so (e.g.,~\citet{Graham2018}) remove process uncertainty by assuming constant interaction probabilities during a short, intense sampling period and also assume that we know the true set of feasible interactions. This may be the case for Graham and Weinstein's relatively small and well-studied system but is not likely to be true for systems containing hundreds of species, systems containing recently-arrived species, systems just beginning to be studied, etc.
		\smallskip
		To make this more clear, we have rephrased this section and added a line (lines XX-XX) stating that we usually cannot determine the cause of all the zeros in an interaction matrix (we can identify obviously unfeasible interactions, but likely cannot say whether a zero for a rare species is because we did not observe enough individuals, there were not enough individuals to perform a particular interaction, or because the interaction is acutally unfeasible). We hope that this revision makes it clearer that the description of different sources of uncertainty is a conceptual guide only.


		\begin{quotation}
			An observed link definitely occurred, but there are multiple reasons why a given link may not be observed \emph{whether or not the interaction truly occurred}. Moreover, given an unobserved interaction in an empirical dataset, we often cannot determine why the interaction did not occur \emph{post hoc}. The detection of any interaction is a stochastic process subject to many levels of uncertainty. As a conceptual guide to the factors affecting this process, we describe three nested levels of uncertainty that roughly address the questions: "Could species $i$ and $j$ interact?", "Do they interact?" and "Do we observe the interaction?" (Fig.~\ref{conceptual_fig}). 
		\end{quotation}


	6. Process uncertainty poorly defined. [[done]]

		\begin{refquote}
		L76ff ‘Process uncertainty’ is not defined. The simplistic example of interaction uncertainty (fish eating a cactus) does not help the reader understand the detail of what is meant by ‘interaction uncertainty’. The two examples of ‘local constraints’ (weather and habitat) are operating on completely different temporal scales (note – it is defined differently in L109). I would regard the issue of weather as much closer to detection uncertainty (e.g. for a pollinator, it would be likely to be interacting if the weather was better), whereas the issue of habitat is closer to the authors’ ‘interaction uncertainty’ (the species don’t interact because they are not, or never, co-occurring in a habitat). Also if the species occur in different habitats then with an appropriate spatial scale of sampling then they do not co-occur – so the issue seems redundant. [[I suspect that the authors are thinking of a meta- or master network in much of their study, but this is not clear (or I have misunderstood and it needs to be explained better), i.e. the predicted presence of an interaction is not the presence of an interaction at the local site (taking detection and process uncertainty into account) but the ability to assess ‘interaction uncertainty’.]][[This is a bit separate from their issue]]
		\end{refquote}


		\textbf{R:} As our manuscript is not concerned with partitioning sources of uncertainty, we felt it was unproductive to get bogged down in a debate over the precise definitions of process vs. interaction uncertainty and which external influences might contribute to which sources (there is enough overlap that simple statements such as "bad weather increases process uncertainty" are, at best, incomplete). To remove this problem, we have rephrased the introduction and discussion to refer to the questions of whether two species \emph{can} interact under ideal conditions and whether they \emph{do} interact at a given site and time. We hope that this reframing, and the addition of clear statements that our framework is not intended to separate different sources of uncertainty, will remove the Reviewer's confusion.
		\smallskip
		Our mention of habitat as a factor affecting the probability of species interacting at a site was not intended to refer to species using different habitats, but rather the possibility that habitat type might affect interaction probabilities. For example, a more open patch of forest might have different interaction probabilities than a denser patch even if the same set of species use both patches. Of course the Reviewer is correct that habitat also affects which species are present at a site. We include co-occurrence in process uncertainty since co-occurrence does not tell us much about whether an interaction is feasible under ideal conditions (which would certainly include co-occurrence). This speaks to our point above that external factors (habitat, weather, etc.) can affect multiple levels of uncertainty at once. In fact, habitat also likely affects detection uncertainty since it is often harder to observe interactions in dense vegetation. So, in short, separating sources of uncertainty based on the external factors which contribute to them is not a particularly useful endeavour.


	7. Point about temporal scales of interaction [[done]]

		\begin{refquote}
		L76ff Different interactions occur at different temporal scales, so it is important to consider where the role of this study lies. For instance, a pollinator-flower interaction is quick (and even the evidence of it, e.g. pollen on the insect, is not long-lasting) whereas an active gall-former interaction could be present for a couple of months and could be detected for even longer (on senescing leaves).
		\end{refquote}


		\textbf{R:} Long-term interactions may be easier to detect, but we do not see how this affects process uncertainty. Spatial variation in interaction probabilities will affect all interaction types, as does variation in abundances between years, so we cannot conceive of any interactions that are exempt from this issue. The timescale of an interaction (and the evidence it leaves) does affect detection uncertainty, so we have added a note in that section. Long-term interactions may fail to be detected, however, and we now add an example to make it clear that detection uncertainty applies to even long-term interactions such as gall-forming (indeed, our results suggest that uncertainty in gall-forming is quite high).

			\begin{quotation}

				Some types of interactions will have higher detection uncertainty than others (e.g., pollination or predation often take place very quickly while parasitism can last for months or years). Even long-term interactions, however, can be missed, especially if species are difficult to identify or if not all individuals of a species share the interaction. Parasites, for example, are often concentrated in only a few individuals~\citep{Lagrue2017}. If these infected individuals do not happen to be included in a sample, their interactoins will be missed.

			\end{quotation}


	8. Confusion about goal of modelling [[done]]

		\begin{refquote}
		I was struggling to really understand what the authors were really trying to model (partly because of the lack of a link between the theoretical and empirical parts of the paper). Are the authors trying to estimate L (the probability that an interaction is feasible or not – I would describe this as a ‘master’ or meta- network), or is it that they are trying to estimate X|L (the probability that the interaction locally occurs)? I would be interested in both, but the second aspect seemed to be ignored in the gall-former example.
		\end{refquote}

		\textbf{R:} In the case study, we are modelling L (the probability that an interaction is feasible). We do not have quantitative data within sites in our dataset, so we cannot isolate the probability of detecting an interaction at a site from the probability that the interaction occurs. This is also the probability we were most interested in. We do note, however, that one could also model X|L using the same framework if there were independent counts of co-occurrences and interactions within a single site. We now state throughout the manuscript that we are interested in compiling the metaweb, the set of interaction which can feasibly occur. In particular, this is now specified in the introduction. We hope that our goal is now crystal clear.

		\begin{quotation}
			To supplement repeated sampling efforts and reduce uncertainty around unobserved interactions, we suggest researchers use prior knowledge of the same or similar systems. Here, we outline a Bayesian approach to combining repeated sampling and prior knowledge in order to assemble a metaweb. We then demonstrate this approach using an intensively and repeatedly sampled empirical dataset. Finally, we show how a probabilistic understanding of a metaweb allows us to establish confidence intervals around measures of network structure.
			\end{quotation}


	9. Misunderstanding of how biased sampling does not solve problems of uncertainty [[done]]

		\begin{refquote}
		L136 This is a completely different issue, that you do not address in the paper.
		\end{refquote}

		\textbf{R:} We do not believe that biased sampling is a completely different issue as the tendency for some interactions to be sampled more easily than others clearly contributes to varying levels of detection uncertainty. Increasing sampling effort will not do much good if we repeatedly sample the same common interactions and very rarely identify any new interactions. We now address questions about whether or not sampling more will remove uncertainty in a dedicated box. We still mention the fact that increased sampling will not reduce uncertainty evenly across interactions as this is an important point to consider when designing sampling protocols and when analysing empirical data. We also point out that combining sampling types is a partial solution to this problem; if different sampling methods have different biases, they may partially cancel each other out. We believe that this addresses the question as much as possible given our focus on analysing collected data rather than collecting new data.


	10. Explain Bayesian approach more simply [[done]]

		\begin{refquote}
		L147 Your Bayesian approach seems important, especially the prior information, and I would have appreciated it being explained more simply.
		\end{refquote}

		\textbf{R:} We have expanded our description of different types of priors and when researchers might prefer one over another. Following a comment from Reviewer 1 we have removed much of the mathematical background for the Bayesian approach, but this material is still present in the supplemental material. We hope that this simplifies the approach adequately.


	11. Integrate L155ff with previous section [[done]]

		\begin{refquote}
		L155ff I think it would be helpful for this section to be integrated with the previous section. It relies on the reader putting quite a lot of work in to understand the link between the two.
		\end{refquote}

		\textbf{R:} We have removed much of the preferatory text explaining which quantity we are most interested in ($\lambda$) and now more explicitly state our goals at the end of the introduction. We hope that the transition to the methods is now less work for a reader.


	12. Ideas presented in L209, L262, L310 are important but explained too briefly [[done]]

		\begin{refquote}
		L209ff This seems a really important set of ideas, but they are exemplified very briefly and very simplistically in the paper (L262, L310). I would have appreciated a much clearer explanation and example.
		\end{refquote}

		\textbf{R:} We are not quite sure what the Reviewer is asking here. $\alpha$ and $\beta$ truly are quite simple (as simple as the mean and standard deviation of a normal distribution) so there is not much more to say about them in themselves. We have expanded our discussion of different types of priors and how they may be obtained, and we hope that this clarifies matters for the Reviewer. We also note that a simple worked example, with accompanying R code, is provided in \emph{Appendix S3} so that readers can see exactly how to obtain $\alpha$ and $\beta$. In case the point of confusion is the idea that $\alpha$ and $\beta$ can be specified or derived depending on the type of prior desired, we have added a line (lines XX-XX) spelling this out.

		\begin{quotation}
			Parameters $\alpha$ and $\beta$ determine the shape of the prior distribution of $\lambda$, which follows a beta distribution. These are called hyper parameters and may be chosen to obtain an intentionally uninformative prior or derived using prior information to create an informed or empirical prior. 
			\end{quotation}


	13. Reframe line 241 in terms of solutions rather than difficulties [[done]]

		\begin{refquote}
		L241 I wonder if you could phrase this more positively as ‘solutions’ rather than just ‘difficulties’?
		\end{refquote}

		\textbf{R:} We appreciate the Reviewer's desire for optimism, but we also selected a high-quality dataset specifically in order to demonstrate that empirically sampling all of the feasible interactions in a system is very unlikely. A lower-quality dataset would work just as well with our framework but would not highlight these difficulties so well. We have therefore kept this line as-is but have added another line (XX-XX) to show how the Bayesian framework provides a partial solution to the problems inherent in even high-quality empirical data.

		\begin{quotation}
		 The high spatiotemporal resolution of this dataset make it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, we anticipate that there will be many pairs of species which were rarely or never observed together. Using the Bayesian framework above, we can identify which potential interactions are more and less uncertain, allowing us to better predict the true structure of the metaweb.
		 \end{quotation}


	14. Line 283 seems to be a very important point and should be explained more clearly [[done]]

		\textbf{R:} Due to space constraints, we cannot provide an extensive description of Jensen's inequality here. As it is quite easy to look up the inequality by name, we are confident that interested readers can find a description to whatever level of detail suits their interest. 
		[[We could potentially add a demo in a new Appendix. Is this worthwhile?]]


	15. Line 291: does assuming probability of 1 for observed interactions introduce bias? [[done]]

		\begin{refquote}
		L291 I have wondered about this – does assuming a probability of 1 for observed interactions create a bias? The observed interactions are a stochastic set of the possible interactions, so by treating observed interactions as 1 and other (equally likely?) unobserved interactions as <1 will surely bias the network metrics. I’m not sure of the solution and would welcome thoughts on this in the paper.
		\end{refquote}

		\textbf{R:} As we are concerned with the metaweb (the set of feasible interactions) rather than the interactions which occurr at a given site on a given day, we do not think that assuming a probability of 1 for observed interactions introduces bias in our study. We have added a justification of setting the probability of observed interactions to 1 in \emph{Appendix S2}. Note that each posterior web is a prediction of the true metaweb and not a local realization of some interactions drawn from the feasible set. These local webs are more akin to our "filtered webs" in which observed interactions are not guaranteed to appear. We have also added a line (lines XX-XX) to make this clear.
		\medskip
		This is an interesting point, however, as systems with a large risk of false positives (e.g., pollination networks which assume all flower visitors provide pollination service) would be biased by assuming all observed interactions are truly feasible. Assuming that all interactions which are known to be feasible actually occur at each site would also introduce bias - I suspect that this is what the Reviewer may be thinking of. As described above, our study cannot isolate $\chi$ (the probability that a feasible interaction occurs at a particular site), so this is not a relevant question for the present work. Future studies with much, much more detailed data may be able to shed light on this.

		\begin{quotation}
			we created a suite of 100 webs by randomly sampling from each posterior distribution. Each of these webs is a prediction of the structure of the metaweb.
		\end{quotation}


	16. Filtering seems arbitrary [[done]]

		\begin{refquote}
		L298 These seem arbitrary. It is not clear what is filtered, or its justification – is it the unique interactions, unique interaction per site or samples? How do these compare to typical sampling effort?
		\end{refquote}

		\textbf{R:} We have rephrased lines XX-XX to make it clearer that the filtered networks are intended to demonstrate how network structure changes as uncertainty increases (and we miss more interactions). As stated, we filtered networks created using the posterior distributions. There are therefore no sites or samples in question here. We are simply retaining a random 90\%-10\% of the interactions (or removing a random 10\%-90\%; these are equivalent) of the interactions in the "true" (posterior) network. We hope that this rephrasing is clearer. 

			\begin{quotation}
				Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. Taking a posterior network as the "true" network, we randomly sampled 90\%, 80\%, 70\%, 60\%, 50\%, 40\%, 30\%, 20\%, and 10\% of the interactions to create a new "filtered" network.
			\end{quotation}


		Note that our model is not concerned with partitioning different sources of variation; the filtering levels we present therefore represent uncertainty from all sources. As such, comparing them directly to "typical sampling effort" would be an apples-to-oranges comparison. We do note that~\citet{Weinstein2017a} found a detectability of 23.3\% for interactions despite high sampling effort,~\citet{Jordano2016} found that about half of unobserved interactions did not qualify as "forbidden links", and~\citet{Bartomeus2013} found that 59\% of interactions were detected. We therefore do not think that the range of filtering levels we applied were particularly unreasonable (although we note that none of the above studies refer to plant-galler networks). That said, the Reviewer is correct that the values we chose were absolutely arbitrary. To make this clear, we now filter in 10\% increments from 90\% to 10\% to illustrate a broader range of uncertainty.


	17. Expand discussion of results on line 321 [[not done]]

		\begin{refquote}
		L321 This is a really important and interesting set of results that are worthy of greater discussion. The issue of metrics from sampled networks is important, but gets lost in the paper. Please expand upon this.
		\end{refquote}

		\textbf{R:} [[This is the network metrics bit - need to expand in discussion.]]


\clearpage

\end{document}