\documentclass[12pt]{letter}

\usepackage[britdate]{LiU-letter}
\usepackage{times}
\usepackage{letterbib}
\usepackage{geometry}
\usepackage[round]{natbib}
\usepackage{graphicx}
\geometry{a4paper}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage[running]{lineno}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}

%\usepackage{natbib}
% \bibpunct[; ]{(}{)}{;}{a}{,}{;}

\newenvironment{refquote}{\bigskip \begin{it}}{\end{it}\smallskip}

\newenvironment{figure}{}


\begin{document}



\newpage

\setcounter{page}{1}


% Changes: reducing discussion of different sources of uncertainty, increasing description of priors, added a bunch of refs, trying to frame our study more clearly. Changed filtering to reflect all uncertainty, not just detection (more accurate, hopefully less confusing). No box needed, just ``Why sample'' section.


% Ask for help: how would we expand this to interaction frequencies? Still with the Bernoulli? Worthwhile to add a demo of Jensen's inequality?
% To do: expand discussion of our results as much as possible given space constraints.
% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
{\Large \bf Reply to Associate Editor}
% ---------------------------------------


	\begin{refquote}
	Your manuscript has been assessed by four different referees who agree that you touch upon a very important problem. However, they all feel your manuscript needs substantial improvements. They provide excellent advise on how to revise your manuscript and you should carefully consider all their comments. Overall, you do not acknowledge important past contributions and do not clearly explain the importance of the methodological issues you cover in your study. Importantly, referee 1 feels the real novelty of your study is the consideration of the importance and complexity of choosing prior information in constructing networks. Obviously, this is an issue in the context of Bayesian approaches, which are not necessarily well understood by empiricists, precisely the audience your manuscript should address. Please, follow very closely the suggestions of the referees when revising your manuscript.

	\end{refquote}

	\textbf{R:} We appreciate the thoughtful feedback by the four referees. We take particular note of the comments regarding the structure and grounding of our introduction and have worked to address them. 


	Reviewer 2 takes a different view of the purpose and scope of the manuscript from that of the other reviewers. We respect his/her ideas but feel that some are beyond the scope of the present manuscript. In particular, we do not feel that a full simulation study is necessary given the simplicity of our framework. We emphasise that we are not introducing a software package (although we do provide simple code to aid those who are new to the field), nor are we introducing an entirely new framework (as the other Reviewers point out, many components of our approach have been touched on by previous work). Thus, the novelty and impact of our work explicitly lies in connecting a Bayesian statistical approach to the problem of limited and uneven sampling of networks (driven by difference in species abundances, detectabilities, constrained time and budgets, etc.) and, we hope, in making this method more accessible to those without extensive statistical or modelling experience. Please note that Reviewer 3 identified this need explicitly. 
	% Tomas has a line break here, I'm not sure.
	Because of the difference between Reviewer 2 and the other Reviewers, we have opted to prioritise the majority view and focused first on comments by Reviewers 1, 3, and 4. However, we hope and trust that, in the course of these revisions, we have at least partially addressed Reviewer 2's concerns as well. 


	As a key point of departure for our revision, we have taken Reviewer 1's suggestion that we expand upon the different types of priors available and reasons for choosing one over the other. We also now offer a brief discussion about concerns over the subjectivity of prior selection. We argue that a great deal of subjectivity is baked into the compilation of empirical networks and that a Bayesian approach can be seen as making this subjectivity explicit. We hope that this will encourage empiricists to explicitly use their system-specific knowledge to create reasonable priors, as likely already occurs subconsciously (as in the designation of ``forbidden links``). 


	Overall, we hope that our revision more clearly frames the importance of uncertainty in ecological networks and positions a simple Bayesian approach as a partial solution (together with high-quality sampling, of course). 
	We have also added many references to prior work. While the present study is not intended to be a full review of the literature, we certainly do not wish to downplay other workers in the area.
	Finally, several of the Reviewers appeared to believe that we were advocating for reduced sampling effort. That is emphatically not the case (we had not anticipated that anyone would seriously consider sampling less than they otherwise would when using our framework), and we have revised the manuscript to be clearer about the fact that increased sampling effort can reduce some sources of uncertainty and that high-quality sampling should form the basis of any empirical network. We hope that it is now clear that the Bayesian framework we promote is a complement to excellent field work, not a replacement for it.


	Once again, we thank the Associate Editor and Reviewers for their comments and hope that our revised manuscript will satisfy their concerns.

\newpage


% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Reviewer \#1}
% ---------------------------------------


	The Reviewer complimented our manuscript as ``well-written'' and addressing the ``hugely important'' question prior choice in network analyses. He/she supports our suggestion that researchers use their system-specific knowledge when embarking upon Bayesian analyses, and has suggested that we restructure the manuscript (especially the introduction) in order to come more directly to the issue of prior choice. In the present revision we have taken this advice to heart and streamlined our introduction in order to expand our discussion of prior choice. In this revision, we have retained some of the introductory material, which the Reviewer notes describes ``ground very well-trod'', in order to ensure that readers entirely new to Bayesian analysis will understand the problem at hand. We hope that the introduction now strikes a balance between providing essential background information for Bayesian novices and moving quickly enough for those who do not need such a gentle introduction. We thank the Reviewer for their feedback and address each point (prefaced by \textbf{R:}) below.


	1. Suggestion to refocus on prior selection

		\begin{refquote}
			In ecology more broadly, priors are treated with timidity, as if we couldn't dare to leverage past work on our current understanding. Personally, I have always felt limited by this standard. I applaud the authors for taking on this challenge, and I would like to see an introduction that merits and debates this question in much more detail. ... Walking the reader through flat priors, informed priors and empirical priors is crucial for the importance of analysis to be understood by the reader. The use of empirical priors can be quite controversial, and should be at least touched on in the discussion. 
			\end{refquote}


		\textbf{R:} We thank the Reviewer for his/her positive evaluation, and have done our utmost to reframe and tighten the introduction and framing of the paper. In doing so, we have happily adopted the suggestion to expand our discussion of prior selection, particularly with regard to approximate/empirical Bayes. Although we are somewhat space-limited, we have expanded our description of the different priors available and why a researcher might choose one over another (section beginning with line 200). We also touch upon the controversy over using empirical priors (lines 283-289) although we were unable to find many references addressing this in detail. We hope that this expanded description will be a better guide for empiricists who may not be familiar with Bayesian statistics.


		In implementing the Reviewer's comments on our introduction, we believe that most readers who are less familiar with Bayesian procedures will need a quick outline of the problem of uncertain detection of interactions in order to be motivated to dive into the larger discussion of priors. We stress that our intended target audience is empirical ecologists working on network description who likely have a different skillset than that of the Reviewer. We also note that Reviewer 2 found that \emph{``The introduction is particularly pleasant to read and the problem is well stated``}, praise which we would hate to lose. Therefore we have revised and streamlined our introduction but still refrain from jumping straight into prior selection. We have, however, taken care to introduce our analysis as a worked example (lines 200-201) and hope that this helps to reduce the conflict between the introduction and our data. 


		Overall, we thank the Reviewer for their compliments and accept their suggestion that we are somewhat overexcited about our approach. Thus, we have refined the introduction to be more specific about the problem we are attempting to solve. We have also expanded our treatment of prior selection and hope that our paper now reads as achieving its goal.


	2. Suggestion to add more literature


		\begin{refquote}
		The introduction flows well and is thoughtfully laid out. Given the enormous amount of literature in the field, it is not possible to provide a full set of citations. However, it seems remiss to not consider Jordano (2016) in the sampling section.
		\end{refquote}


		\textbf{R:} We thank the Reviewer for their compliments to our introduction and for the literature recommendations. We have incorporated these references as suggested (including Jordano, 2016 in the sampling section). Following comments from other reviewers, we have refined and restructured our introduction in the hope of more clearly establishing the goal of our manuscript. We hope that this revised introduction will also meet with the Reviewer's approval. 


	3. Suggestion to de-emphasise MLE estimate and get straight to Bayes


		\begin{refquote}
		It's a bit confusing to lead the reader towards a Bayesian analysis, and then immediately start with the MLE estimate. Why is this needed at all? (L162-186). Just start at 187?
		\end{refquote}


		\textbf{R:} The MLE estimate is part of the Bayesian framework as it dictates the shape of the distribution that we use. Moreover, it helps to formalise our argument that most networks are undersampled, justifying the Bayesian approach and the use of priors to reduce/set bounds around the resulting uncertainty. We therefore feel that it is important to keep some discussion of the MLE estimate in the manuscript. We now introduce the MLE formally within this context (lines 179-184) and take care to be explicit when using it to explore the sample size needed in the absence of prior knowledge later (caption of Figure S2, \emph{Appendix S2}}).


		Lines 179-184:


		\begin{quotation}
			The basis of a Bayesian approach to modelling the probability that an interaction between species $i$ and $j$ occurs ($\lambda_{ij}$) is combining the maximum likelihood estimate (MLE) of $\lambda_{ij}$ with a prior distribution (described in the next section) and a normalising function. The MLE of $\lambda_{ij}$ can be modelled as a Bernoulli trial based on the number of observed interactions $k_ij$ and observed co-occurrences $n_{ij}$: $\lambda_{ij}=\frac{k_{ij}}{n_{ij}}$. The most appropriate prior distribution for $\lambda_{ij}$ is the beta distribution:
		\end{quotation}


		Caption of Figure S2:


		\begin{quotation}
			The number of observed co-occurrences needed to believe that an unobserved interaction cannot occur is very high (about 35; Fig. 3), and most datasets will not include this level of sampling for all pairs of species~\citep{Bartomeus2013}.
		\end{quotation}


	4. Suggestion to remove moments of the beta distribution


		\begin{refquote}
		I think a bit of space is wasted on defining the moments of the beta distribution. This is very googleable, and almost too thorough. I think the space is better utilised aligning the ecological challenge and the quantitative method.
		\end{refquote}


		\textbf{R:} While we feel that a short introduction to the beta distribution is important to bring researchers new to Bayesian statistics up to speed (and give them some keywords to Google), we accept the Reviewer's suggestion to reduce the amount of space given to the beta. We have therefore moved the description of basic properties to Appendix S3. The remaining paragraph introducing the beta distribution now leads directly into the section describing prior selection.


	5. Novelty of the study not clear in current framing


		\begin{refquote}
		I'm wrestling with the novelty of the work as presented and whether it reaches the standard for publication at MEE. Certainly, much of this logic is laid out in other works. The authors are well aware of this and have made significant contributions to this topic in the last few years. In particular, the authors should try to be much more explicit about the contribution they hope to offer that hasn't been covered. ...
		While it is true that none of the [suggested] papers do the exact same thing as this manuscript, they all	orbit the same topic. 
		\end{refquote}


		\textbf{R:} We thank the Reviewer for the literature suggestions and now include them in our introduction and/or discussion. We emphasise the board applicability of our approach across network types and systems with varying degrees of prior knowledge. We also emphasise that our approach is not restricted to species observed X times (as many predictive models are) and can include species not yet observed at a site (e.g., potential invaders). Finally, we note that there is a need to synthesise the literature on sampling issues and formalise the sources of uncertainty affecting the estimation of pairwise interactions. There are, as the Reviewer notes, already a number of publications addressing probabilistic interactions, but none of them adequately characterise uncertainty about interactions. We hope that the contribution our manuscript makes is now clearer.


	6. Potential contradiction 
 

		\begin{refquote}
		L89 for example, seems to conflict with the two paragraphs immediately following it?
		\end{refquote}


		\textbf{R:} We now address questions of sampling in the paragraph beginning with line 168 and in Appendix S2. We hope that this revision makes it clear that sampling should be as high-quality as possible but that sampling is unlikely to completely remove uncertainty.


	% 	Literature suggestions:
		% Jordano, P. (2016). Sampling networks of ecological interactions. Functional Ecology, 30(12), 1883–1893. doi:10.1111/1365-2435.12763
		% Bartomeus, I. (2013). Understanding Linkage Rules in Plant-Pollinator Networks by Using Hierarchical Models That Incorporate Pollinator Detectability and Plant Traits. PLoS ONE, 8(7), 1–9. doi:10.1371/journal.pone.0069200
		% Poisot, T., Cirtwill, A. R., Cazelles, K., Gravel, D., Fortin, M.-J., & Stouffer, D. B. (2016). The structure of probabilistic networks. Methods in Ecology and Evolution, 7(3), 303–312. doi:10.1111/2041-210X.12468
		% Poisot, T., Stouffer, D. B., & Gravel, D. (2015). Beyond species: why ecological interaction networks vary through space and time. Oikos, 124(3), 243–251. doi:10.1111/oik.01719
		% Graham, C. H., & Weinstein, B. G. (2018). Towards a predictive model of species interaction beta diversity. Ecology Letters. doi:10.1111/ele.13084
		% Gravel, D., Poisot, T., Albouy, C., Velez, L., & Mouillot, D. (2013). Inferring food web structure from predator-prey body size relationships. Methods in Ecology and Evolution, 4(11), 1083–1090. doi:10.1111/2041-210X.12103
		% Wells, K., & O'Hara, R. B. (2013). Species interactions: Estimating per-individual interaction strength and covariates before simplifying data into per-species ecological networks. Methods in Ecology and Evolution, 4(1), 1–8. doi:10.1111/j.2041-210x.2012.00249.x


\clearpage


% ----------------------------------------------------------------------
% ---------------------------------------------------------------------
{\Large \bf Reply to Reviewer \#2} 
% ---------------------------------------

	The Reviewer stated that our manuscript ``tackles a very interesting problem, quantifying the uncertainty of interactions'' which he/she rates as ``one of the hottest topics in the field``. He/she also points out that ``the introduction is particularly pleasant to read'' and that we framed the problem well. The Reviewer also pointed out a number of weaknesses to the manuscript that we respond to one-by-one. In general, we feel that the Reviewer's comments reflect a high degree of statistical expertise; expertise that we do not expect to be shared by the bulk of our intended audience (empirical ecologists assembling new ecological networks). We have therefore prioritised comments by this and the other Reviewers that seemed most likely to improve the manuscript for readers who are relatively new to Bayesian analysis over concerns most relevant to a highly knowledgeable reader. We hope that our revised manuscript makes this target audience clearer, and that we have addressed the Reviewer's key concerns with our revision. Below, we respond to each of the Reviewer's comments (preceded by \textbf{R:}) in turn.


	1. Lack of references 


		\begin{refquote}
			
			The fundamental question about predicting interactions given some uncertainty has been and is debated in many papers (see the seminal paper by Roger Guimer\`{a} and Marta Sales-Pardo, PNAS, 2009). Even if the proposed framework is probably not stated in its exact terms in the literature, bridges between existing approaches (beyond Ecology) and the one in the paper would be very welcomed. An appropriate discussion between points of convergence and difference would help the reader to appreciate the significance and the impact of the proposed methodology.
		
		\end{refquote}


		\textbf{R:} This comment echoes the impression of Reviewers 1 (above) and 3 (below) that we do not give adequate attention to previous work. As stated above, we have now added many further pointers to previous work, and also been much more explicit regarding whom we try to reach with what message in the current paper. We have also included references from medical and epidemiological research as examples of the use of Bayesian methods beyond ecology. 


	2. Non-independence of interactions not accounted for 

		\begin{refquote}
			2/ network oversight: the approach considers that the interactions are independent, which is not the case in real data. Indeed, the paper is supposed to be ``network-oriented'' but the methodology deals with independent interactions (e.g. the variables L,T,X and D introduced lines 62,77,101 are for instance not indexed by ij which could have suggested that the interactions were seen as a whole). Consequently, the mathematical framework remains quite simple and may not reflect nor model the processes governing the actual detection of interactions. Despite of this drawback, the proposed method is interesting but at least the authors should add some discussion on the limits of dealing with independent interactions,
		\end{refquote}


		\textbf{R:} We agree wholeheartedly that ecological interactions are often not independent. Indeed, some of the priors we discuss (e.g., those incorporating species' abundances or trait-matching) will introduce covariance between interactions. The Reviewer is correct that we did not initially mention this non-independence explicitly. Our aim is to keep our mathematical framework simple so that it is easy for those not familiar with Bayesian analysis to adopt. Nevertheless, non-independence of interactions is an important consideration. We are therefore happy to index all variables referring to interactions by ij and we have added explicit statements (lines 186-190 and 248-255) that some priors treat interactions independently while others will introduce covariance (e.g., by species). 


		Lines 186-190:


		\begin{quotation}
		    The shape parameters, or hyperparameters, may be set to particular values or derived from some data (see below). Note that the hyperparameters may be set to the same values for all interactions, allowed to vary independently for all interactions, or may incorporate non-independence between interactions (e.g., when the shape of the prior distribution depends upon species' abundances or traits).
		\end{quotation}


		Lines 248-255:


		\begin{quotation}
			Multiple sources of information can be combined into a single model (e.g., the the $K$ nearest neighbour (KNN) algorithm, which identifies likely interaction partners based on similarity to known partners~\citep{DesjardinsProulx}). This would result in a highly informative prior that would, moreover, account for some of the non-independence in interaction probabilities. 


	        Using an informative prior like these tailors the level of uncertainty surrounding each interaction and may account for non-independence of interactions (as in abundance-based or KNN models).
	    \end{quotation}


	3. Question about identifiability of the model

		\begin{refquote}

			the reader would appreciate that the authors discuss and prove the identifiability of the model. Indeed, the three levels of uncertainty are nested but one could wonder whether different parameters at the three levels can fit the same data with the same quality (i.e. no identifiability).  I would suggest this point to be addressed in a specific section.

		\end{refquote}


		\textbf{R:} We believe that this comment stems from a lack of clarity about the goal of our model. It is not designed to separate the three levels of uncertainty or introduce parameters at particular levels. The only inputs are a prior distribution, which could refer to any level of uncertainty applicable to the study at hand, and post-hoc counts of interactions and co-occurrences. Using only the observed data, it is impossible to separate the three levels of uncertainty and our model does not aim to do so (as stated in lines 159-167 and lines 199-201). We therefore do not believe that an in-depth discussion of identifiability would add much value to the manuscript and, in the interest of space, have decided not to include one. Instead, we refer interested readers to~\citet{Weinstein2017} which does attempt to separate sources of uncertainty.


		Lines 159-167:


		\begin{quotation}
			When considering a metaweb, we wish to separate the unobserved interactions where $L_{ij}=0$ (i.e., unfeasible interactions) from interactions which could occur but did not at a particular sampling site or which occurred but were not detected (Fig. 1). Unfortunately, this is not possible for most interactions (except those where we know an interaction is truly not feasible). That is, we generally do not know \emph{why} an interaction was not observed, only that it was not. An empirical ecologist will instead measure the marginal probability $P(L_{ij})=k_{ij}/n_{ij}$, where $k_{ij}$ is the number of observed interactions between species $i$ and $j$ and $n_{ij}$ the number of observed co-occurrences. Given this information, the question becomes: how can we reduce the uncertainty around our estimated interaction probability?
		\end{quotation}


		Lines 199-201:


		\begin{quotation}
			 Note that these models of $\lambda_{ij}$ do not distinguish between sources of uncertainty except through the choice of prior. For a model which attempts to separate sources of uncertainty, see~\citet{Weinstein2017}.
		\end{quotation}


	4. Request for a simulation study 


		\begin{refquote}
			the authors proposed an original approach based on a Bayesian framework. Beyond the identifiability question (see above), the reader can question the power of the method. Usually, a methodological proposal comes with a complete simulation study that is supposed to show  the proposed model is adapted/suitable to the question and efficient to solve it. In the paper in its present form, the authors assume that the reader will be convinced by the results obtained on a single real dataset... In my opinion, the reader can't be fairly convinced: how powerful is the method? what can we say about the priors? how much data (n, k) is necessary to expect good results? An so on... Only a well-conducted simulation study can answer these questions.
		\end{refquote}


		\textbf{R:} We agree with the Reviewer that a full simulation study, based on recreating the sources of uncertainty in a data set generated from known processes, is a good way to demonstrate the power of a novel method. The novelty and impact of our work, however, is not in the method itself (several other Reviewers rightly point out that similar approaches have occasionally been used before) but in connecting a Bayesian statistical approach to the problem of limited and uneven sampling of networks and, we hope, in making this method more accessible to those without extensive statistical or modelling experience. In other words, what we try to achieve here is to alert empirical ecologists constructing and analysing networks to the uncertainties built into their work. We then try to provide them with simple tools for grasping the extent and consequences of typical patterns. Please note that other Reviewers (as expressed by Reviewer 3 in particular) find this a highly worthwhile objective. 


		What Reviewer 2 proposes would be more suitable for an entirely novel method and is substantially beyond the scope of the present study. There is indubitably a place for simulation studies in order to find the most powerful method once a variety of tools are in common use, especially for researchers aiming to convince modellers that their tool is more powerful. Our manuscript, however, is not aimed at those already comfortable with Bayesian approaches but rather at those who may be aware of the problems of uneven uncertainty but not aware of any way to include this information in their analyses. We are confident that even a very simple model which incorporates the differences in sampling across interactions (as ours does) is more powerful than a model which ignores this information completely, and we therefore do not intend to conduct a full-scale simulation study. We accept that this means that those already using more intricate Bayesian methods are unlikely to switch to our simpler version; it was never our intention that they should do so.


		We must also point out that some of the Reviewer's questions (e.g., how much data is necessary to expect good results) have already been answered analytically. Without an informative prior, we need approximately 35 observed co-occurrences with no observed interaction to be 95\% confident that the interaction does not occur. We also provide simple R code that will allow interested readers to analytically explore the response of confidence intervals, etc. to different amounts of data and different strengths of priors. While a simulation study could help to develop intuitions about changing field conditions, these analytical responses are exact and more general.


	5. Request for an extended results and discussion section


		\begin{refquote}
			5/ results\&discussion too short: the reader is surprised to read 27 lines of raw results only... Given the amount of new methodology that is proposed, one can expect a complete description of its pros and cons. Obviously, a simulation study (see above) would enrich the results part. Forgetting about the length of these parts, it is still difficult to catch the key messages from the text, and it is not obvious to relate discussion and the obtained results (for instance,from l.343 to l.351).
		\end{refquote}


		\textbf{R:} We very much appreciate the Reviewer's point that the results and discussion do not clearly illustrate the point of the manuscript. Although we have not conducted a simulation study (see above), we have extensively revised these sections in order to highlight the main thread through the manuscript. Due to space limitations, we were unable to greatly expand either section (we prioritise the introduction and methods, which lay out the problem of uncertainty in networks and how it can be partially addressed), but we hope that the results now more clearly demonstrate how a Bayesian approach can address the uncertainty inherent in sampling.


	6. Suggestions to improve notation 


		\begin{refquote}
			6/ lack of rigorous notations: it is possible to understand the approach with the present notations but some improvements can help the reader because there are a series of inconsistencies. Here are some suggestions. The authors chose upper case letters L,T ,X,D for single entities whereas the mathematician is used to expect matrices or constants in upper case. Traditionally, given species i and j, we would consider interaction $L_ij$, feasibility $X_ij$, detection ability $D_ij$... \\
			Still, what is T?? not defined, never reused: is it a characteristics on i, on j, on both? \\
			How can be D<1 on l.169? D=0 or 1 since it says if an interaction is detectable or not... \\
			Moreover, L is reused later but is the number of interactions (l.100 supp.mat)... \\
			What is ``N'' in Figure 4? is it ``n''? What is $n_ij$ and $k_ij$ l.266? Never defined, never reused. \\
			In the beginning of the paper, $\lambda$ is a probability (l.62) but it becomes a random variable (l.164): it would be more consistent to introduce before the notion of hyperparameters  (l.209-213) and to explain we consider that $\lambda$ is drawn into its distribution.
		\end{refquote}


		\textbf{R:} 
			\begin{itemize}
				\item As described above, we have now indexed $L$, $T$, $X$, $D$, etc. by $ij$. 
				\item $T$ describes trait matching, so it is a characterisation on $i$ and $j$ together. 
				\item $D$ can be \textless1 because some interactions are detectable but with a lower probability due to limitations in sampling techniques, sampling time, etc. With infinite monitoring time and capacity, all $D_{ij}$ would indeed be 0 or 1, but given real-world constraints that lead to otherwise-detectable interactions being missed, we feel it makes sense to discuss $0<D_{ij}<1$. For instance, consider a predator feeding upon two prey. If one of the prey (A) has many hard parts and is digested slowly, while the other has no hard parts and is digested quickly (B), the interaction involving prey A will be more detectable than the interaction involving prey B. The interaction with prey B is does not have D=0, because the interaction might be observed directly or through examination of gut contents very soon after B was consumed, but we cannot say that D=1 because we are quite likely not to detect this interaction in any given sample. 
				\item Using L to mean the number of interactions is incredibly common in the food-web literature, especially when defining connectance (as in the instance the Reviewer points out - now included in the main text). That said, we appreciate that this useage may confuse mathematicians. We therefore now define the number of interactions as N and hope that this is less puzzling.
				\item Yes, the N on figure 4 should have been $n_{ij}$. This has been corrected. As discussed above, $n$ and $k$ are now always indexed by $ij$. 
				\item We do not catch what the Reviewer is aiming at here. We hope that our revised introduction and methods have addressed this point; if not, we request that the Reviewer kindly provide some more detail so that we can address his/her concern.
			\end{itemize}


	7. l.62: define formally T


		\textbf{R}: We now define $T_{ij}$ as ``some function describing trait-matching $\mathbf{T_{ij}}$``. This definition is intentionally open-ended as we foresee that $T_{ij}$ could be binary (traits are compatible or not) or continuous with a wide array of distributions.


	8. Clarify the point of analysing the data using an alternative prior 

		
		\begin{refquote}	
			-l.244: this is weird to mention that the analysis has been done on another dataset but that the results will not be discussed... What is the interest for the reader?
		\end{refquote}


		\textbf{R}: We have removed the reference to the analysis and now explain more thoroughly how the choice of an unsuitable prior can result in unrealistic posterior distributions, as this is the interest for the reader.


	9. No ``moral network'' 


		\begin{refquote}
			-l.149: since the authors consider the interactions are independent, there is morally no network in the approach (except the result)
		\end{refquote}


		\textbf{R:} While we do implicitly consider interactions independent, we disagree that there is no network in the approach. The structure of the network is used to design our prior distribution for interaction probabilities, and we show how an understanding of uncertainty at the level of species pairs is essential to understand uncertainty about network-level properties (Appendix S10). Note that even had we specifically stated that interactions are considered independent, this would not be unique among network analyses (see e.g., ...). To us, non-independence of interactions is not necessary when considering a network. All that is essential is the endeavour to better understand a community of interacting species, which our study does aim to do. 


	10. l.252: not clear. Why this choice?


		\textbf{R:} We have expanded the description of the reasoning behind our choice of prior and hope that the following is clearer:


		Lines 320-324:


		\begin{quotation}
			As we lack a trait-based model or similar published network, we will use data from a single sub-network from the middle of the geographical distribution of the~\citet{Kopelke2017} dataset to inform our prior distribution. This simulates an empirical Bayes model using a pilot site to inform the prior distribution. A site in the middle of the geographic distribution was chosen in order to minimise bias towards species at any geographic extreme.
		\end{quotation}


	11. l.259: not clear 
	
		
		\textbf{R:} We have expanded our explanation of how mis-matched priors can give unrealistic results. We hope that the following is clearer:


		Lines 324-326:


		\begin{quotation}
			To demonstrate how a poor choice of prior can give unreasonable posterior distributions, we repeated our analyses using priors derived from a much smaller system (\emph{Appendix S7}).
		\end{quotation}


	12. Why connectance and nestedness?


		\begin{refquote}
			-l.278: the authors investigate the consequence of uncertainty on network metrics. This question is of peculiar interest, but here it is restricted to the connectance and nestedness. Why these two metrics? Why not others? What is the impact of integrating uncertainty into the metrics computation? (we guess the answers but we could expect the authors develop these points).
		\end{refquote}


		\textbf{R:} We chose connectance and nestedness (together with degree distributions) as simple examples of commonly-assessed network properties that would be familiar to most readers working with ecological networks. Obviously these are not the only parameters of interest, but we do not have space to provide an exhaustive analysis of how uncertainty in the computation of network metrics affects different network properties. Our aim was simply to show that including uncertainty in interactions (and accounting for the possibility that many interactions are not observed) can dramatically change our perception of network metrics. A full discussion of how and why these values differ is better suited to either an exhaustive simulation study or an experimental study where different sources of uncertainty can be controlled to some degree. We now state that these four properties were chosen as illustrative examples (lines 425-428).


		\begin{quotation}
			After obtaining these posterior networks, we calculated, as examples of commonly-used network properties, the connectance of each web, as well as the mean number of links per galler and per natural enemy, and the nestedness (NODF) of the network.
		\end{quotation}


	13. l.291: explain better the simulation procedure
	

		\textbf{R:} In the interest of space, we have added an extended description of the sampling procedure in \emph{Appendix S2}. 


		Lines 420-425:


		\begin{quotation}
			Using the prior distributions and procedures described above, we calculated posterior probability distributions for species pairs that were not observed interacting. Using these posterior distributions and assuming probabilities of 1 for pairs of species that were observed interacting (see Appendix S2 for a justification), we created a suite of 100 webs by randomly sampling from each posterior distribution. Each of these webs is a prediction of the structure of the metaweb.
		\end{quotation}


	14. l.306: given the shape of the distribution (exponential), the mean is not an appropriate indicator. [done]


		\textbf{R:} The mean may not be the best indicator with which to describe the shape of the distribution, but we hope that the Reviewer will agree that it gets the point across (co-occurrences are rare; the specific values are not of great importance). Nevertheless, we now include both mean and median in order to better reflect the exponential distribution of the data.


		Lines XX-XX:


		\begin{quotation}
			the total number of co-occurrences was generally low (mean=3.87, median=2; Fig. 2A). The bulk (92.24\%) of these co-occurring species pairs were never observed interacting. Of those pairs that did interact, the incidence of interaction was also low (mean=4.04, median=2; Fig. 2B) and was lower than the number of observed co-occurrences (Fig. 2C).
		\end{quotation}


	15. What does higher nestedness in the observed networks mean? How is it possible? [done]


		\textbf{R:} Nestedness being higher in the observed networks simply means that the additional interactions predicted by our model tend not to be between generalists and specialists and, as such, do not contribute strongly to nestedness. This is actually somewhat intuitive - ``specialists'' in the observed data are exactly those species for which we are most likely to be missing interactions, and interactions between specialists and the most likely to be predicted to occur but not have been observed. Due to the tight word limit, we do not have space to discuss this extensively in the manuscript but have added brief interpretations in the results.


		Lines XX-XX:


		\begin{quotation}
			Nestedness was higher in the observed network (NODF=6.85) than in the posterior webs (6.31 $\leq NODF \leq$ 6.82; Fig. 5C), indicating that the posterior webs include many more interactions between specialists than the observed network. In addition, the stronger the detection filter, the farther apart were the nestedness of the observed and posterior webs. This suggests that the interactions included in the observed network are not a random subset of those included in the posterior webs.
		\end{quotation}

\clearpage

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#3}
% ---------------------------------------

	The Reviewer commented that our paper is, overall, very good and ``makes an important contribution'' as ``a very nice attempt to show the broader community that the Bayesian approach is not so complex and has many advantages``. We are glad that the Reviewer agrees about the importance of this message and appreciate his/her suggestions to improve the manuscript. We have taken care to add references and clarify the introduction, as well as to state explicitly that we are emphatically not suggesting that anyone sample with lower effort/intensity than they otherwise would. We considered the benefits of high-quality sampling to be so self-evident that it did not occur to us that our manuscript could be read as suggesting that extensive sampling is not worthwhile. We thank the Reviewer for pointing out the potential for confusion over this point and hope that it is now clear that Bayesian analyses are a complement to, not a replacement for, high-quality sampling. Below we address each of the Reviewer's suggestions (response preceded with \textbf{R:}) in detail.


	1. Add more references to the literature


		\begin{refquote}
		1.      The simplest – do a better job of acknowledging what else has been done in the field – much of which has actually been done by the authors and their collaborators.  Given that they know there work I won't point that out (but they are under-siting this literature a bit) but they could consider Graham and Weinstein on-line early 2018 (I realise that this was just out when the author's submitted but it has some very similar messages) and the empirical example of Weinstein and Graham in Ecology letters 2017.  I don't think this would in any way diminish the importance of the current paper because I think the challenge in network ecology is to get people to use better quantitative methods.
		\end{refquote}


		\textbf{R:} We thank the Reviewer for stressing the need to further acknowledge previous work in the field. As this was also emphasised by other reviewers, we have taken this carefully \emph{ad notam} and expanded our references to earlier work as much as possible given length restrictions. We have taken particular care to add references to Graham/Weinsten papers as two of the reviewers suggested work by these authors. We hope that the introduction now presents a more thorough sample of previous work, remembering that our manuscript is not intended to be a comprehensive review.


		\begin{refquote}
		Line 7.  It is certainly true that most networks are snapshots in time but there is a growing realisation – including some nice examples (including those by the authors) that address this issue.  Maybe what you want to say is that we know that networks should not be considered static but we lack the tools – or ability to collect data – or whatever you think is the cause – to correct this situation. 
		\end{refquote}


		\textbf{R:} When revising the manuscript we removed line 7 and no longer refer to networks as snapshots.


		\begin{refquote}
		Line 30.  There are several conceptual and empirical attempts to consider detection probability – why aren't these cited (work by Bartomeus comes to mind).\\
		\end{refquote}


			\textbf{R:} We agree, and have added a citation to Bartomeus as requested. In terms of why we will have omitted references to other similar papers and to some less conceptual and empirical attempts, we must stress that we are not striving for a comprehensive review but rather trying to reach a particular audience with a particular message, for which we find MEE the ideal forum. The length and formatting constraints of an MEE article mean that, for the sake of brevity and clarity, we cannot cite all previous work concerning detection probability.


		\begin{refquote}
			Line 36.  I certainly see value in the approach and the general ideas of these authors in particular but they should acknowledge the work that has been done by themselves and others!\\
		\end{refquote}


		\textbf{R:} We have rephrased the end of this paragraph to mention previous predictive models dealing with uncertainty in interaction matrices. As said, we have done our best to improve our coverage of previous work, within the limits offered by the current format.


		\begin{refquote}
		Line 89.  In Weinstein and Graham (Ecology Letters) the processes modelled were trait matching (which you place in interaction uncertainty) and abundance (which is perhaps your process uncertainty??).  I find myself quite confused based on how you describe things in this MS (See text above) and how you cite the literature.
		\end{refquote}


		\textbf{R:} We have revised this section and now no longer refer to the specifics of Weinstein and Graham at all. Instead, we discuss repeated sampling in an appendix dedicated to the question of whether sampling is useful (of course it is) and whether it can completely solve problems of uncertainty in ecological networks (almost certainly not). We hope that this is less confusing.


		\begin{refquote}
		Line 148.  Please note that a paper with a very similar aim was recently published (Graham and Weinstein).  This does not to diminish the value of this study in any way, as multiple perspectives on quantitative solutions in network ecology are urgently needed..... but the other work should be considered. 
		\end{refquote}


		\textbf{R:} We had not seen the Graham and Weinstein paper when we first submitted our manuscript, but now cite it in the introduction. We have also revised this section in hopes of making the uniqueness of our framework (its simplicity and adaptability) clear. % Dom and Tomas have a paper that also addresses this, but I'm not quite sure which one (you're both too productive!)


		\begin{refquote}
		Line 288.  I am pretty sure this idea is in the literature several times and should be cited.  Isn't this the same as drawing a probability of interaction from a distribution where the distribution of each interaction is an output of the Bayesian method?
		\end{refquote}


		\textbf{R:} Yes, that is exactly the idea. We are also sure that this is a common approach and therefore hadn't cited it (in the same way one would not be likely to cite the prior users of common statistical tests). We have added a citation to~\citet{Vazquez2005,Guimera2009} as two examples and hope that this is sufficient.


		\begin{refquote}
		Line 352 – 358.  Citations are needed in this section as this has been suggested before.
		\end{refquote}


		\textbf{R:} Most of these lines refer specifically to our results, making it somewhat difficult to add citations. We have added citations where possible and rephrased this section to make it clearer when we are referring to work done in the present manuscript.


	2. Clarify confusing terminology

		\begin{refquote}
		2.      Provide more clarity in descriptions making sure to consider how terms and ideas have been used previously.  Two things come to mind – the use of terms and distinction between interaction and process uncertainty; and the somewhat contradictory sounding statements about if sampling more is actually good.


		Line 86.  So, similar factors (i.e., trait matching) can be used to detect different kinds of uncertainty.  Should this be stated?  You might also consider a different word that process as ``observation models'' and ``process models'' are commonly used terms in Bayesian stats and in this case ``process'' often considers what you call ``interaction''.  There are some interesting to attempts to model co-evolution that consider similar ideas (i.e., a barrier to interaction and then trait-matching; but maybe outside of the scope of this MS). While I appreciate that your naming has merit, I think if your hope is that more ecologists use these methods then the terminology should be consistent across papers/approaches to the greatest extent possible.
		\end{refquote}


		\textbf{R:} We have revised this section of the introduction to both avoid introducing rigid terminology and make it clear that our model is not concerned with partitioning different sources of variation (indeed, we state that in many cases this is not possible using empirical data). Hopefully this will discourage readers from getting bogged down in trying to isolate which external factors cause which types of uncertainty (there is almost certainly overlap - e.g., bad weather could both reduce the probability that species will be active and interact and the probability that an interaction is observed if visibility is poor). We have also added a section (beginning line 117) referring to ``forbidden links'' which addresses overlap between the questions of whether species can interact (which we had previously called interaction uncertainty) and whether they do interact at a particular site (previously process uncertainty). We hope that this addition clarifies the agreement of our manuscript with previous works listing sources of uncertainty.


			\begin{quotation}
        \textbf{Forbidden links}

            Both whether species can ever interact and whether they interact at a particular place and time have been discussed in the context of ``forbidden links``~\citep{Jordano2016}. In this framework, all links which are prevented by spatio-temporal uncoupling, physiological constraints, etc. are considered ``structural zeros'' that cannot be observed~\citep{Jordano1987,Jordano2016}. We conceptually distinguish between physiological constraints and spatio-temporal uncoupling to allow for cases in which a species is introduced to a new habitat, expands its range, or shifts phenology~\citep{Gravel2013}. In such cases, links which are impossible due to physiological constraints remain forbidden but links previously ``forbidden'' by spatio-temporal mismatch could potentially occur. 
      \end{quotation}


	3. Introduction of the case study seems off-topic and illogical. 


		\begin{refquote}
		3.      The set up (introduction) to the case study is quite odd and somehow seems off topic – or at least not logical based on what the reader has read up to that point.
		\medskip
		Line 240.  I found the justification for the system a bit odd.  Is the goal to show the gaps in sampling or to apply the model described thus far to consider the 3 different types of uncertainty outlined?  At this point the reader is confused about the goal...
		\medskip
		Line 249.  The statement about training data is redundant with what is stated above – adjust writing.
		\end{refquote}


		\textbf{R:} We have expanded our introduction of the case study (beginning line 295) to make it clear that we are using the highest-quality empirical network we can find as even such networks have uncertainty about unobserved interactions. This relates back to our point that urging increased sampling effort is not likely to solve problems of uncertainty as long as sampling is limited in the number of methodologies that can be applied, biased towards abundant or easy-to-identify species, restricted to particular spatial sites and/or environmental conditions (if the network is intended to be more general), or all of the above. Given budgetary constraints, it is extremely likely that empirical ecologists cannot sample as intensively and extensively as they would like and therefore some uncertainty is likely to remain. We repeat this point in the discussion to ensure that the case study is relevant. We have also clarified our statement that a strict application of Bayesian statistics does not allow empirical priors, but that they are an option for researchers that are more concerned about matching their prior to their study system than with strict formalism (lines 296-293). As Reviewer 1 points out, this is somewhat controversial and we feel it is important to note the potential objection.


		\begin{quotation}
		  \subsection*{An empirical example}

		      To illustrate the process of constructing a Bayesian network to quantify uncertainty about interactions, we use the comprehensively-sampled system of willows (\emph{Salix}), herbivorous gallers, and their natural enemies described by~\citet{Kopelke2017}. This dataset consists of a single community type sampled across Europe over 29 years and at 374 unique locations. The meta-network consists of 1,173 different interactions between 52 \emph{Salix} nodes, 92 herbivore nodes, and 126 natural enemy nodes (see \emph{Appendix S5} for details). 
		      The high spatiotemporal resolution of this dataset make it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, there were many pairs of species which were rarely or never observed together and about which we therefore have high uncertainty about interaction probabilities (Fig. 2). Using the Bayesian framework above, we can identify which potential interactions are more and less uncertain, allowing us to better predict the true structure of the metaweb. 
		      % To show the gaps in sampling, we compared the frequencies of observed co-occurrences and interactions. 
		      We calculated an empirical prior and computed the posterior distribution of the probability of an as-yet-unobserved interaction being feasible ($\lambda_{ij}$). We analysed both the \emph{Salix}-galler and galler-natural enemy components of the network but, for brevity, present only the latter here (see~\emph{Appendix S6} for \emph{Salix}-galler results).
		\end{quotation}


	4. Misunderstanding of our point about sampling effort 


		\textbf{R:} We believe that the Reviewer has  misunderstood the point of our comments on sampling effort. Several of their comments suggest that they believe that we are advocating for reducing sampling effort. This is emphatically not the case. Rather, we assumed that field researchers already sample to the maximum extent possible given their time and resource constraints and so a call to ``sample more'' would not be helpful. Increased sampling can reduce some sources of uncertainty, but is unlikely to remove all uncertainty and so is not a complete solution. We now address this explicitly in an appendix (Appendix S2)  dedicated to the potential for sampling effort to reduce uncertainty about interactions. Below, we address the Reviewer's sampling-related comments one by one.


		\begin{refquote}
		Line 94.  I find this a very odd argument against sampling multiple times.  So, if you sample more you might see more then understand the system less?  The logic does not make sense to me. 
		\end{refquote}


		\textbf{R:} Of course sampling more does not lead to less understanding. It can, however, reveal knowledge gaps (as when a rare species is detected, revealing our ignorance of its interactions). This is not an argument against multiple sampling but a statement that increased sampling is likely to lead to the addition of more ``false zeros'' as species about which we know little are added to the network.


		\begin{refquote}
		Line 107.  There is a lot of literature in wildlife ecology emphasising the importance of repeat sampling for estimating detection probability.  Is this just wrong?  If so this does need more explanation in the context of this literature.
		\end{refquote}


		\textbf{R:} Here it seems that we have expressed ourselves poorly. Of course we are not against repeat sampling. This is, in fact, one of the core parts of our approach. Our point here is that some species (e.g., cryptic or difficult-to-identify species) and interactions (e.g., brief visits of pollinators to plants) are difficult to detect and may be missed even with multiple sampling. If a rare species is only detected in one sampling round, then the repeated sampling necessarily tells us little about its interactions. For species which are frequently detected, we absolutely learn about the detection probability of their interactions with repeated sampling. We have tried to clarify our intended meaning throughout the revised text.


		\begin{refquote}
		Line 130.  The ideas here are largely a repeat from those above.  Further, while it may be true that we can sample too much – I think it is dangerous to suggest we should sample less – do the authors think that sampling across most network studies is sufficient (the opposite is stated in the discussion)?  I wonder if the argument is a bit more statistical than biological.
		\end{refquote}


		\textbf{R:} We agree that it is dangerous to suggest that anyone sample less, and again we regret the confusion caused by our previous draft. We argue only that the amount of sampling required to be confident that co-occurring species do not interact is large -- likely beyond what is feasible for speciose systems given the limited resources available to many researchers. Sampling across most network studies is almost certainly not sufficient, but data which would allow readers to judge this (i.e., number of times each species is observed, independent of numbers of observed interactions) is not generally provided. Overall, we assume that those compiling empirical networks are sampling as much as possible given the constraints of their system and available resources. Infinite sampling would, of course, be the best option but it is unlikely that researchers will be able to perpetually increase sampling.


		\begin{refquote}
		Line 144.  I am much more comfortable with this statement than how sampling effort should be considered and I would suggest moving this up and then explaining how even if we sample well we need to consider uncertainty for the reasons you mention in the previous section.  Please note that you make the same point in your discussion on line 338.
		\end{refquote}


		\textbf{R:} We are pleased that this point was clear and have made sure to include it in our revision.


		\begin{refquote}
		Line 319.  It is clear that these are large samples but if interaction among co-occurring species was greater than you need lower samples – correct?  Should this be made clear?  Otherwise, we maybe can just never get enough data!
		\end{refquote}


		\textbf{R:} We are specifically speaking about interactions which were never observed. As interaction networks tend to be sparse, there will always be many of these. If interaction frequencies were higher among species that co-occurred, then we would have fewer unobserved interactions but the sample sizes needed to be confident that an unobserved interaction does not occur would not change (perhaps our threshold for deciding to believe a zero might, which is why we provide sample sizes for several thresholds). The Reviewer has hit the nail on the head with the idea that it is extremely hard to get enough data to be sure about every interaction. This is why prior knowledge can be so useful!


		\begin{refquote}
		Line 338 to 342.  Throughout I am confused if the authors suggest more sampling is good or bad...  At the end of the paragraph it seems it isn't so great to sample more because you end up with these annoying ``0'' values...??????
		\end{refquote}


		\textbf{R:} In our revised manuscript, we have collected our discussion of sampling into a dedicated appendix and added several explicit statements that high-quality sampling can reduce some sources of uncertainty. We hope that it is now clear that sampling is very important but cannot completely eliminate uncertainty (except perhaps in some very species-poor and unusually static systems, but these are certainly rare). As to adding more zeros than ones specifically, this is only ``bad'' in the sense that it gives us more high-uncertainty cells in the interaction matrix. We take the view that it is better to have ``known unknowns'' than ``unknown unknowns'' and it is certainly better to know about more of the species in a community than fewer, but finding a single individual of a rare species will not reduce uncertainty in the web. We have added a line in \emph{Appendix S2} specifically to address this.


		\begin{quotation}
			we will accumulate observations of co-occurrences faster than we will accumulate observations of interactions (Fig. 2C). While this improves our understanding of the set of species present in the community, it introduces yet more uncertainty into the interaction matrix. Note that it is better to identify the set of potential interactions than to miss a species, so sampling effort should not be reduced in order to exclude rare species.
		\end{quotation}


	5. Eliminate redundant ``because'' on line 23 


		\textbf{R:} Done.


	6. Reduce repetition of inevitable uncertainty 


		\begin{refquote}
		Line 73, 87.  Maybe the idea that some uncertainty is ``inevitable'' should not be repeated in multiple sections.  Either find a different way of saying it – or state it in your introductory paragraph and then don't keep repeating.
		\end{refquote}


		\textbf{R:} We have rephrased the manuscript and the word ``inevitable'' no longer appears. We hope that the current phrasing is less repetitive.


	7. Why not always model probabilities of co-occurrence?


		\begin{refquote}
		Line 142.  But shouldn't you model the probability of two species co-occurring?  The authors have a paper doing this.... Is that not a good idea?
		\end{refquote}


		\textbf{R:} Modelling the probability of co-occurrence is an option for many systems (e.g., aquatic food webs where ranges of fish species are fairly well-known, as in~\citet{Gravel2013}). It may also be possible to separate the probability of observing an interaction at a particular location into a metaweb component (the focus of the current manuscript) and a co-occurrence probability, as in~\citep{Gravel2018}. This addresses the question of interaction probabilities at specific locations, however, in contrast to our focus on metaweb interaction probabilities.


		In some systems, however, the factors affecting probabilities of co-occurrence may not be known. We therefore cannot suggest modelling co-occurrence as a panacea. Instead, we now emphasise that co-occurrence probabilities are one thing that could be included in a prior (section beginning line 231). 


		The fact remains that a lack of observed interactions between species which do not co-occur tells us nothing about whether these species \emph{could} interact if they should begin to co-occur (e.g., following a range shift). Following the Reviewer's suggestion, we have revised our manuscript to clarify our terminology. In particular, we have taken care to specify which level of uncertainty we are addressing at different points in the manuscript. We hope that this will remove some of the confusion about whether or not modelling different components of uncertainty/sampling more is a good idea. 


	8. Issue of testing hypotheses based on inputs into models 


		\begin{refquote}
		Line 121.  I think one of the reason non-Bayesians' are not comfortable with the approach is that if you put in prior information on something like trait matching and test for trait matching and then discover trait matching is important – what does it mean?  Maybe this is too obvious (I realise there are tons of papers on how to choose priors) but I wonder if it is worth explaining (would a box or something be worthwhile?  I leave it up to the authors/editor)?  Maybe the issue could be acknowledged and an appropriate paper cited?
		\end{refquote}


		\textbf{R:} Following suggestions by this Reviewer and another, we have substantially expanded our discussion of different options for priors (including the trait-based and co-occurrence models the Reviewer points out). We have also added an explicit statement that researchers wishing to test the influence of a particular trait (for example) should \emph{not} include that trait in their prior (lines 252-255). We hope that this statement, and the expanded discussion of different types of priors more generally, allay the Reviewer's concerns. 


		\begin{quotation}
			Also note that researchers wishing to test whether a particular trait influences interaction probabilities should either exclude that trait from their prior or model the network using priors which include and exclude the trait of interest (as in~\citet{Weinstein2017,Weinstein2017a}).
		\end{quotation}


	9. Redundancy in line 235


		\textbf{R:} The redundant line has been removed. Thank you for pointing this out.


	10. Unsure about the point of filtering networks 


		\begin{refquote}
		Line 295 to 302.  I would think that this second step (i.e., filtered networks) is to explore sampling not to determine how networks will be influenced by uncertainty?  Do you need the filtering step to evaluate uncertainty (as written it seems that this is the case)?
		\end{refquote}


		\textbf{R:} The filtering was intended to show how uncertainty likely warps our current understanding of network properties like connectance. If we do not observe 20-50\% of the interactions in a network, then many network properties in the published literature will be inaccurate. Even worse, networks compiled under different levels of uncertainty (e.g., species with more or less variable traits, or studies with multiple sampling methods versus only one) or with different sampling efforts will have network structure metrics that are inaccurate to different degrees. Filtering networks in the way that we do could give an idea of how many networks are missing, but we do not think it is necessary to evaluate uncertainty (we believe that examining the posterior distributions directly is a better approach there). Due to length restrictions, we have moved this analysis to an appendix (\emph{Appendix S10}) and have rephrased these lines to emphasise that the filtered networks are intended to demonstrate the consequences of uncertainty more than anything else.


		\begin{quotation}
			Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. 
		\end{quotation}


	11. Scepticism about sampling requirements to be sure interactions do not occur 


		\begin{refquote}
		Line 361.  I find the statement that 30-50 individuals need to be evaluated a bit strong.  This statement is based on this study – are all systems like the gall system?  If species are specialised or bound to interact for some other reason (i.e., co-occurring when there are few other resources) wouldn't you need to observe fewer individuals?  The point of the method is that you can estimate how many individuals are needed.... This is great!  But given that this can be estimated from any given system why give a value from one system and state that is what is required?  It defeats the point of the very nice method proposed...??
		\end{refquote}


		\textbf{R:} The point of our method is not actually to quantify the amount of sampling needed. Although the ideal sampling effort \emph{can} be calculated using the framework we put forward (as we demonstrate), the real point is to quantify how uncertain we are that an interaction we do not observe really does not occur. Given this, we do not think that recommending uncertainty be explicitly stated undermines our point. 


		The Reviewer's suggestion that we might need fewer samples for species that are ``specialised or bound to interact for some other reason'' reflects a very strong prior. In this case, yes we would need fewer samples for the species concerned. With sufficiently strong priors, it is not necessary to sample at all! For example, in most food webs it is assumed that basal resources will never consume prey even if a given resource and a given animal are never observed co-occurring and it is generally accepted that there is very low uncertainty about these zeros. In many cases, the assumptions involved in excluding interactions are less clear-cut and different researchers may disagree about which species are ``bound to interact'' (or not to interact). The concept of pollination syndromes is one example - many flower visitors are less rigidly specialised on particular flower types than initially thought~\citep{Ollerton2009}. To address such ``forbidden links``, we now suggest that researchers explicitly state both the uncertainty about data-based zeros and the assumptions by which they create structural zeros. This will allow future researchers to evaluate the uncertainty about all interactions in a network as the state of expert knowledge changes. We hope that this expanded recommendation (lines XX-XX) is clearer.


		Finally, we emphasise that the estimate of 30-50 samples does not refer to the \emph{Salix}-galler-natural enemy test system but to a much more general interpretation of the problem. Without a prior distribution and with \emph{no prior information}, as long as we assume that interaction probabilities follow a beta distribution it will take 30-50 observations of two species co-occurring to be 95-99\% confident that the species do not interact. Sampling requirements will be much less if an interaction was observed (note that in the empirical example we assume an interaction was feasible if it was observed even once).


\clearpage

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#4}
% ---------------------------------------


	The Reviewer has ``been surprised how little that sampling effects have been formally considered in the analysis of networks'' and therefore feels that our manuscript makes an important contribution. Nevertheless, the Reviewer has concerns that the manuscript might not reach empirical ecologists ``because they either would not understand its relevance or would not be able to apply it practically``. We agree with the Reviewer that this would be a great shame, and appreciate their suggestions to improve the manuscript. With this revision, we hope that we have established the relevance of our method and offered enough of an explanation that empiricists will be able to apply it. Our goal is to increase access to a statistical technique which we see as complementary to high-quality field work, and we believe that the Reviewer's comments will help us to achieve this. We respond (preceded by \textbf{R:}) to each of the Reviewer's comments in detail below.


	1. Paper is poorly structured

		\begin{refquote}
		However, I felt that the structuring of the paper made it a challenge to understand and apply. It felt like the paper itself had been written in different sections (by different authors?) with not enough links between the sections. I also felt that there was a strong theoretical component, which is important, but there needed to be a stronger link with the issues around empirical ecology, as explained below.
		\end{refquote}


		\textbf{R:} We have revised the manuscript with an eye to clarifying the flow between sections. We hope that it is now clear that our proposed framework is designed to use Bayesian theory to complement empirical networks and empiricists' detailed knowledge of their systems. 


	2. Add more citations


		\begin{refquote}
		Introduction – T. Poisot and colleagues have done a lot of relevant work in this area, but I felt there was undue reference to their work in comparison with other relevant work. There were some obvious papers (e.g. sampling by Jordano, forbidden links by various others) that were not cited. A broader perspective on the literature would, I think, help the authors appreciate the value of their paper and the need to ensure that it is fully understandable and of practical use.
		\end{refquote}


		\textbf{R:} All of the Reviewers were unhappy with our treatment of the literature, and we have now done our best to improve on this, bearing in mind the strict word limit of MEE and the fact that it was never our goal to conduct a comprehensive review. We have cited additional literature as recommended by Reviewer 1, including a paper by Jordano. If the Reviewer has any suggestions of specific papers that they feel are missing, we would be happy to consider them as well. Note, however, that we do not intend our manuscript to be a complete review of the literature surrounding interaction probabilities. We hope that the citations we have added appear more balanced to the Reviewer.


	3. Comment on weighted metrics


		\begin{refquote}
		L36ff The authors should note the value of weighted metrics in taking account of sampling biases.
		\end{refquote}


		\textbf{R:} We do not see how weighted metrics (which we infer mean metrics including interaction strength/frequencies based on the Reviewer's comment below) account for sampling biases. It seems to us that measures of interaction strength should be \emph{more} susceptible to sampling biases, not less, as abundant species are both more likely to have their interactions recorded and more likely to have these interactions recorded as strong/frequent. Of course weighted metrics have many other strengths, but these are not germane to the topic at hand. We have rephrased the introduction so that the original line 36 no longer appears, and hope that this will remove the Reviewer's objection.


		Applying our framework to quantitative networks is beyond the scope of the current study due to length restrictions. It is, however, an interesting question worthy of future consideration. With quantitative interactions, the problem of true and false zeros disappears. However, there will now be a great deal of uncertainty about the observed interactions as we must now estimate variability in interaction frequencies. There is a significant trade-off here, and whether quantitative or qualitative networks are better-suited to acknowledging uncertainty in species interactions remains a very open question.


	4. Request for extension to weighted networks


		\begin{refquote}
		L45 It is a shame not to give some idea of how the method could be extended (or is this the intention of the authors?). For empirical analysis of networks it is rare to use binary networks given the value of weighted networks for taking account of sampling biases. Indeed, I am much less concerned about whether an interaction never occurs, and much more concerned with the frequency of occurrence.
		\end{refquote}


		\textbf{R:} As stated above, we do not agree that weighted networks reduce sampling biases. Moreover, we disagree that it is rare to use binary networks as most food webs (for example) are still binary. It takes an even greater sampling effort to quantify interaction strengths than the presence and absence of links, so for species-rich systems in particular there simply are not many high-quality weighted networks published. Moreover, as the Reviewer mentioned, empirical ecologists may already struggle to apply a Bayesian framework using qualitative data. We therefore opted not to extend our framework in this manuscript and leave this as an area for future work.


	5. Description of causes of uncertainty poorly integrated with the case study


		\begin{refquote}
		L50 This is a nice and clearly explained description of the problem that many network ecologists ignore, or are unaware of.
		Section from L50. This section is valuable, but had very weak links with the empirical analysis later in the paper. For instance in the example of the gall-formers, there was not formal discussion about the different sources of uncertainty. 
		\end{refquote}


		\textbf{R:} As we state in the section \textbf{Estimating uncertainty}, we usually cannot distinguish different sources of uncertainty in empirical data. Those studies which attempt to do so (e.g.,~\citet{Graham2018}) remove process uncertainty by assuming constant interaction probabilities during a short, intense sampling period and also assume that we know the true set of feasible interactions. This may be the case for Graham and Weinstein's relatively small and well-studied system but is not likely to be true for systems containing hundreds of species, systems containing recently-arrived species, systems just beginning to be studied, etc. A more generally-applicable approach is to test explicitly whether species always interact when co-occurring, whether interaction probability depends on the probability of co-occurrence, and whether both co-occurrence and interaction probabilities depend upon environmental conditions, as in~\citet{Gravel2018}. Note, however, that this study refers to the probability of an interaction occurring in a local realisation of a food web while we are concerned with metawebs in the present study.
		

		To make this clearer, we have rephrased this section and added a line (lines 61-68) stating that we usually cannot determine the cause of all the zeros in an interaction matrix (we can identify obviously unfeasible interactions, but likely cannot say whether a zero for a rare species is because we did not observe enough individuals, there were not enough individuals to perform a particular interaction, or because the interaction is actually unfeasible). We hope that this revision makes it clearer that the description of different sources of uncertainty is a conceptual guide only.


		\begin{quotation}
			While an observed link definitely occurred (assuming correct identification of the species involved), a given link may not be observed for many reasons, \emph{whether or not it truly occurred} (Fig. 1). Moreover, given an unobserved interaction in an empirical dataset, we often cannot determine why the interaction was not observed \emph{post hoc}. The detection of any interaction is a stochastic process subject to many levels of uncertainty. As a conceptual guide, we describe three nested levels of uncertainty that roughly address the questions: ``Could species $i$ and $j$ interact?", ``Did they interact during sampling?", and ``Did we observe the interaction?"
		\end{quotation}


	6. Process uncertainty poorly defined.

		\begin{refquote}
		L76ff `Process uncertainty' is not defined. The simplistic example of interaction uncertainty (fish eating a cactus) does not help the reader understand the detail of what is meant by `interaction uncertainty'. The two examples of `local constraints' (weather and habitat) are operating on completely different temporal scales (note – it is defined differently in L109). I would regard the issue of weather as much closer to detection uncertainty (e.g. for a pollinator, it would be likely to be interacting if the weather was better), whereas the issue of habitat is closer to the authors' `interaction uncertainty' (the species don't interact because they are not, or never, co-occurring in a habitat). Also if the species occur in different habitats then with an appropriate spatial scale of sampling then they do not co-occur – so the issue seems redundant. I suspect that the authors are thinking of a meta- or master network in much of their study, but this is not clear (or I have misunderstood and it needs to be explained better), i.e. the predicted presence of an interaction is not the presence of an interaction at the local site (taking detection and process uncertainty into account) but the ability to assess `interaction uncertainty'.
		\end{refquote}


		\textbf{R:} As our manuscript is not concerned with partitioning sources of uncertainty, we felt it was unproductive to get bogged down in a debate over the precise definitions of process vs. interaction uncertainty and which external influences might contribute to which sources (there is enough overlap that simple statements such as ``bad weather increases process uncertainty'' are, at best, incomplete). To remove this problem, we have rephrased the introduction and discussion to refer to the questions of whether two species \emph{can} interact under ideal conditions and whether they \emph{do} interact at a given site and time. We hope that this reframing, and the addition of clear statements that our framework is not intended to separate different sources of uncertainty, will remove the Reviewer's confusion.


		Our mention of habitat as a factor affecting the probability of species interacting at a site was not intended to refer to species using different habitats, but rather the possibility that habitat type might affect interaction probabilities. For example, a more open patch of forest might have different interaction probabilities than a denser patch even if the same set of species use both patches. The Reviewer is clearly correct that habitat also affects which species are present at a site. We included co-occurrence in process uncertainty since co-occurrence does not tell us much about whether an interaction is feasible under ideal conditions (which would certainly include co-occurrence). This speaks to our point above that external factors (habitat, weather, etc.) can affect multiple levels of uncertainty at once. In fact, habitat also likely affects detection uncertainty since it is often harder to observe interactions in dense vegetation. So, in short, separating sources of uncertainty based on the external factors which contribute to them is not a particularly useful endeavour and we have revised the manuscript to steer readers away from it.


	7. Point about temporal scales of interaction


		\begin{refquote}
		L76ff Different interactions occur at different temporal scales, so it is important to consider where the role of this study lies. For instance, a pollinator-flower interaction is quick (and even the evidence of it, e.g. pollen on the insect, is not long-lasting) whereas an active gall-former interaction could be present for a couple of months and could be detected for even longer (on senescing leaves).
		\end{refquote}


		\textbf{R:} Long-term interactions may be easier to detect, but this does not necessarily translate into reduced process uncertainty. Spatial variation in interaction probabilities will affect all interaction types, as does variation in abundances between years, so we cannot conceive of any interactions that are exempt from this issue. The timescale of an interaction (and the evidence it leaves) does affect detection uncertainty, so we have added a note in that section (lines 137-140). Long-term interactions may still fail to be detected, however, and we now add an example to make it clear that detection uncertainty applies to even long-term interactions such as gall-forming (indeed, our results suggest that uncertainty in gall-forming is quite high). 


		Perhaps more important is the effect of sampling interval. As sampling time increases toward infinity, interaction probabilities should converge to 0 or 1 with no uncertainty. As we discuss, however, sampling times are limited by resources, the trade-off between sampling a single site intensively versus many sites, etc. Any interaction could therefore occur outside of the sampling window and hence be missed.


		Lines 137-140:


		\begin{quotation}
			The probability of detecting an interaction will also depend on the duration of the interaction and its evidence, the species involved, and the individuals sampled~\citep{Wells2013,Lagrue2015,Cirtwill2016,Weinstein2017}. 
		\end{quotation}

	8. Confusion about goal of modelling


		\begin{refquote}
		I was struggling to really understand what the authors were really trying to model (partly because of the lack of a link between the theoretical and empirical parts of the paper). Are the authors trying to estimate L (the probability that an interaction is feasible or not – I would describe this as a `master' or meta- network), or is it that they are trying to estimate X|L (the probability that the interaction locally occurs)? I would be interested in both, but the second aspect seemed to be ignored in the gall-former example.
		\end{refquote}


		\textbf{R:} In the case study, we are modelling L (the probability that an interaction is feasible). We do not have quantitative data within sites in our dataset, so we cannot isolate the probability of detecting an interaction at a site from the probability that the interaction occurs. This is also the probability we were most interested in. We do note, however, that one could also model X|L using the same framework if there were independent counts of co-occurrences and interactions within a single site. \citet{Gravel2018} does just this. We now state throughout the manuscript that we are interested in compiling the metaweb, the set of interaction which can feasibly occur. We hope that our goal is now crystal clear.


	9. Misunderstanding of how biased sampling does not solve problems of uncertainty


		\begin{refquote}
		L136 This is a completely different issue, that you do not address in the paper.
		\end{refquote}


		\textbf{R:} We do not believe that biased sampling is a completely different issue as the tendency for some interactions to be sampled more easily than others clearly contributes to varying levels of detection uncertainty. Increasing sampling effort will not do much good if we repeatedly sample the same common interactions and very rarely identify any new interactions. We now address questions about whether or not sampling more will remove uncertainty in a dedicated appendix (\emph{Appendix S2}). We still mention the fact that increased sampling will not reduce uncertainty evenly across interactions as this is an important point to consider when designing sampling protocols and when analysing empirical data. We also point out that combining sampling types is a partial solution to this problem; if different sampling methods have different biases, they may partially cancel each other out. We believe that this addresses the question as much as possible given our focus on analysing collected data rather than collecting new data.


	10. Explain Bayesian approach more simply


		\begin{refquote}
		L147 Your Bayesian approach seems important, especially the prior information, and I would have appreciated it being explained more simply.
		\end{refquote}


		\textbf{R:} We have expanded our description of different types of priors and when researchers might prefer one over another. Following a comment from Reviewer 1 we have removed much of the mathematical background for the Bayesian approach, but this material is still present in the supplemental material. We hope that this simplifies the approach adequately.


	11. Integrate L155ff with previous section


		\begin{refquote}
		L155ff I think it would be helpful for this section to be integrated with the previous section. It relies on the reader putting quite a lot of work in to understand the link between the two.
		\end{refquote}


		\textbf{R:} We have removed much of the introductory text explaining which quantity we are most interested in ($\lambda$) and now more explicitly state our goals at the end of the introduction. We hope that the transition to the methods is now less work for a reader.


	12. Ideas presented in L209, L262, L310 are important but explained too briefly


		\begin{refquote}
		L209ff This seems a really important set of ideas, but they are exemplified very briefly and very simplistically in the paper (L262, L310). I would have appreciated a much clearer explanation and example.
		\end{refquote}


		\textbf{R:} We are not quite sure what the Reviewer is asking here. $\alpha$ and $\beta$ truly are quite simple (as simple as the mean and standard deviation of a normal distribution) so there is not much more to say about them in themselves. We have expanded our discussion of different types of priors and how they may be obtained, and we hope that this clarifies matters for the Reviewer. We also note that a simple worked example, with accompanying R code, is provided in \emph{Appendix S4} so that readers can see exactly how to obtain $\alpha$ and $\beta$. In case the point of confusion is the idea that $\alpha$ and $\beta$ can be specified or derived depending on the type of prior desired, we have added a line (lines 181-185) spelling this out.


		\begin{quotation}
			The shape parameters, or hyperparameters, may be set to particular values or derived from some data (see below). They may be set to the same values for all interactions, allowed to vary independently for all interactions, or incorporate non-independence between interactions (e.g., when the shape of the prior distribution depends upon species' abundances or traits). 
			\end{quotation}


	13. Reframe line 241 in terms of solutions rather than difficulties


		\begin{refquote}
		L241 I wonder if you could phrase this more positively as `solutions' rather than just `difficulties'?
		\end{refquote}


		\textbf{R:} We appreciate the Reviewer's desire for optimism, but we also selected a high-quality dataset specifically in order to demonstrate that empirically sampling all of the feasible interactions in a system is very unlikely. A lower-quality dataset would work just as well with our framework but would not highlight these difficulties so well. We have therefore kept this line as-is but have expanded the paragraph (301-307) to show how the Bayesian framework provides a partial solution to the problems inherent in even high-quality empirical data.


		\begin{quotation}
		 The high spatiotemporal resolution of this dataset makes it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, there were many pairs of species which were rarely or never observed together and about which we therefore have high uncertainty about interaction probabilities (Fig. 2). Using the Bayesian framework above, we can identify which potential interactions are more and less uncertain, allowing us to better predict the true structure of the metaweb. 
		 \end{quotation}


	14. Line 283 seems to be a very important point and should be explained more clearly


		\textbf{R:} Due to space constraints, we have refrained from adding an extensive description of Jensen's inequality here, but are confident that readers can find a fuller description in the online literature if they choose.


	15. Line 291: does assuming probability of 1 for observed interactions introduce bias?


		\begin{refquote}
		L291 I have wondered about this – does assuming a probability of 1 for observed interactions create a bias? The observed interactions are a stochastic set of the possible interactions, so by treating observed interactions as 1 and other (equally likely?) unobserved interactions as \textless1 will surely bias the network metrics. I'm not sure of the solution and would welcome thoughts on this in the paper.
		\end{refquote}


		\textbf{R:} As we are concerned with the metaweb (the set of feasible interactions) rather than the interactions which occur at a given site on a given day, we do not think that assuming a probability of 1 for observed interactions introduces bias in our study. We have added a justification of setting the probability of observed interactions to 1 in \emph{Appendix S3}. Note that each posterior web is a prediction of the true metaweb and not a local realisation of some interactions drawn from the feasible set. These local webs are more akin to our ``filtered webs'' in which observed interactions are not guaranteed to appear. 


		One interesting point is whether systems with a large risk of false positives (e.g., pollination networks which assume all flower visitors provide pollination service) would be biased by assuming all observed interactions are truly feasible. Assuming that all interactions which are known to be feasible actually occur at each site would also introduce bias - I suspect that this is what the Reviewer may be thinking of. As described above, our study cannot isolate $\chi$ (the probability that a feasible interaction occurs at a particular site), so this is not a relevant question for the present work. Future studies with much, much more detailed data may be able to shed light on this.


		We suspect, however, that the Reviewer may be thinking of weighted networks where interaction frequencies of feasible (occurring somewhere in the metaweb) interactions vary. In this case, the probability of an interaction will almost never be 1 as an interaction which occurred 10 times in 10 observed co-occurrences might not occur at an 11th observation. As discussed above, this is an interesting avenue for future extensions but beyond the scope of the present manuscript.


	16. Filtering seems arbitrary 

		\begin{refquote}
		L298 These seem arbitrary. It is not clear what is filtered, or its justification – is it the unique interactions, unique interaction per site or samples? How do these compare to typical sampling effort?
		\end{refquote}


		\textbf{R:} We have rephrased our description (in \emph{Appendix S10}) to make it clearer that the filtered networks are intended to demonstrate how network structure changes as uncertainty increases (and we miss more interactions). As stated, we filtered networks created using the posterior distributions. There are therefore no sites or samples in question here. We are simply retaining a random 90\%-10\% of the interactions (or removing a random 10\%-90\%; these are equivalent) of the interactions in the ``true'' (posterior) network. We hope that this rephrasing is clearer. 


			\begin{quotation}
				Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. Taking a posterior network as the ``true'' network, we randomly sampled 90\%, 80\%, 70\%, 60\%, 50\%, 40\%, 30\%, 20\%, and 10\% of the interactions to create a new ``filtered'' network.
			\end{quotation}


		Note that our model is not concerned with partitioning different sources of variation; the filtering levels we present therefore represent uncertainty from all sources. As such, comparing them directly to ``typical sampling effort'' would be an apples-to-oranges comparison. We do note that~\citet{Weinstein2017a} found a detectability of 23.3\% for interactions despite high sampling effort,~\citet{Jordano2016} found that about half of unobserved interactions did not qualify as ``forbidden links``, and~\citet{Bartomeus2013} found that 59\% of interactions were detected. We therefore do not think that the range of filtering levels we applied were particularly unreasonable (although we note that none of the above studies refer to plant-galler networks). That said, the Reviewer is correct that the values we chose were absolutely arbitrary. To make this clear, we now filter in 10\% increments from 90\% to 10\% to illustrate a broader range of uncertainty.


	17. Expand discussion of results on line 321 


		\begin{refquote}
		L321 This is a really important and interesting set of results that are worthy of greater discussion. The issue of metrics from sampled networks is important, but gets lost in the paper. Please expand upon this.
		\end{refquote}


		\textbf{R:} Ultimately, length restrictions meant that we were obliged to remove our discussion of network metrics to an appendix (\emph{Appendix S10}). After adding the additional material requested by Reviewers in the methods, there simply was not space to discuss the network-level metrics in the main manuscript. We agree with the Reviewer that this is an extremely important question, but feel that it is essential to provide a clear and useable explanation of the basic Bayesian framework in the present manuscript. We hope to return to the question of how network metrics are impacted by sampling issues in more detail in future work.


\clearpage

    \bibliographystyle{ecol_let} 
    \bibliography{manual} % Abbreviate journal titles.



\end{document}