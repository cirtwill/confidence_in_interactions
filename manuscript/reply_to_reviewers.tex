\documentclass[12pt]{letter}

\usepackage[britdate]{LiU-letter}
\usepackage{times}
\usepackage{letterbib}
\usepackage{geometry}
\usepackage[round]{natbib}
\usepackage{graphicx}
\geometry{a4paper}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage[running]{lineno}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}

%\usepackage{natbib}
% \bibpunct[; ]{(}{)}{;}{a}{,}{;}

\newenvironment{refquote}{\bigskip \begin{it}}{\end{it}\smallskip}

\newenvironment{figure}{}


\begin{document}



\newpage

\setcounter{page}{1}


% Changes: reducing discussion of different sources of uncertainty, increasing description of priors, added a bunch of refs, trying to frame our study more clearly. Changed filtering to reflect all uncertainty, not just detection (more accurate, hopefully less confusing). No box needed, just "Why sample" section.


% Ask for help: how would we expand this to interaction frequencies? Still with the Bernoulli? Worthwhile to add a demo of Jensen's inequality?
% To do: expand discussion of our results as much as possible given space constraints.
% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
{\Large \bf Reply to Associate Editor}
% ---------------------------------------


	\begin{refquote}
	Your manuscript has been assessed by four different referees who agree that you touch upon a very important problem. However, they all feel your manuscript needs substantial improvements. They provide excellent advise on how to revise your manuscript and you should carefully consider all their comments. Overall, you do not acknowledge important past contributions and do not clearly explain the importance of the methodological issues you cover in your study. Importantly, referee 1 feels the real novelty of your study is the consideration of the importance and complexity of choosing prior information in constructing networks. Obviously, this is an issue in the context of Bayesian approaches, which are not necessarily well understood by empiricists, precisely the audience your manuscript should address. Please, follow very closely the suggestions of the referees when revising your manuscript.

	\end{refquote}

	\textbf{R:} We appreciate the thoughtful feedback by the four referees. We take particular note of the comments regarding the structure and grounding of our introduction and have worked to address them. 


	Reviewer 2 takes a different view of the purpose and scope of the manuscript from that of the other reviewers. We respect his/her ideas but feel that some are beyond the scope of the present manuscript. In particular, we do not feel that a full simulation study is necessary given the simplicity of our framework. We emphasize that we are not introducing a software package (although we do provide simple code to aid those who are new to the field), nor are we introducing an entirely new framework (as the other Reviewers point out, many components of our approach have been touched on by previous work). Thus, the novelty and impact of our work explicitly lies in connecting a Bayesian statistical approach to the problem of limited and uneven sampling of networks (driven by difference in species abundances, detectabilities, constrained time and budgets, etc.) and, we hope, in making this method more accessible to those without extensive statistical or modelling experience. Please note that Reviewer 3 identified this need explicitly. 
	% Tomas has a line break here, I'm not sure.
	Because of the difference between Reviewer 2 and the other Reviewers, we have opted to prioritise the majority view and focused first on comments by Reviewers 1, 3, and 4. However, we hope and trust that, in the course of these revisions, we have at least partially addressed Reviewer 2's concerns as well. 


	As a key point of departure for our revision, we have taken Reviewer 1's suggestion that we expand upon the different types of priors available and reasons for choosing one over the other. We also now offer a brief discussion about concerns over the subjectivity of prior selection. We argue that a great deal of subjectivity is baked into the compilation of empirical networks and that a Bayesian approach can be seen as making this subjectivity explicit. We hope that this will encourage empiricists to explicitly use their system-specific knowledge to create reasonable priors, as likely already occurs subconsciously (as in the designation of "forbidden links"). 


	Overall, we hope that our revision more clearly frames the importance of uncertainty in ecological networks and positions a simple Bayesian approach as a partial solution (together with high-quality sampling, of course). 
	We have also added many references to prior work. While the present study is not intended to be a full review of the literature, we certainly do not wish to downplay other workers in the area.
	Finally, several of the Reviewers appeared to believe that we were advocating for reduced sampling effort. That is emphatically not the case (we find the idea absurd), and we have revised the manuscript to be clearer about the fact that increased sampling effort can reduce some sources of uncertainty. We hope that it is now clear that the Bayesian framework we promote is a complement to high sampling effort.


	Once again, we thank the Associate Editor and Reviewers for their comments and hope that our revised manuscript will satisfy their concerns.

\newpage


% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Reviewer \#1}
% ---------------------------------------
Preamble.

	1. Suggestion to refocus on prior selection

		\begin{refquote}
			Below I offer my thoughts on this well-written manuscript. Normally I condense my review into a few key points, but I found myself uncharacteristically divided with the paper as presented. At first, the introduction covers ground very well-trod by prior works and doesn’t really address its contribution. I was mostly frustrated by the rehashing of topics made by many previous papers, include many by the authors themselves. But then the paper seems to morph and pick up steam on L248. Rather than reaching towards an amorphous and grandiose “quantitative framework”, the authors briefly zoom into a very concise, and hugely important, question of choosing prior distributions for harnessing information among networks. This has been completely unexplored and merits attention. In ecology more broadly, priors are treated with timidity, as if we couldn’t dare to leverage past work on our current understanding. Personally, I have always felt limited by this standard. I applaud the authors for taking on this challenge, and I would like to see an introduction that merits and debates this question in much more detail. When should we use prior information? How do we go about constructing informed priors for networks? When can we use priors from the data in question? This is sometimes called approximate bayes (http://andrewgelman.com/2016/03/25/28321/), or empirical bayes, perhaps alluded to in the title, but not fully explained in the introduction. Should empirical priors be drawn from hyperpriors or fixed for each interaction? Can we combine qualitative information and quantitative information? This is all exciting ground that will open up new avenues for networks. Walking the reader through flat priors, informed priors and empirical priors is crucial for the importance of analysis to be understood by the reader. The use of empirical priors can be quite controversial, and should be atleast touched on in the discussion. \\
			I’ve left my comments below on the introduction, but in my opinion, it should be almost wholly rewritten in favor of a more targeted question constructing networks using priors, which is the key novelty of the work and is mostly hidden by the current introduction. I’m not convinced any new analysis needs to be done, which speaks to the conflict between the current introduction and the actual data presented. I see the makings of a really nice paper here, and I’m confident the authors will be able to achieve this text revision.


			At the same time, the paper is clear and very readable. I wholly support the method and I think it is something critical that needs to be adopted by the community. \\
			Having read the paper several times, I think that the authors are trying to cast their net too widely, even starting from the title. From that perspective, they don’t meet the expectation of new insight. However!! I was extremely interested in the brief discussion on using prior knowledge, especially the delicacy of trying to transfer information among networks (L248). My recommendation is to drastically reduce the grandiose attempt at a “quantitative framework for networks” (L1 – L246) and really zoom in on the contribution of transferring information among networks through informed priors.	Again L278, this is very well covered in concept by recent papers in MEE that include the authors of this work, as well as several by Weinstein, Bartomeus and others.
			\end{refquote}


		\textbf{R:} We thank the Reviewer for his/her positive evaluation, and have done our utmost to reframe and tighten the introduction and framing of the paper. In doing so, we have happily adopted the suggestion to expand our discussion of prior selection, particularly with regard to approximate/empirical Bayes. Although we are somewhat space-limited, we have expanded our description of the different priors available and why a researcher might choose one over another (section beginning with line 245). We also touch upon the controversy over using empirical priors (lines 340-345) although we were unable to find many references addressing this in detail. We hope that this expanded description will be a better guide for empiricists who may not be familiar with Bayesian statistics.


		In implementing the Reviewer's comments on our introduction, we believe that most readers who are less familiar with Bayesian procedures will need a quick outline of the problem of uncertain detection of interactions in order to be motivated to dive into the larger discussion of priors. We stress that our intended target audience is empirical ecologists working on network description who likely have a different skillset than that of the Reviewer. We also note that Reviewer 2 found that \emph{``The introduction is particularly pleasant to read and the problem is well stated"}, praise which we would hate to loose. Therefore we have revised and streamlined our introduction but still refrain from jumping straight into prior selection. We have, however, taken care to introduce our analysis as a worked example (lines 347) and hope that this helps to reduce the conflict between the introduction and our data. 


		Overall, we thank the Reviewer for their compliments and accept their suggestion that we are somewhat overexcited about our approach. Thus, we have refined the introduction to be more specific about the problem we are attempting to solve. We have also expanded our treatment of prior selection and hope that our paper now reads as achieving its goal.


	2. Suggestion to add more literature

		\begin{refquote}
		The introduction flows well and is thoughtfully laid out. Given the enormous amount of literature in the field, it is not possible to provide a full set of citations. However, it seems remiss to not consider Jordano (2016) in the sampling section.
		\end{refquote}

		\textbf{R:} We thank the Reviewer for their compliments to our introduction and for the literature recommendations. We have incorporated these references as suggested (including Jordano, 2016 in the sampling section). Following comments from other reviewers, we have refined and slightly restructured our introduction in the hope of more clearly establishing the goal of our manuscript. We hope that this revised introduction will also meet with the Reviewer's approval. 


	3. Suggestion to de-emphasize MLE estimate and get straight to Bayes

		\begin{refquote}
		It’s a bit confusing to lead the reader towards a Bayesian analysis, and then immediately start with the MLE estimate. Why is this needed at all? (L162-186). Just start at 187?
		\end{refquote}

		\textbf{R:} The MLE estimate is part of the Bayesian framework as it dictates the shape of the distribution that we use. We now introduce the MLE formally within this context (lines 229-231) and take care to be explicit when using it to explore the sample size needed in the absence of prior knowledge later (caption of Figure 3).

		Lines 229-231:

		\begin{quotation}
			The basis of a Bayesian approach to modelling the probability that an interaction occurs ($\lambda$) is combining the maximum likelihood estimate (MLE) of $\lambda$ with a prior distribution (described in the next section) and a normalising function. The MLE of $\lambda$ can be modelled as a Bernoulli trial based on the number of observed interactions $k$ and observed co-occurrances $n$: $\lambda = \frac{k}{n}$. The most appropriate prior distribution for a probability such as $\lambda$ is the beta distribution:
		\end{quotation}

		Caption of figure 3:

		\begin{quotation}
			The number of observed co-occurrences needed to believe that an unobserved interaction cannot occur is very high (about 35; Fig. 3), and most datasets will not include this level of sampling for all pairs of species~\citep{Bartomeus2013}.
		\end{quotation}


	4. Suggestion to remove moments of the beta distribution

		\begin{refquote}
		I think a bit of space is wasted on defining the moments of the beta distribution. This is very googleable, and almost too thorough. I think the space is better utilized aligning the ecological challenge and the quantitative method.
		\end{refquote}

		\textbf{R:} While we feel that a short introduction to the beta distribution is important to bring researchers new to Bayesian statistics up to speed (and give them some keywords to Google), we accept the Reviewer's suggestion to reduce the amount of space given to the beta. We have therefore moved the description of basic properties to Appendix S2. The remaining paragraph introducing the beta distribution now leads directly into the section describing prior selection.


	5. Novelty of the study not clear in current framing

		\begin{refquote}
		I’m wrestling with the novelty of the work as presented and whether it reaches the standard for publication at MEE. Certainly, much of this logic is laid out in other works. The authors are well aware of this and have made significant contributions to this topic in the last few years. In particular, the authors should try to be much more explicit about the contribution they hope to offer that hasn’t been covered. ...
		While it is true that none of the [suggested] papers do the exact same thing as this manuscript, they all	orbit the same topic. 
		\end{refquote}


		\textbf{R:} We thank the Reviewer for the literature suggestions and now include them in our introduction and/or discussion. We emphasize the board applicability of our approach across network types and systems with varying degrees of prior knowledge. We also emphasize that our approach is not restricted to species observed X times (as many predictive models are) and can include species not yet observed at a site (e.g., potential invaders). We hope that the contribution our manuscript makes is now clearer.


	6. Potential contradiction 

		\begin{refquote}
		L89 for example, seems to conflict with the two paragraphs immediately following it?
		\end{refquote}


		\textbf{R:} We now address questions of sampling in the subsection \textbf{Why can't we sample more?}. We hope that this revision makes it clear that sampling should be as high-quality as possible but that sampling is unlikely to completely remove uncertainty.


	% 	Literature suggestions:
		% Jordano, P. (2016). Sampling networks of ecological interactions. Functional Ecology, 30(12), 1883–1893. doi:10.1111/1365-2435.12763
		% Bartomeus, I. (2013). Understanding Linkage Rules in Plant-Pollinator Networks by Using Hierarchical Models That Incorporate Pollinator Detectability and Plant Traits. PLoS ONE, 8(7), 1–9. doi:10.1371/journal.pone.0069200
		% Poisot, T., Cirtwill, A. R., Cazelles, K., Gravel, D., Fortin, M.-J., & Stouffer, D. B. (2016). The structure of probabilistic networks. Methods in Ecology and Evolution, 7(3), 303–312. doi:10.1111/2041-210X.12468
		% Poisot, T., Stouffer, D. B., & Gravel, D. (2015). Beyond species: why ecological interaction networks vary through space and time. Oikos, 124(3), 243–251. doi:10.1111/oik.01719
		% Graham, C. H., & Weinstein, B. G. (2018). Towards a predictive model of species interaction beta diversity. Ecology Letters. doi:10.1111/ele.13084
		% Gravel, D., Poisot, T., Albouy, C., Velez, L., & Mouillot, D. (2013). Inferring food web structure from predator-prey body size relationships. Methods in Ecology and Evolution, 4(11), 1083–1090. doi:10.1111/2041-210X.12103
		% Wells, K., & O’Hara, R. B. (2013). Species interactions: Estimating per-individual interaction strength and covariates before simplifying data into per-species ecological networks. Methods in Ecology and Evolution, 4(1), 1–8. doi:10.1111/j.2041-210x.2012.00249.x


\clearpage


% ----------------------------------------------------------------------
% ---------------------------------------------------------------------
{\Large \bf Reply to Reviewer \#2} [[done?]]
% ---------------------------------------

	The Reviewer stated that our manuscript ``tackles a very interesting problem, quantifying the uncertainity of interactions" which he/she rates as ``one of the hottest topics in the field". He/she also points out that ``the introduction is particularly pleasant to read" and that we framed the problem well. The Reviewer also pointed out a number of weaknesses to the manuscript that we respond to one-by-one. In general, we feel that the Reviewer's comments reflect a high degree of statistical expertise; expertise that we do not expect to be shared by the bulk of our intended audience (empirical ecologists assembing new ecological networks). We have therefore prioritised comments by this and the other Reviewers that seemed most likely to improve the manuscript for readers who are relatively new to Bayesian analysis over concerns most relevant to a highly knowledgeable reader. We hope that our revised manuscript makes this target audience clearer, and that we have addressed the Reviewer's key concerns with our revision.


	1. Lack of references [done]

		\begin{refquote}
			
			The fundamental question about predicting interactions given some incertainity has been and is debated in many papers (see the seminal paper by Roger Guimer\`{a} and Marta Sales-Pardo, PNAS, 2009). Even if the proposed framework is probably not stated in its exact terms in the literature, bridges between existing approaches (beyond Ecology) and the one in the paper would be very welcomed. An appropriate discussion between points of convergence and difference would help the reader to appreciate the significance and the impact of the proposed methodology.
		
		\end{refquote}


		\textbf{R:} This comment echoes the impression of Reviewers 1 (above) and 3 (below) that we do not give adequate attention to previous work. As stated above, we have now added many further pointers to previous work, and also been much more explicit regarding whom we try to reach with what message in the current paper.


	2. Non-independence of interactions not accounted for [done]

		\begin{refquote}
			2/ network oversight: the approach considers that the interactions are independent, which is not the case in real data. Indeed, the paper is supposed to be “network-oriented“ but the methodology deals with independent interactions (e.g. the variables L,T,X and D introduced lines 62,77,101 are for instance not indexed by ij which could have suggested that the interactions were seen as a whole). Consequently, the mathematical framework remains quite simple and may not reflect nor model the processes governing the actual detection of interactions. Despite of this drawback, the proposed method is interesting but at least the authors should add some discussion on the limits of dealing with independent interactions,
		\end{refquote}


		\textbf{R:} We agree wholeheartedly that ecological interactions are often not independent. Indeed, some of the priors we discuss (e.g., those incorporating species' abundances or trait-matching) will introduce covariance between interactions. The Reviewer is correct that we did not initially mention this non-independence explicitly. Our aim is to keep our mathematical framework simple so that it is easy for those not familiar with Bayesian analysis to adopt. Nevertheless, non-independence of interactions is an important consideration. We are therefore happy to index all variables referring to interactions by ij and we have added an explicit statement (lines XX-XX) that some priors treat interactions independently while others will introduce covariance (e.g., by species). 


		Lines XX-XX:

		\begin{quotation}
		    The shape parameters, or hyperparameters, may be set to particular values or derived from some data (see below). Note that the hyperparameters may be set to the same values for all interactions, allowed to vary independently for all interactions, or may incorporate non-independence betwween interactions (e.g., when the shape of the prior distribution depends upon species' abundances or traits).
		\end{quotation}


	3. Question about identifiability of the model [done]

		\begin{refquote}

			the reader would appreciate that the authors discuss and prove the identifiability of the model. Indeed, the three levels of uncertainity are nested but one could wonder whether different parameters at the three levels can fit the same data with the same quality (i.e. no identifiability).  I would suggest this point to be addressed in a specific section.

		\end{refquote}


		\textbf{R:} We believe that this comment stems from a lack of clarity about the goal of our model. It is not designed to separate the three levels of uncertainty or introduce parameters at particular levels. The only inputs are a prior distribution, which could refer to any level of uncertainty applicable to the study at hand, and post-hoc counts of interactions and co-occurrences. Using only the observed data, it is impossible to separate the three levels of uncertainty and our model does not aim to do so (as stated in lines XX-XX and lines XX-XX). We therefore do not believe that an in-depth discussion of identifiability would add much value to the manuscript and, in the interest of space, have decided not to include one.


		Lines XX-XX:


		\begin{quotation}
			When considering a metaweb, we wish to separate the unobserved interactions where $L_{ij} = 0$ (i.e., unfeasible interactions) from interactions which could occur but did not at a particular sampling site or which occurred but were not detected (Fig. 1). Unfortunately, this is not possible for most interactions (except those where we know an interaction is truly not feasible). That is, we generally do not know \emph{why} an interaction was not observed, only that it was not. An empirical ecologist will instead measure the marginal probability $P(L_{ij}) = k_{ij}/n_{ij}$, where $k_{ij}$ is the number of observed interactions between species $i$ and $j$ and $n_{ij}$ the number of observed co-occurrences. Given this information, the question becomes: how can we reduce the uncertainty around our estimated interaction probability?
		\end{quotation}


		Lines XX-XX:


		\begin{quotation}
			Note that these Bayesian models of $\lambda_{ij}$ are designed to quantify (and reduce) the total uncertainty about $\lambda_{ij}$. They do not address any of the nested sources of uncertainty in particular except through the choice of prior.
		\end{quotation}


	4. Request for a simulation study [done; thanks Tomas]


		\begin{refquote}
			the authors proposed an original approach based on a bayesian framework. Beyond the identifiability question (see above), the reader can question the power of the method. Usually, a methodological proposal comes with a complete simulation study that is supposed to show  the proposed model is adapted/suitable to the question and efficient to solve it. In the paper in its present form, the authors assume that the reader will be convinced by the results obtained on a single real dataset… In my opinion, the reader can’t be fairly convinced: how powerfull is the method? what can we say about the priors? how much data (n, k) is necessary to expect good results? An so on… Only a well-conducted simulation study can answer these questions.
		\end{refquote}


		\textbf{R:} We agree with the Reviewer that a full simulation study, based on recreating the sources of uncertainty in a data set generated from known processes, is an excellent way to demonstrate the power of a novel method. The novelty and impact of our work, however, is not in the method itself (several other Reviewers rightly point out that similar approaches have occasionally been used before) but in connecting a Bayesian statistical approach to the problem of limited and uneven sampling of networks and, we hope, in making this method more accessible to those without extensive statistical or modelling experience. In other words, what we try to achieve here is to alert empirical ecologists constructing and analyzing networks to the uncertainties built into their work. We then try to provide them with simple tools for grasping the extent and consequences of typical patterns. Please note that other Reviewers (as expressed by Reviewer 3 in particular) find this a highly worthwhile objective. 


		What Reviewer 2 proposes would be more suitable for an entirely novel method and is substantially beyond the scope of the present study. There is indubitably a place for simulation studies in order to find the most powerful method once a variety of tools are in common use, especially for researchers aiming to convince modellers that their tool is more powerful. Our manuscript, however, is not aimed at those already comfortable with Bayesian approaches but rather at those who may be aware of the problems of uneven uncertainty but not aware of any way to include this information in their analyses. We are confident that even a very simple model which incorporates the differences in sampling across interactions (as ours does) is more powerful than a model which ignores this information completely, and we therefore do not intend to conduct a full-scale simulation study. We accept that this means that those already using more intricate Bayesian methods are unlikely to switch to our simpler version; it was never our intention that they should do so.


	5. Request for an extended results and discussion section [no actual response, just words]


		\begin{refquote}
			5/ results\&discussion too short: the reader is surprised to read 27 lines of raw results only… Given the amount of new methodology that is proposed, one can expect a complete description of its pros and cons. Obvisouly, a simulation study (see above) would enrich the results part. Forgetting about the length of these parts, it is still difficult to catch the key messages from the text, and it is not obvious to relate discussion and the obtained results (for instance,from l.343 to l.351).
		\end{refquote}


		\textbf{R:} We very much appreciate the Reviewer's point that the results and discussion do not clearly illustrate the point of the manuscript. Although we have not conducted a simulation study (see above), we have extensively revised these sections in order to highlight the main thread through the manuscript. Due to space limitations, we were unable to greatly expand either section (we prioritise the introduciton and methods, which lay out the problem of uncertainty in networks and how it can be partially addressed), but we hope that the results now more clearly demonstrate how a Bayesian approach can address the uncertainty inherent in sampling.


	6. Suggestions to improve notation [done? unless anyone else can figure out the last part...]


		\begin{refquote}
			6/ lack of rigorous notations: it is possible to understand the approach with the present notations but some improvements can help the reader because there are a series of inconsistencies. Here are some suggestions. The authors chose upper case letters L,T ,X,D for single entities whereas the mathematician is used to expect matrices or constants in upper case. Traditionaly, given species i and j, we would consider interaction $L_ij$, feasibility $X_ij$, detectionability $D_ij$... \\
			Still, what is T?? not defined, never reused: is it a characteristics on i, on j, on both? \\
			How can be D<1 on l.169? D=0 or 1 since it says if an interaction is detectable or not... \\
			Moreover, L is reused later but is the number of interactions (l.100 supp.mat)… \\
			What is “N” in Figure 4? is it “n”? What is $n_ij$ and $k_ij$ l.266? Never defined, never reused. \\
			In the beginning of the paper, $\lambda$ is a probability (l.62) but it becomes a random variable (l.164): it would be more consistent to introduce before the notion of hyperparameters  (l.209-213) and to explain we consider that $\lambda$ is drawn into its distribution.
		\end{refquote}


		\textbf{R:} 
			\begin{itemize}
				\item As described above, we have now indexed $L$, $T$, $X$, $D$, etc. by $ij$. 
				\item $T$ describes trait matching, so it is a characterisation on $i$ and $j$ together. 
				\item $D$ can be \textless1 because some interactions are detectable but with a lower probability due to limitations in sampling techniques, sampling time, etc. With infinite monitoring time and capacity, all $D_{ij}$ would indeed be 0 or 1, but given real-world constraints that lead to otherwise-detectable interactions being missed, we feel it makes sense to discuss $0<D_{ij}<1$. For instance, consider a predator feeding upon two prey. If one of the prey (A) has many hard parts and is digested slowly, while the other has no hard parts and is digested quickly (B), the interaction involving prey A will be more detectable than the interaction involving prey B. The interaction with prey B is does not have D=0, because the interaction might be observed directly or through examination of gut contents very soon after B was consumed, but we cannot say that D=1 because we are quite likely not to detect this interaction in any given sample.
				\item Using L to mean the number of interactions is incredibly common in the food-web literature, especially when defining connectance (as in the instance the Reviewer points out - now included in the main text). That said, we appreciate that this useage may confuse mathematicians. We therefore now define the number of interactions as N and hope that this is less puzzling.
				\item Yes, the N on figure 4 should have been $n_{ij}$. This has been corrected. As discussed above, $n$ and $k$ are now always indexed by $ij$. 
				\item We do not catch what the Reviewer is aiming at here. We hope that our revised introduction and methods have addressed this point; if not, we request that the Reviewer kindly provide some more detail so that we can address his/her concern.
			\end{itemize}


	7. l.62: define formally T [done]


		\textbf{R}: We now define $T_{ij}$ as ``some function describing trait-matching between species $i$ and $j$ $\mathbf{T_{ij}}$". This definition is intentionally open-ended as we foresee that $T_{ij}$ could be binary (traits are compatible or not) or continuous with a wide array of distributions.


	8. Clarify the point of analysing the data using an alternative prior [done]

		
		\begin{refquote}	
			-l.244: this is weird to mention that the analysis has been done on another dataset but that the results will not be discussed… What is the interest for the reader?
		\end{refquote}


		\textbf{R}: We have removed the reference to the analysis and now explain more thoroughly how the choice of an unsuitable prior can result in unrealistic posterior distributions, as this is the interest for the reader.


	9. No ``moral network" [not sure about this one.]

		\begin{refquote}
			-l.149: since the authors consider the interactions are independent, there is morally no network in the approach (except the result)
		\end{refquote}


		\textbf{R}: We do not agree with this assessment. We do not explicitly consider the interactions to be independent, although we also do not explicitly define a dependence structure (we did not have data on species abundances or preferences that would allow us to do this). Even had we specifically stated that interactions are considered independent, this would not be unique among network analyses (see e.g., ...). To us, non-independence of interactions is not necessary when considering a network. All that is essential is the endeavour to better understand a community of interacting species, which our study does aim to do. 


	10. l.252: not clear. Why this choice? [done]


		\textbf{R:} We have expanded the description of the reasoning behind our choice of prior and hope that the following is clearer:


		Lines 369-373:


		\begin{quotation}
			researchers must choose between using a less-informative prior (e.g., one based on distributions of links across a large set of networks) or an empirical prior based on some ”training data” from the study. Here, we opted for the latter and created priors using a single sub-network from the middle of the geographical distribution of the Kopelke et al. (2017) dataset. 
		\end{quotation}


	11. l.259: not clear [done]
	
		
		\textbf{R:} We have expanded our explanation of how mis-matched priors can give unrealistic results. We hope that the following is clearer:


		Lines 373-379:


		\begin{quotation}
			To demonstrate how the use of data from a different system can affect the prior distribution and conclusions based on it, we repeated our analyses using priors derived from a much smaller Salix-galler-natural enemy system based around genotypes of a single Salix species (Barbour et al., 2016, Data available from the Dryad Digital Repository: https://doi.org/10.5061/dryad.g7805). This smaller system was much more densely-connected than that described in Kopelke et al. (2017) and provided unreasonable distributions for interaction probabilities (Appendix S6 ).
		\end{quotation}


	12. Why connectance and nestedness? [done?]


		\begin{refquote}
			-l.278: the authors investigate the consequence of uncertainity on network metrics. This question is of peculiar interest, but here it is restricted to the connectance and nestedness. Why these two metrics? Why not others? What is the impact of integrating incertainity into the metrics computation? (we guess the answers but we could expect the authors develop these points).
		\end{refquote}


		\textbf{R:} We chose connectance and nestedness (together with degree distributions) as simple examples of commonly-assessed network properties that would be familiar to most readers working with ecological networks. Obviously these are not the only parameters of interest, but we do not have space to provide an exhaustive analysis of how uncertainty in the computation of network metrics affects different network properties. Our aim was simply to show that including uncertainty in interactions (and accounting for the possibility that many interactions are not observed) can dramatically change our perception of network metrics. A full discussion of how and why these values differ is better suited to either an exhaustive simulation study or an experimental study where different sources of uncertainty can be controlled to some degree. We now state that these four properties were chosen as illustrative examples (lines 425-428).


		\begin{quotation}
			After obtaining these posterior networks, we calculated, as examples of commonly-used network properties, the connectance of each web, as well as the mean number of links per galler and per natural enemy, and the nestedness (NODF) of the network.
		\end{quotation}


	13. l.291: explain better the simulation procedure [done]
	

		\textbf{R:} In the interest of space, we have added an extended description of the sampling procedure in \emph{Appendix S2}. 


		Lines 420-425:


		\begin{quotation}
			Using the prior distributions and procedures described above, we calculated posterior probability distributions for species pairs that were not observed interacting. Using these posterior distributions and assuming probabilities of 1 for pairs of species that were observed interacting (see Appendix S2 for a justification), we created a suite of 100 webs by randomly sampling from each posterior distribution. Each of these webs is a prediction of the structure of the metaweb.
		\end{quotation}


	14. l.306: given the shape of the distribution (exponential), the mean is not an appropriate indicator. [done]


		\textbf{R:} The mean may not be the best indicator with which to describe the shape of the distribution, but we hope that the Reviewer will agree that it gets the point across (co-occurrences are rare; the specific values are not of great importance). Nevertheless, we now include both mean and median in order to better reflect the exponential distribution of the data.


		Lines XX-XX:


		\begin{quotation}
			the total number of co-occurrences was generally low (mean=3.87, median=2; Fig. 2A). The bulk (92.24\%) of these co-occurring species pairs were never observed interacting. Of those pairs that did interact, the incidence of interaction was also low (mean=4.04, median=2; Fig. 2B) and was lower than the number of observed co-occurrences (Fig. 2C).
		\end{quotation}


	15. What does higher nestedness in the observed networks mean? How is it possible? [done]


		\textbf{R:} Nestedness being higher in the observed networks simply means that the additional interactions predicted by our model tend not to be between generalists and specialists and, as such, do not contribute strongly to nestedness. This is actually somewhat intuitive - ``specialists" in the observed data are exactly those species for which we are most likely to be missing interactions, and interactions between specialists and the most likely to be predicted to occur but not have been observed. Due to the tight word limit, we do not have space to discuss this extensively in the manuscript but have added brief interpretations in the results.


		Lines XX-XX:


		\begin{quotation}
			Nestedness was higher in the observed network (NODF=6.85) than in the posterior webs (6.31 $\leq NODF \leq$ 6.82; Fig. 5C), indicating that the posterior webs include many more interactions between specialists than the observed network. In addition, the stronger the detection filter, the farther apart were the nestedness of the observed and posterior webs. This suggests that the interactions included in the observed network are not a random subset of those included in the posterior webs.
		\end{quotation}

\clearpage

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#3}
% ---------------------------------------

	\begin{refquote}
		Comments to the Corresponding Author
		Overall, I think this is a very good paper and makes an important contribution.  I think there are three main ways it can be improved: 1.      The simplest – do a better job of acknowledging what else has been done in the field – much of which has actually been done by the authors and their collaborators. ... 2.      Provide more clarity in descriptions making sure to consider how terms and ideas have been used previously. ... 3.      The set up (introduction) to the case study is quite odd and somehow seems off topic – or at least not logical based on what the reader has read up to that point.
		I hope this review is helpful.  


		More generally, the introduction does not really do justice to what has been done already – even the authors own work.  The problem in my view is that the community using better statistics – of which the authors are very important members – has not managed to communicate to most people studying networks and better methods are simply not being adopted.  The current paper is a very nice attempt to show the broader community that the Bayesian approach is not so complex and has many advantages.  I think this is a very important message and is what makes this paper an important contribution.  Further, the approach to parse out different types of uncertainty and suggestions for how to come-up with informative priors – is very useful.  The theory/method is well developed overall and provides an example – which is great.

		\end{refquote}

		\textbf{R:} We than the Reviewer for their literature suggestions and for demonstrating that our desire not to criticise hard-working empiricists could be misinterpreted as suggesting reduced sampling effort. We had not realised that anyone would consider such a possibility and have revised our manuscript to make it clearer that our approach is a complement to extensive sampling, not an excuse for poor sampling. 


	1. Add more references to the literature [[done]]

		\begin{refquote}
		1.      The simplest – do a better job of acknowledging what else has been done in the field – much of which has actually been done by the authors and their collaborators.  Given that they know there work I won’t point that out (but they are under-siting this literature a bit) but they could consider Graham and Weinstein on-line early 2018 (I realize that this was just out when the author’s submitted but it has some very similar messages) and the empirical example of Weinstein and Graham in Ecology letters 2017.  I don’t think this would in any way diminish the importance of the current paper because I think the challenge in network ecology is to get people to use better quantitative methods.
		\end{refquote}

		\textbf{R:} We had not intended to write a review paper and did not wish to over-cite ourselves, but we take the Reviewer's point and have expanded our references to the literature. We have taken particular care to add references to Graham/Weinsten papers as two of the reviewers suggested work by these authors. We hope that the introduction now presents a more thorough sample of previous work.

		\begin{refquote}
		Line 7.  It is certainly true that most networks are snapshots in time but there is a growing realization – including some nice examples (including those by the authors) that address this issue.  Maybe what you want to say is that we know that networks should not be considered static but we lack the tools – or ability to collect data – or whatever you think is the cause – to correct this situation. 
		\end{refquote}

		\textbf{R:} We have softened this statement to say that empirical networks are "often limited" and hope that this rephrasing will not offend those who are working to include variation in their descriptions.

			\begin{quotation}
				Despite this additional information, empirical descriptions of ecological networks are still often limited by a lack of data or tools to adequately incorporate variation in interactions into networks.
			\end{quotation}


		\begin{refquote}
		Line 30.  There are several conceptual and empirical attempts to consider detection probability – why aren’t these cited (work by Bartomeus comes to mind).\\
		\end{refquote}

			\textbf{R:} We have added a citation to Bartomeus as requested.

		\begin{refquote}
			Line 36.  I certainly see value in the approach and the general ideas of these authors in particular but they should acknowledge the work that has been done by themselves and others!\\
		\end{refquote}

		\textbf{R:} We have rephrased the end of this paragraph to mention previous predictive models dealing with uncertainty in interaction matrices.

		\begin{refquote}
		Line 89.  In Weinstein and Graham (Ecology Letters) the processes modeled were trait matching (which you place in interaction uncertainty) and abundance (which is perhaps your process uncertainty??).  I find myself quite confused based on how you describe things in this MS (See text above) and how you cite the literature.
		\end{refquote}

		\textbf{R:} We have revised this section and now no longer refer to the specifics of Weinstein and Graham at all. Instead, we discuss repeated sampling in a section dedicated to the question of whether sampling is useful (of course it is) and whether it can completely solve problems of uncertainty in ecological networks (almost certinaly not). We hope that this is less confusing.

		\begin{refquote}
		Line 148.  Please note that a paper with a very similar aim was recently published (Graham and Weinstein).  This does not to diminish the value of this study in any way, as multiple perspectives on quantitative solutions in network ecology are urgently needed….. but the other work should be considered. 
		\end{refquote}

		\textbf{R:} We had not seen the Graham and Weinstein paper when we first submitted our manuscript, but now cite it in the introduction. We have also revised this section in hopes of making the uniqueness of our framework (its simplicity and adaptability) clear. 

		\begin{refquote}
		Line 288.  I am pretty sure this idea is in the literature several times and should be cited.  Isn’t this the same as drawing a probability of interaction from a distribution where the distribution of each interaction is an output of the Bayesian method?\\
		\end{refquote}

		\textbf{R:} Yes, that is exactly the idea. We are also sure that this is a common approach and therefore hadn't cited it (in the same way one would not be likely to cite the prior users of common statistical tests). We have added a citation to~\citet{Vazquez2005,Guimera2009} as two examples and hope that this is sufficient.

		\begin{refquote}
		Line 352 – 358.  Citations are needed in this section as this has been suggested before.
		\end{refquote}

		\textbf{R:} Most of these lines refer specifically to our results, making it somewhat difficult to add citations. We have added citations where possible and rephrased this section to make it clearer when we are referring to work done in the present manuscript.


	2. Confusing terminology [[done]]

		\begin{refquote}
		2.      Provide more clarity in descriptions making sure to consider how terms and ideas have been used previously.  Two things come to mind – the use of terms and distinction between interaction and process uncertainty; and the somewhat contradictory sounding statements about if sampling more is actually good.
		\medskip
		Line 86.  So, similar factors (i.e., trait matching) can be used to detect different kinds of uncertainty.  Should this be stated?  You might also consider a different word that process as “observation models” and “process models” are commonly used terms in Bayesian stats and in this case “process” often considers what you call “interaction”.  There are some interesting to attempts to model co-evolution that consider similar ideas (i.e., a barrier to interaction and then trait-matching; but maybe outside of the scope of this MS). While I appreciate that your naming has merit, I think if your hope is that more ecologists use these methods then the terminology should be consistent across papers/approaches to the greatest extent possible.
		\end{refquote}


		\textbf{R:} We have revised this section of the introduction to both avoid introducing rigid terminology and make it clear that our model is not concerned with partitioning different sources of variation (indeed, we state that in many cases this is not possible using empirical data). Hopefully this will discourage readers from getting bogged down in trying to isolate which external factors cause which types of uncertainty (there is almost certainly overlap - e.g., bad weather could both reduce the probability that species will be active and interact and the probability that an interaction is observed if visibility is poor). We have also added a section (lines XX-XX) referring to "forbidden links" which address aspects of whether species can interact (which we had previously called interaction uncertainty) and whether they do interact at a particular site (previously process uncertainty). We hope that this addition clarifies the agreement of our manuscript with previous works listing sources of uncertainty.

			\begin{quotation}

        \textbf{Forbidden links}

            Both of the above sources of uncertainty (i.e., whether species would be able to interact given their traits and whether they are able to interact at a particular place and time) are addressed in the concept of "forbidden links"~\citep{Jordano2016}. In this framework, all links which are prevented by spatio-temporal uncoupling~\citep{Jordano1987}, physiological constraints~\citep{Jordano1987}, etc. are considered "structural zeros" that cannot be observed~\citep{Jordano2016}. We conceptually distinguish between physiological constraints and spatio-temporal uncoupling to allow for cases in which a species is introduced to a new habitat, expands its range, or shifts phenology~\citep{Gravel2013}. In such cases, links which are forbidden due to physiological constraints remain forbidden but links previously forbidden due to spatio-temporal mismatch could potentially occur. 

      \end{quotation}


	3. Introduction of the case study seems off-topic and illogical. [[done]]

		\begin{refquote}
		3.      The set up (introduction) to the case study is quite odd and somehow seems off topic – or at least not logical based on what the reader has read up to that point.
		\medskip
		Line 240.  I found the justification for the system a bit odd.  Is the goal to show the gaps in sampling or to apply the model described thus far to consider the 3 different types of uncertainty outlined?  At this point the reader is confused about the goal…
		\medskip
		Line 249.  The statement about training data is redundant with what is stated above – adjust writing.
		\end{refquote}

		\textbf{R:} We have expanded our introduction of the case study (lines XX-XX) to make it clear that we are using the highest-quality empirical network we can find as even such networks have uncertainty about unobserved interactions. This relates back to our point that urging increased sampling effort is not likely to solve problems of uncertainty as long as sampling is limited in number of methodologies, biased towards abundant or easy-to-identify species, restricted to particular spatial sites and/or environmental conditions (if the network is intended to be more general), or all of the above. We repeat this point in the discussion to ensure that the case study is relevant. We have also clarified our statement that strict Bayes does not allow empirical priors, but that they are an option for researchers that are more concerned about matching their prior to their study system than with strict formalism (lines XX-XX). As Reviewer 1 points out, this is somewhat controversial and we feel it is important to note the potential objection.

		\begin{quotation}

 			To illustrate the process of constructing a Bayesian network to quantify uncertainty about interactions, we use the comprehensively-sampled system of willows (\emph{Salix}), herbivorous gallers, and their natural enemies described by~\citet{Kopelke2017}. This dataset consists of a single community type sampled across Europe over 29 years and at 374 unique locations. The meta-network consists of 1,173 different interactions between 52 \emph{Salix} nodes, 92 herbivore nodes, and 126 natural enemy nodes (see \emph{Appendix S4} for details). 
      The high spatiotemporal resolution of this dataset make it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, we anticipate that there will be many pairs of species which were rarely or never observed together. Using the Bayesian framework above, we can identify which potential interactions are more and less uncertain, allowing us to better predict the true structure of the metaweb. To show the gaps in sampling, we compared the frequencies of observed co-occurrences and interactions. We then calculated an empirical prior and computed the posterior distribution of the probability of an as-yet-unobserved interaction being feasible ($\lambda$).
      We analysed both the \emph{Salix}-galler and galler-natural enemy components of the network but, for brevity, present only the latter here (see~\emph{Appendix S5} for \emph{Salix}-galler results).

		\end{quotation}


	4. Misunderstanding of our point about sampling effort [[done]]

		\textbf{R:} We believe that the Reviewer has badly misunderstood the point of our comments on sampling effort. Several of their comments suggest that we are advocating for reducing sampling effort. This is emphatically not the case. Rather, we assumed that field researchers already sample to the maximum extent possible given their time and resource constraints and so a call to "sample more" would not be helpful. We now address this assumption explicitly in a section dedicated to the potential for sampling effort to reduce uncertainty about interactions (\textbf{Why can't we sample more?}. Below, we address the Reviewer's sampling-related comments one by one.


		\begin{refquote}
		Line 94.  I find this a very odd argument against sampling multiple times.  So, if you sample more you might see more then understand the system less?  The logic does not make sense to me. 
		\end{refquote}

		\textbf{R:} Of course sampling more does not lead to less understanding. It can, however, reveal knowledge gaps (as when a rare species is detected, revealing our ignorance of its interactions). This is not an argument against multiple sampling but a statement that increased sampling is likely to lead to the addition of more "false zeros" as species about which we know little are added to the network.

		\begin{refquote}
		Line 107.  There is a lot of literature in wildlife ecology emphasizing the importance of repeat sampling for estimating detection probability.  Is this just wrong?  If so this does need more explanation in the context of this literature.
		\end{refquote}

		\textbf{R:} I do not know how the Reviewer assumes that we are against repeat sampling when this is, in fact, one of the core parts of our approach. Our point here is that some species (e.g., cryptic or difficult-to-identify species) and interactions (e.g., brief visits of pollinators to plants) are difficult to detect and may be missed even with multiple sampling. If a rare species is only detected in one sampling round, then the repeated sampling necessarily tells us little about its interactions. For species which are frequently detected, we absolutely learn about the detection probability of their interactions with repeated sampling.

		\begin{refquote}
		Line 130.  The ideas here are largely a repeat from those above.  Further, while it may be true that we can sample too much – I think it is dangerous to suggest we should sample less – do the authors think that sampling across most network studies is sufficient (the opposite is stated in the discussion)?  I wonder if the argument is a bit more statistical than biological.
		\end{refquote}

		\textbf{R:} We agree that it is dangerous to suggest that anyone sample less, that is why we have not done so. We argue only that the amount of sampling required to be confident that co-occurring species do not interact is large -- likely beyond what is feasible for speciose systems given the limited resources available to many researchers. Sampling across most network studies is almost certainly not sufficient, but data which would allow readers to judge this (i.e., number of times each species is observed, independent of numbers of observed interactions) is not generally provided. We chose to be more charitable than the Reviewer and assume that those compiling empirical networks are sampling as much as possible given the constraints of their system and available resources. Infinite sampling would, of course, be the best option but it is unlikely that researchers will be able to perpetually increase sampling.

		\begin{refquote}
		Line 144.  I am much more comfortable with this statement than how sampling effort should be considered and I would suggest moving this up and then explaining how even if we sample well we need to consider uncertainty for the reasons you mention in the previous section.  Please note that you make the same point in your discussion on line 338.
		\end{refquote}

		\textbf{R:} We are pleased that this point was clear and have made sure to include it in our revision.

		\begin{refquote}
		Line 319.  It is clear that these are large samples but if interaction among co-occurring species was greater than you need lower samples – correct?  Should this be made clear?  Otherwise, we maybe can just never get enough data!
		\end{refquote}

		\textbf{R:} We are specifically speaking about interactions which were never observed. As interaction networks tend to be sparse, there will always be many of these. If interaction frequencies were higher among species that co-occurred, then we would have fewer unobserved interactions but the sample sizes needed to be confident that an unobserved interaction does not occur would not change (perhaps our threshold for deciding to believe a zero might, which is why we provide sample sizes for several thresholds). The Reviewer has hit the nail on the head with the idea that it is extremely hard to get enough data to be sure about every interaction. This is why prior knowledge can be so useful!

		\begin{refquote}
		Line 338 to 342.  Throughout I am confused if the authors suggest more sampling is good or bad…  At the end of the paragraph it seems it isn’t so great to sample more because you end up with these annoying “0” values…??????
		\end{refquote}

		\textbf{R:} We had written our first draft with the assumption that empirical ecologists are well aware that large sample sizes are important and that they should sample as much as possible. Given that, repeating the call to sample more seemed more likely to come across as patronizing than helpful. We did not anticipate that anyone would read the omission of such a call a statement that anyone should sample \emph{less}. In our revised manuscript, we collect our discussion of sampling into a dedicated section. We hope that this will make it clearer that sampling is very important but cannot completely eliminate uncertainty (except perhaps in some very species-poor and unusually static systems, but these are certainly rare). As to adding more zeros than ones specifically, this is only "bad" in the sense that it gives us more high-uncertainty cells in the interaction matrix. We take the view that it is better to have "known unknowns" than "unknown unknowns" and it is certainly better to know about more of the species in a community than fewer, but finding a single individual of a rare species will not reduce uncertainty in the web. We have added a line (XX-XX) specifically to address this.

		\begin{quotation}
			we will accumulate observations of co-occurrences faster than we will accumulate observations of interactions (Fig. 2C). While this improves our understanding of the set of species present in the community, it introduces yet more uncertainty into the interaction matrix. Note that it is better to identify the set of potential interactions than to miss a species, so sampling effort should not be reduced in order to exclude rare species.
		\end{quotation}


	5. Eliminate redundant "because" on line 23 [[done]]

		\textbf{R:} Done.


	6. Reduce repetition of inevitable uncertainty [[done]]

		\begin{refquote}
		Line 73, 87.  Maybe the idea that some uncertainty is “inevitable” should not be repeated in multiple sections.  Either find a different way of saying it – or state it in your introductory paragraph and then don’t keep repeating.
		\end{refquote}

		\textbf{R:} We have rephrased the paragraph about detection uncertainty. The last line now reads:
			
			\begin{quotation}

				Until these gaps are filled, some interaction uncertainty will remain.

			\end{quotation}


	7. Why not always model probabilities of co-occurrence? [[done]]

		\begin{refquote}
		Line 142.  But shouldn’t you model the probability of two species co-occurring?  The authors have a paper doing this…. Is that not a good idea?
		\end{refquote}

		\textbf{R:} Of course modelling the probability of co-occurrence is an option for many systems (e.g., aquatic food webs where ranges of fish species are fairly well-known, as in~\citet{Gravel2013}). In some systems, however, the factors affecting probabilities of co-occurrence may not be known. We therefore cannot suggest modelling co-occurrence as a panacea. Instead, we now emphasize that co-occurrence probabilities are one thing that could be included in a prior (lines XX-XX - section Informative priors). 
		\smallskip
		The fact remains that a lack of observed interactions between species which do not co-occur tells us nothing about whether these species \emph{could} interact if they should begin to co-occur (e.g., following a range shift). Following the Revewier's suggestion, we have revised our manuscript to clarify our technology. In particular, we have taken care to specify which level of uncertainty we are addressing at different points in the manuscript. We hope that this will remove some of the confusion about whether or not modelling different components of uncertainty/sampling more is a good idea. 


	8. Issue of testing hypotheses based on inputs into models [[done]]

		\begin{refquote}
		Line 121.  I think one of the reason non-Bayesians’ are not comfortable with the approach is that if you put in prior information on something like trait matching and test for trait matching and then discover trait matching is important – what does it mean?  Maybe this is too obvious (I realize there are tons of papers on how to choose priors) but I wonder if it is worth explaining (would a box or something be worthwhile?  I leave it up to the authors/editor)?  Maybe the issue could be acknowledged and an appropriate paper cited?
		\end{refquote}

		\textbf{R:} Following suggestions by this Reviewer and another, we have substantially expanded our discussion of different options for priors (including the trait-based and co-occurrence models the Reviewer points out). It seems fairly obvious that discovering that trait-matching is important in a model framework which relies of trait-matching as a starting assumption does not mean very much... but we also recognize that researchers unfamiliar with Bayesian approaches might prioritize reducing uncertainty and therefore include all available information even when it conflicts with the study question. We have therefore added an explicit statement that researchers wishing to test the influence of a particular trait (for example) should \emph{not} include that trait in their prior (lines XX-XX). We hope that this statement, and the expanded discussion of different types of priors more generally, allay the Reviewer's concerns. 

		\begin{quotation}
			Similarly, if detailed information is available but refers to the question at hand, it is best to use a less informative prior so as not to force a particular result. For example, if researchers are interested in testing whether body-size ratios affect probabilities of interaction they should not use a prior which predicts interactions based on body sizes.
		\end{quotation}


	9. Redundancy in line 235 [[done]]

		\textbf{R:} The redundant line has been removed. Thank you for pointing this out.


	10. Unsure about the point of filtering networks [[done]]

		\begin{refquote}
		Line 295 to 302.  I would think that this second step (i.e., filtered networks) is to explore sampling not to determine how networks will be influenced by uncertainty?  Do you need the filtering step to evaluate uncertainty (as written it seems that this is the case)?
		\end{refquote}

		\textbf{R:} The filtering was intended to show how uncertainty likely warps our current understanding of network properties like connectance. If we do not observe 20-50\% of the interactions in a network, then many network properties in the published literature will be inaccurate. Even worse, networks compiled under different levels of uncertainty (e.g., species with more or less variable traits, or studies with multiple sampling methods or only one) or with different sampling efforts will have network structure metrics that are inaccurate to different degrees. Filtering networks in the way that we do could give an idea of how many networks are missing, but we do not think it is necessary to evaluate uncertainty (we believe that examining the posterior distributions directly is a better approach there). We have rephrased these lines (XX-XX) to emphasize that the filtered networks are intended to demonstrate the consequences of uncertainty more than anything else.

		\begin{quotation}
			Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. 
		\end{quotation}


	11. Skepticism about sampling requirements to be sure interactions do not occur [[done]]

		\begin{refquote}
		Line 361.  I find the statement that 30-50 individuals need to be evaluated a bit strong.  This statement is based on this study – are all systems like the gall system?  If species are specialized or bound to interact for some other reason (i.e., co-occurring when there are few other resources) wouldn’t you need to observe fewer individuals?  The point of the method is that you can estimate how many individuals are needed…. This is great!  But given that this can be estimated from any given system why give a value from one system and state that is what is required?  It defeats the point of the very nice method proposed…??
		\end{refquote}

		\textbf{R:} The point of our method is not actually to quantify the amount of sampling needed. Although the ideal sampling effort \emph{can} be calculated using the framework we put forward (as we demonstrate), the real point is to quantify how uncertain we are that an interaction we do not observe really does not occur. Given this, we do not think that recommending uncertainty be explicitly stated undermines our point at all. 
		\smallskip
		The Reviewer's suggestion that we might need fewer samples for species that are "specialized or bound to interact for some other reason" reflects a very strong prior. In this case, yes we would need fewer samples for the species concerned. With sufficiently strong priors, it is not necessary to sample at all! For example, in most food webs it is assumed that basal resources will never consume prey even if a given resource and a given animal are never observed co-occurring and it is generally accepted that there is very low uncertainty about these zeros. In many cases, the assumptions involved in excluding interactions are less clear-cut and different researchers may disagree about which species are "bound to interact" (or not to interact). The concept of pollination syndromes is one example - many flower visitors are less rigidly specialized on particular flower types than initially thought~\citep{Ollerton2009}. To address such "forbidden links", we now suggest that researchers explicitly state both the uncertainty about data-based zeros and the assumptions by which they create structural zeros. This will allow future researchers to evaluate the uncertainty about all interactions in a network as the state of expert knowledge changes. We hope that this expanded recommendation (lines XX-XX) is clearer.


		\begin{quotation}

			Second, researchers should acknowledge the varying levels of confidence surrounding interactions between species pairs. In the absence of strong prior information a very high level of sampling (i.e., 30-50 observations in our example) is needed \emph{for each species pair}. This is not likely to be possible for most studies. including the $n$ and $k$ values for each interaction will clearly indicate which unobserved interactions are most likely to be observed with further sampling and which estimates are more reliable. Where there are strong prior expectations about pairs of species that will not interact, these should be explicitly stated so that readers know which zeros in an interaction matrix are based on observed data and which are based primarily upon expert knowledge.

		\end{quotation}


\clearpage

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
{\Large \bf Reply to Referee \#4}
% ---------------------------------------

	\begin{refquote}
		Comments to the Corresponding Author
		I have been surprised how little that sampling effects have been formally considered in the analysis of networks, so I welcome this contribution that provides a theoretical framework. Overall, I felt that this contribution was really helpful, and that it provides both a theoretical framework and a practical example.

		Overall, I fear that this review is rather meandering, but I think that reflects some of the challenges I have with the paper. Currently I do not think the paper would be used by empirical network ecologists because they either would not understand its relevance or would not be able to apply it practically. This would be a great shame. I hope that the comments are clear enough to allow the authors to improve the paper – the paper has the potential to be important and very useful.
		\end{refquote}

		\textbf{R:} As we did not intend to write a review, we understand the Reviewer's complaint. This shows that we did not clearly establish the purpose of our manuscript, and we hope that our revision corrects this. In particular, we hope that we have established the relevance of our method and offered enough of an explanation that empiricists will be able to apply it. Our goal is to increase access to a statistical technique which we see as complementary to high-quality field work, and we believe that the Reviewer's comments will help us to achieve this.


	1. Paper is poorly structured [[done?]]

		\begin{refquote}
		However, I felt that the structuring of the paper made it a challenge to understand and apply. It felt like the paper itself had been written in different sections (by different authors?) with not enough links between the sections. I also felt that there was a strong theoretical component, which is important, but there needed to be a stronger link with the issues around empirical ecology, as explained below.
		\end{refquote}

		\textbf{R:} We have revised the manuscript with an eye to clarifying the flow between sections. We hope that it is now clear that our proposed framework is designed to use Bayesian theory to complement empirical networks and empiricists' detailed knowledge of their systems. 


	2. Add more citations [[done]]

		\begin{refquote}
		Introduction – T. Poisot and colleagues have done a lot of relevant work in this area, but I felt there was undue reference to their work in comparison with other relevant work. There were some obvious papers (e.g. sampling by Jordano, forbidden links by various others) that were not cited. A broader perspective on the literature would, I think, help the authors appreciate the value of their paper and the need to ensure that it is fully understandable and of practical use.
		\end{refquote}

		\textbf{R:} We have cited addition literature as recommended by Reviewer 1, including a paper by Jordano. If the Reviewer has any suggestions of specific papers that they feel are missing, we would be happy to consider them as well. Note, however, that we do not intend our manuscript to be a complete review of the literature surrounding interaction probabilities. We hope that the citations we have added appear more balanced to the Reviewer.


	3. Comment on weighted metrics [[done]]

		\begin{refquote}
		L36ff The authors should note the value of weighted metrics in taking account of sampling biases.
		\end{refquote}

		\textbf{R:} We do not see how weighted metrics (which we infer mean metrics including interaction strength/frequencies based on the Reviewer's comment below) account for sampling biases. It seems to us that measures of interaction strength should be \emph{more} susceptible to sampling biases, not less, as abundant species are both more likely to have their interactions recorded and more likely to have these interactions recorded as strong/frequent. We have rephrased the introduction so that the original line 36 no longer appears. If the Reviewer strongly feels that weighted metrics somehow do sampling biases, we must ask for clarification as to why. We are willing to add a note as requested, but only if we are convinced that weighted metrics are indeed useful in this regard.


	4. Demand for extension to weighted networks [[not done - do we want to do this?]]

		\begin{refquote}
		L45 It is a shame not to give some idea of how the method could be extended (or is this the intention of the authors?). For empirical analysis of networks it is rare to use binary networks given the value of weighted networks for taking account of sampling biases. Indeed, I am much less concerned about whether an interaction never occurs, and much more concerned with the frequency of occurrence.
		\end{refquote}

		\textbf{R:} As stated above, we do not agree that weighted networks reduce sampling biases. Moreover, we disagree that it is rare to use binary networks as most food webs (for example) are still binary. It takes an even greater sampling effort to quantify interaction strengths than the presence and absence of links, so for species-rich systems in particular there simply are not many high-quality weighted networks published. If the Reviewer is only concerned about weighted interactions, we congratulate them on their tractable study system. Nevertheless, we do not wish to exclude the many researchers who are not so fortunate.
		\smallskip
		To model frequencies of interactions, ...
			 [[Do we want to add a bit of non-binary stuff or just make it clearer that we are talking about feasibility and that probabilities of occurrance could be layered on later?]]


	5. Description of causes of uncertainty poorly integrated with the case study [[done]]

		\begin{refquote}
		L50 This is a nice and clearly explained description of the problem that many network ecologists ignore, or are unaware of.
		Section from L50. This section is valuable, but had very weak links with the empirical analysis later in the paper. For instance in the example of the gall-formers, there was not formal discussion about the different sources of uncertainty. 
		\end{refquote}

		\textbf{R:} As we state in the section \textbf{Estimating uncertainty}, we usually cannot distinguish different sources of uncertainty in empirical data. Those studies which attempt to do so (e.g.,~\citet{Graham2018}) remove process uncertainty by assuming constant interaction probabilities during a short, intense sampling period and also assume that we know the true set of feasible interactions. This may be the case for Graham and Weinstein's relatively small and well-studied system but is not likely to be true for systems containing hundreds of species, systems containing recently-arrived species, systems just beginning to be studied, etc.
		\smallskip
		To make this more clear, we have rephrased this section and added a line (lines XX-XX) stating that we usually cannot determine the cause of all the zeros in an interaction matrix (we can identify obviously unfeasible interactions, but likely cannot say whether a zero for a rare species is because we did not observe enough individuals, there were not enough individuals to perform a particular interaction, or because the interaction is acutally unfeasible). We hope that this revision makes it clearer that the description of different sources of uncertainty is a conceptual guide only.


		\begin{quotation}
			An observed link definitely occurred, but there are multiple reasons why a given link may not be observed \emph{whether or not the interaction truly occurred}. Moreover, given an unobserved interaction in an empirical dataset, we often cannot determine why the interaction did not occur \emph{post hoc}. The detection of any interaction is a stochastic process subject to many levels of uncertainty. As a conceptual guide to the factors affecting this process, we describe three nested levels of uncertainty that roughly address the questions: "Could species $i$ and $j$ interact?", "Do they interact?" and "Do we observe the interaction?" (Fig. 1). 
		\end{quotation}


	6. Process uncertainty poorly defined. [[done]]

		\begin{refquote}
		L76ff ‘Process uncertainty’ is not defined. The simplistic example of interaction uncertainty (fish eating a cactus) does not help the reader understand the detail of what is meant by ‘interaction uncertainty’. The two examples of ‘local constraints’ (weather and habitat) are operating on completely different temporal scales (note – it is defined differently in L109). I would regard the issue of weather as much closer to detection uncertainty (e.g. for a pollinator, it would be likely to be interacting if the weather was better), whereas the issue of habitat is closer to the authors’ ‘interaction uncertainty’ (the species don’t interact because they are not, or never, co-occurring in a habitat). Also if the species occur in different habitats then with an appropriate spatial scale of sampling then they do not co-occur – so the issue seems redundant. [[I suspect that the authors are thinking of a meta- or master network in much of their study, but this is not clear (or I have misunderstood and it needs to be explained better), i.e. the predicted presence of an interaction is not the presence of an interaction at the local site (taking detection and process uncertainty into account) but the ability to assess ‘interaction uncertainty’.]][[This is a bit separate from their issue]]
		\end{refquote}


		\textbf{R:} As our manuscript is not concerned with partitioning sources of uncertainty, we felt it was unproductive to get bogged down in a debate over the precise definitions of process vs. interaction uncertainty and which external influences might contribute to which sources (there is enough overlap that simple statements such as "bad weather increases process uncertainty" are, at best, incomplete). To remove this problem, we have rephrased the introduction and discussion to refer to the questions of whether two species \emph{can} interact under ideal conditions and whether they \emph{do} interact at a given site and time. We hope that this reframing, and the addition of clear statements that our framework is not intended to separate different sources of uncertainty, will remove the Reviewer's confusion.
		\smallskip
		Our mention of habitat as a factor affecting the probability of species interacting at a site was not intended to refer to species using different habitats, but rather the possibility that habitat type might affect interaction probabilities. For example, a more open patch of forest might have different interaction probabilities than a denser patch even if the same set of species use both patches. Of course the Reviewer is correct that habitat also affects which species are present at a site. We include co-occurrence in process uncertainty since co-occurrence does not tell us much about whether an interaction is feasible under ideal conditions (which would certainly include co-occurrence). This speaks to our point above that external factors (habitat, weather, etc.) can affect multiple levels of uncertainty at once. In fact, habitat also likely affects detection uncertainty since it is often harder to observe interactions in dense vegetation. So, in short, separating sources of uncertainty based on the external factors which contribute to them is not a particularly useful endeavour.


	7. Point about temporal scales of interaction [[done]]

		\begin{refquote}
		L76ff Different interactions occur at different temporal scales, so it is important to consider where the role of this study lies. For instance, a pollinator-flower interaction is quick (and even the evidence of it, e.g. pollen on the insect, is not long-lasting) whereas an active gall-former interaction could be present for a couple of months and could be detected for even longer (on senescing leaves).
		\end{refquote}


		\textbf{R:} Long-term interactions may be easier to detect, but we do not see how this affects process uncertainty. Spatial variation in interaction probabilities will affect all interaction types, as does variation in abundances between years, so we cannot conceive of any interactions that are exempt from this issue. The timescale of an interaction (and the evidence it leaves) does affect detection uncertainty, so we have added a note in that section. Long-term interactions may fail to be detected, however, and we now add an example to make it clear that detection uncertainty applies to even long-term interactions such as gall-forming (indeed, our results suggest that uncertainty in gall-forming is quite high).

			\begin{quotation}

				Some types of interactions will have higher detection uncertainty than others (e.g., pollination or predation often take place very quickly while parasitism can last for months or years). Even long-term interactions, however, can be missed, especially if species are difficult to identify or if not all individuals of a species share the interaction. Parasites, for example, are often concentrated in only a few individuals~\citep{Lagrue2015}. If these infected individuals do not happen to be included in a sample, their interactoins will be missed.

			\end{quotation}


	8. Confusion about goal of modelling [[done]]

		\begin{refquote}
		I was struggling to really understand what the authors were really trying to model (partly because of the lack of a link between the theoretical and empirical parts of the paper). Are the authors trying to estimate L (the probability that an interaction is feasible or not – I would describe this as a ‘master’ or meta- network), or is it that they are trying to estimate X|L (the probability that the interaction locally occurs)? I would be interested in both, but the second aspect seemed to be ignored in the gall-former example.
		\end{refquote}

		\textbf{R:} In the case study, we are modelling L (the probability that an interaction is feasible). We do not have quantitative data within sites in our dataset, so we cannot isolate the probability of detecting an interaction at a site from the probability that the interaction occurs. This is also the probability we were most interested in. We do note, however, that one could also model X|L using the same framework if there were independent counts of co-occurrences and interactions within a single site. We now state throughout the manuscript that we are interested in compiling the metaweb, the set of interaction which can feasibly occur. In particular, this is now specified in the introduction. We hope that our goal is now crystal clear.

		\begin{quotation}
			To supplement repeated sampling efforts and reduce uncertainty around unobserved interactions, we suggest researchers use prior knowledge of the same or similar systems. Here, we outline a Bayesian approach to combining repeated sampling and prior knowledge in order to assemble a metaweb. We then demonstrate this approach using an intensively and repeatedly sampled empirical dataset. Finally, we show how a probabilistic understanding of a metaweb allows us to establish confidence intervals around measures of network structure.
			\end{quotation}


	9. Misunderstanding of how biased sampling does not solve problems of uncertainty [[done]]

		\begin{refquote}
		L136 This is a completely different issue, that you do not address in the paper.
		\end{refquote}

		\textbf{R:} We do not believe that biased sampling is a completely different issue as the tendency for some interactions to be sampled more easily than others clearly contributes to varying levels of detection uncertainty. Increasing sampling effort will not do much good if we repeatedly sample the same common interactions and very rarely identify any new interactions. We now address questions about whether or not sampling more will remove uncertainty in a dedicated section (\textbf{Why can't we just sample more?}). We still mention the fact that increased sampling will not reduce uncertainty evenly across interactions as this is an important point to consider when designing sampling protocols and when analysing empirical data. We also point out that combining sampling types is a partial solution to this problem; if different sampling methods have different biases, they may partially cancel each other out. We believe that this addresses the question as much as possible given our focus on analysing collected data rather than collecting new data.


	10. Explain Bayesian approach more simply [[done]]

		\begin{refquote}
		L147 Your Bayesian approach seems important, especially the prior information, and I would have appreciated it being explained more simply.
		\end{refquote}

		\textbf{R:} We have expanded our description of different types of priors and when researchers might prefer one over another. Following a comment from Reviewer 1 we have removed much of the mathematical background for the Bayesian approach, but this material is still present in the supplemental material. We hope that this simplifies the approach adequately.


	11. Integrate L155ff with previous section [[done]]

		\begin{refquote}
		L155ff I think it would be helpful for this section to be integrated with the previous section. It relies on the reader putting quite a lot of work in to understand the link between the two.
		\end{refquote}

		\textbf{R:} We have removed much of the preferatory text explaining which quantity we are most interested in ($\lambda$) and now more explicitly state our goals at the end of the introduction. We hope that the transition to the methods is now less work for a reader.


	12. Ideas presented in L209, L262, L310 are important but explained too briefly [[done]]

		\begin{refquote}
		L209ff This seems a really important set of ideas, but they are exemplified very briefly and very simplistically in the paper (L262, L310). I would have appreciated a much clearer explanation and example.
		\end{refquote}

		\textbf{R:} We are not quite sure what the Reviewer is asking here. $\alpha$ and $\beta$ truly are quite simple (as simple as the mean and standard deviation of a normal distribution) so there is not much more to say about them in themselves. We have expanded our discussion of different types of priors and how they may be obtained, and we hope that this clarifies matters for the Reviewer. We also note that a simple worked example, with accompanying R code, is provided in \emph{Appendix S3} so that readers can see exactly how to obtain $\alpha$ and $\beta$. In case the point of confusion is the idea that $\alpha$ and $\beta$ can be specified or derived depending on the type of prior desired, we have added a line (lines XX-XX) spelling this out.

		\begin{quotation}
			Parameters $\alpha$ and $\beta$ determine the shape of the prior distribution of $\lambda$, which follows a beta distribution. These are called hyper parameters and may be chosen to obtain an intentionally uninformative prior or derived using prior information to create an informed or empirical prior. 
			\end{quotation}


	13. Reframe line 241 in terms of solutions rather than difficulties [[done]]

		\begin{refquote}
		L241 I wonder if you could phrase this more positively as ‘solutions’ rather than just ‘difficulties’?
		\end{refquote}

		\textbf{R:} We appreciate the Reviewer's desire for optimism, but we also selected a high-quality dataset specifically in order to demonstrate that empirically sampling all of the feasible interactions in a system is very unlikely. A lower-quality dataset would work just as well with our framework but would not highlight these difficulties so well. We have therefore kept this line as-is but have added another line (XX-XX) to show how the Bayesian framework provides a partial solution to the problems inherent in even high-quality empirical data.

		\begin{quotation}
		 The high spatiotemporal resolution of this dataset make it ideal for illustrating the difficulties in completely sampling a network; even with such an unusually high sampling effort, we anticipate that there will be many pairs of species which were rarely or never observed together. Using the Bayesian framework above, we can identify which potential interactions are more and less uncertain, allowing us to better predict the true structure of the metaweb.
		 \end{quotation}


	14. Line 283 seems to be a very important point and should be explained more clearly [[done]]

		\textbf{R:} Due to space constraints, we cannot provide an extensive description of Jensen's inequality here. As it is quite easy to look up the inequality by name, we are confident that interested readers can find a description to whatever level of detail suits their interest. 
		[[We could potentially add a demo in a new Appendix. Is this worthwhile?]]


	15. Line 291: does assuming probability of 1 for observed interactions introduce bias? [[done]]

		\begin{refquote}
		L291 I have wondered about this – does assuming a probability of 1 for observed interactions create a bias? The observed interactions are a stochastic set of the possible interactions, so by treating observed interactions as 1 and other (equally likely?) unobserved interactions as <1 will surely bias the network metrics. I’m not sure of the solution and would welcome thoughts on this in the paper.
		\end{refquote}

		\textbf{R:} As we are concerned with the metaweb (the set of feasible interactions) rather than the interactions which occurr at a given site on a given day, we do not think that assuming a probability of 1 for observed interactions introduces bias in our study. We have added a justification of setting the probability of observed interactions to 1 in \emph{Appendix S2}. Note that each posterior web is a prediction of the true metaweb and not a local realization of some interactions drawn from the feasible set. These local webs are more akin to our "filtered webs" in which observed interactions are not guaranteed to appear. We have also added a line (lines XX-XX) to make this clear.
		\medskip
		This is an interesting point, however, as systems with a large risk of false positives (e.g., pollination networks which assume all flower visitors provide pollination service) would be biased by assuming all observed interactions are truly feasible. Assuming that all interactions which are known to be feasible actually occur at each site would also introduce bias - I suspect that this is what the Reviewer may be thinking of. As described above, our study cannot isolate $\chi$ (the probability that a feasible interaction occurs at a particular site), so this is not a relevant question for the present work. Future studies with much, much more detailed data may be able to shed light on this.

		\begin{quotation}
			we created a suite of 100 webs by randomly sampling from each posterior distribution. Each of these webs is a prediction of the structure of the metaweb.
		\end{quotation}


	16. Filtering seems arbitrary [[done]]

		\begin{refquote}
		L298 These seem arbitrary. It is not clear what is filtered, or its justification – is it the unique interactions, unique interaction per site or samples? How do these compare to typical sampling effort?
		\end{refquote}

		\textbf{R:} We have rephrased lines XX-XX to make it clearer that the filtered networks are intended to demonstrate how network structure changes as uncertainty increases (and we miss more interactions). As stated, we filtered networks created using the posterior distributions. There are therefore no sites or samples in question here. We are simply retaining a random 90\%-10\% of the interactions (or removing a random 10\%-90\%; these are equivalent) of the interactions in the "true" (posterior) network. We hope that this rephrasing is clearer. 

			\begin{quotation}
				Measures of network structure which are based on empirical networks that are missing interactions may differ substantially from the values that would be obtained if detection certainty and variation in interactions over space and time could be removed. To demonstrate this, we created a suite of filtered networks for each posterior network. Taking a posterior network as the "true" network, we randomly sampled 90\%, 80\%, 70\%, 60\%, 50\%, 40\%, 30\%, 20\%, and 10\% of the interactions to create a new "filtered" network.
			\end{quotation}


		Note that our model is not concerned with partitioning different sources of variation; the filtering levels we present therefore represent uncertainty from all sources. As such, comparing them directly to "typical sampling effort" would be an apples-to-oranges comparison. We do note that~\citet{Weinstein2017a} found a detectability of 23.3\% for interactions despite high sampling effort,~\citet{Jordano2016} found that about half of unobserved interactions did not qualify as "forbidden links", and~\citet{Bartomeus2013} found that 59\% of interactions were detected. We therefore do not think that the range of filtering levels we applied were particularly unreasonable (although we note that none of the above studies refer to plant-galler networks). That said, the Reviewer is correct that the values we chose were absolutely arbitrary. To make this clear, we now filter in 10\% increments from 90\% to 10\% to illustrate a broader range of uncertainty.


	17. Expand discussion of results on line 321 [[not done - will take this after we see about space]]

		\begin{refquote}
		L321 This is a really important and interesting set of results that are worthy of greater discussion. The issue of metrics from sampled networks is important, but gets lost in the paper. Please expand upon this.
		\end{refquote}

		\textbf{R:} [[This is the network metrics bit - need to expand in discussion.]]


\clearpage

    \bibliographystyle{ecol_let} 
    \bibliography{manual_abbrev} % Abbreviate journal titles.



\end{document}