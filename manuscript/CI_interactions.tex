\documentclass[12pt]{article} 
\usepackage{amsmath} 
\usepackage[dvips]{graphicx}
\usepackage{multirow} 
\usepackage{geometry} 
\usepackage{pdflscape}
\usepackage[labelfont=bf]{caption} 
\usepackage{setspace}
\usepackage[running]{lineno} 
% \usepackage[numbers,sort]{natbib}
\usepackage[round]{natbib} 
\usepackage{array}

\newcommand{\methods}{\textit{Materials \& Methods}}
\newcommand{\SI}{\textit{Appendix}~}

\topmargin -1.5cm % 0.0cm 
\oddsidemargin 0.0cm % 0.2cm 
\textwidth 6.5in
\textheight 9.0in % 21cm
\footskip 1.0cm % 1.0cm

\usepackage{authblk}

\title{???A quantitative framework for investigating the reliability of network construction}


\author{Dominique Gravel, \& Alyssa R. Cirtwill$^{1}$, Anna Ekl\"{o}f, Tomas Roslin, Kate Wootton}
\date{\small$^1$Department of Physics, Chemistry\\ 
and Biology (IFM)\\ 
Link\"{o}ping University\\
Link\"{o}ping, Sweden\\
% \medskip
% $^\dagger$ Corresponding author:\\
% alyssa.cirtwill@gmail.com\\
% +46 723 158464\\
 }

\renewcommand\Authands{ and }

\begin{document} 
\maketitle 
\raggedright
\setlength{\parindent}{15pt} 


\section*{Abstract}

% A quantitative framework for investigating the reliability of network construction
% D. Gravel, D. Carstensen, T. Poisot, D. Stouffer, A. Cirtwill

\section*{Introduction}

    % Present Salix data with holes as an example of uncertainty in data. Focus just on the white and grey, ignore uncertainty in the blacks


    Ecological networks-- which include antagonistic food webs and host-parasite networks as well as plant-pollinator and plant-frugivore mutualist networks --are usually considered to be static representations of the communities and interactions they describe. That is, whether the network is assembled based on aggregated data, a single intensive "snapshot" sample, or expert knowledge, interactions are assumed to occur at constant frequencies~\citep{Olesen2011a}. This assumption conflicts with known variation in interactions over time~\citep{Kitching1987,Olesen2011a} and space~\citep{Kitching1987,Baiser2012} and between individuals of a given species~\citep{Pires2011a,Fodrie2015,Novak2015}. Taking the variances in interaction frequencies into account would therefore represent a substantial increase in the realism of ecological networks as representations of ecological communities.


    Efforts to account for variance in interaction frequencies are complicated by the fact that not only interaction frequencies but network structure vary over space and time. Community composition and species abundances vary from site to site~\citep{Baiser2012} and over time within a site~\citep{Olesen2011a}. Moreover, interactions between species may change even if the participating species remain present at a site but do not co-occur temporally or are too rare to detect each other~\citep{Tylianakis2010}, or through changes to individual preferences~\citep{Fodrie2015}. Several researchers have pointed to the importance of sampling intensity for the assessment of network structure (e.g.,~\citealp{}). The acknowledgement that insufficient sampling effort limits our ability to describe variation in ecological networks has not, however, led to a quantitative framework to deal with the uncertainty of ecological interactions and of sampling.


    The main objective of this study is to develop analytical tools that could be used to better represent the uncertainty in the estimation of pairwise interaction probability. We start with the description of a new Bayesian approach to estimate ecological interactions and of a related R package. We first illustrate the framework with simple quantitative examples, followed by an assessment of the quality of an empirically-estimated plant-pollinator network. Next, we use the framework to provide analytical criteria for improving the sampling of rare interations. Finally, we discuss the implications of uncertainty in the estimation of pairwise interactions on the properties of ecological networks. Through these efforts, we demonstrate both the utility of our approach and the importance of acknowledging the uncertainty inherent in ecological networks.

% <!-- ## Background

%   - Ecological interaction networks are usually considered deterministic, but nature is highly variable and interactions should be considered with their variance
%   - There is spatial and temporal variability in network structure and of pairwise interactions
%   - There used to be a debate on the importance of sampling intensity for the assessment of network structure, but it never led to a quantitative framework dealing with uncertainty of ecological interactions and of sampling

% ## Objective:

%   - The main objective of this study is to develop analytical tools that could be used to better represent the uncertainty in the estimation of pairwise interaction probability
%   - We start with the description of a new bayesian approach to estimate ecological interactions and of a related R package. 
%   - We illustre the framework with simple quantitative examples, and then with the assessment of the quality of an empirical estimate of plant-pollinator networks. 
%   - We further use the framework to provide analytical criteria for improving the sampling of rare interations. 
%   - We discuss the implications of the uncertainty in the estimation of pairwise interactions on the properties of ecological networks -->



\section*{Different uncertainties in computing a network}

THIS SECTIONS BUILDS ON THE SALIX DATA TO ILLUSTRATE THE GAPS THERE ARE IN THE METHOD. DESPITE THE INTENSITY OF THE SAMPLING, THERE ARE SEVERAL HOLES.



\section*{A naive qunatification of interaction probability and uncertainty}

It is getting more and more common to represent interactions as probabilities. Some theoretical models of network structure propose to represent interactions with probabilities, for instance the minmum potential model introduces gaps in the feeding niche of predators (Allesina et al. 2008), while a gaussian probability function is used to represent the niche by Williams et al. (2010). Eklof et al. (2013) introduced variability as well in the computation of network dimensions, allowing the absence of interactions within the n-dimension niche of every species. Empirical investigation of trait-matching constraints often consider the occurrence of interactions as binomial process (e.g. Rohr et al. 2016). There are also ways to perform analysis of probabilistic networks, with almost all metrics having a probabilistic version (Poisot et al. 2015). But there is not yet consensus on what an interaction probability between a pair of species means, and this is definitely a problem when comes time to estimate the uncertainty of both pairwise interactions and entire networks. 

As a start, we will consider how we could naively quantify intetraction probability and its associated uncertainty. We consider that a pair of species have been observed $n$ times co-occurring at one location, and the number of times they interact is $k = 0$. We aim to evaluate the uncertainty of this interaction. The occurrence of an interaction is a Bernoulli trial. Consequently, the number of success $k$ over $n$ trials will follow a binomial distribution: 
    
    \begin{equation}
      X \sim Bin(n,\lambda) ,
    \end{equation}

    \noindent and 

    \begin{equation}
       P(X = k|\lambda,n) = {n \choose k}\lambda^k(1-\lambda)^{n-k} . 
       \label{likelihood}
    \end{equation}

\noindent The parameter $\lambda$, the probability of observing an interaction over an infinite time interval and area, is the quantity we want to estimate from empirical data. The variance of a Bernoulli experiment is simply n$\lambda$(1-$\lambda$). It is important to remember this variance reports the variability of the number of success $k$ for $n$ trials, it is not the variance associated with the estimation of $\lambda$.

The maximal likelihood estimate of $\lambda$ is straightforward to find given $k$ and $n$. It is simply equal to:

    \begin{equation}
      \theta_{MLE} = \frac{k}{n}  .
      \label{theta_MLE}
    \end{equation}

It is possible to compute the confidence interval for this estimate using any of several methods, including the \emph{Wilson score interval}, the \emph{Clopper-Pearson interval}, and the \emph{Agresti-Coull Interval}. Finding this estimate is therefore quite straightforward, but it nonetheless has two drawbacks. First, $\lambda$ is a random variable with a given uncertainty and whose distribution is unknown, it is not a single point estimate. This means that even if $k = 0$ in a given sample, it does not implies necessarily that the two species will never interact. It means that no interaction is the most likely situation, but there is nonetheless a significant chance that the two species could interaction. In contrast with the situation where $k>0$, where we are sure that an interaction is feasible (in which case, the ratio $k/n$ is smaller than $n$ because of detection and process uncertainty), we are not sure that absence of interactions are caused by $L=0$. Second, and most importantly, the number of trials $n$ might be very low in many instances (and some pairs of species might even not be documented), and consequently the uncertainty in the estimation of $\lambda$ might be considerable. We illustrated at Fig. X how the estimate of $\lambda$ could vary with sampling size using the Clopper-Pearson interval. It shows that the 95\% confidence interval requires a signifcant amount of sampling in order to be sure that species are not interacting. 

The situation where $k = 0$ is also problematic because we have very few information to estimate $\lambda$, in particular when $n$ is also small. We therefore propose a Bayesian approach to solve this problem, building on two relevant features of such statistics : posterior distribution of parameter estimates and usage of prior information. But before moving to this direction, we will first take time to better describe what is exactly meant by an interaction probability and appropriately define sources of uncertainty.

So many sources of interaction pooled into a single entity; hard to estimate.

MLE is zero if no interactions detected, but there may still be a substantial probability of interaction should the two species co-occur. [This is particularly important in the context of a changing world, where species not co-occurring today – or species not detected co-occurring today – may well do so tomorrow, forming complex interactions.]




<<<<<<< HEAD


\section*{Why some interactions do not occur ?}

What this is mean exactly ? We consider there are three nested level of uncertainty making this phenomenon a stochastic process :  

\textit{Interaction uncertainty} First, and most fundamentally, we do not know if these species have the appropriate characteristics to interact or not. We define the probability of an interaction $L$ as $P(L)=\lambda$. Obviously, because $k=0$, it is very likely they can not interact if provided enough time and there were no environmental constraint for this interaction to happen. But it is nonetheless possible the interaction is a rare phenomenon that has never been documented before. This source of uncertainty is the one documented by trait-matching models. It arises because every model is imperfect and lack information (i.e. traits) about the constraints on the interaction. In other words, with sufficient sampling and all information accessible, this interaction probability should either tend to 0 or to 1 and the uncertainty vanish.  

\textit{Process uncertainty} It could happen that the interaction is feasible, i.e. $L=1$, but that it does not occur at a given location or at a moment in time because there are local constraints preventing it to occur. We define the realization of the interaction process $X$ given an interaction is feasible as a stochastic process with associated probability $P(X|L)=\chi$. This phenomenon of interaction contingencies is usually not considered in network studies, but there is a rich literature in community ecology about the contingencies of interactions. We imagine for instance that an interaction between a gall and a parasitoid is not recorded at a location because it was the wrong time of the year and the gall has not yet formed (phenological constraints), because a late frost killed the larvae (an abiotic environmental constraint) , another parasitoid species competitively excluded the parasitoid species of interst (a biotic environmental constraint) or simply the parasitoid is too rare (an abundance constraint). 

\textit{Detection uncertainty} Lastly, measurement errors are always source of uncertainty in the observation of ecological processes. We define the detection of an interaction $D$, given an interaction is feasible and occurs in the local conditions, as a stochastic process with associated probability $P(D|X,L)=\delta$. Detection failure could happen for several reasons, for instance if the rearing of a parasitoid fails with inappropriate lab conditions or because of species mis-identification. Some source of detection error could be minimized with appropriate sampling effort ($\chi$ will converge to one with increasing number of collected galls), but other sources are often difficult to reduce (e.g. the occurrence of cryptic species might require molecular analysis for appropriate taxonomic identification).

\textit{What is an observation of "no interaction" ?} The combination of these three sources of uncertainty together leads to many potential explanations for the observation of an absence of interaction, but only the situation where $L = 0$ is a true absence therefore is relevant for the investigation of networks. While the observation of an interaction is straightforward to interpret, absence of interactions must be decomposed in different quantities. It is particularly important to rule out the situations where $D=0 \cup X = 1 \cup L=1$, i.e. the interaction occurred at the location but was not observed, and $D=1 \cup X = 0 \cup L =1$, the interaction would have been detected but did not occur. 

It is important to keep in mind that for network analysis, ecologists seek to measure the occurrence of true absences, which is the joint event $L=1\cup X=1 \cup \D=1$), but in reality they measure the marginal probability $P(L) = k/n$. 



\section*{Estimating detection and process uncertainty}

For the ecologist working on collecting network data, and on later interpreting these data, the considerations above raise a major challenge: how may we infer whether unobserved interactions went undetected due to sampling, or whether they truly do not occur. How then may we refine our sampling approaches to reduce uncertainties, and to gain insights into the impact of multiple processes on field observations? Importantly, some sources can be minimized with appropriate sampling design and efforts, while other sources are difficult or impossible to reduce – since they are generated by chance variation created by the very process in which we are interested.

The basic information that we are collecting consists of interaction matrices of interaction partners. If our counts of whether species A is interacting with species B reflects both uncertainty with respect to whether two species interact when co-occurring at a given site, chance variation in whether the interaction is realized, and uncertainty with respect to whether it is detected when realized, then what can we do to pin down any of these different parts?

A simple consideration will illustrate the problem: assuming that we want to infer the probability of an interaction between two species, A and B. Now assume that in reality, interaction between A and B is plain impossible (i.e. the true (P(L|co-occurrence of A and B = 0). Given no added detection error in observing the incidence of the interaction, then a single observation of species co-occurrence will reveal (very) little regarding the probability of the interaction – the confidence limits for one observation essentially spans from 0 to 1 (see following section). For 5 observations, this confidence limit will still extends to 0.5. Only with thirty observations will it shrink to 0.1. Thus, adding (many) more observations is certainly useful in controlling uncertainty due to stochasticity inherent in the process itself.

The pattern of Fig. X (binomial CL fig from Dom) should be compared to the frequency of co-occurrence of taxa in the Salix-galler data set. Here, most(TO COMPUTE) pairs of species are never found co-occurring, and for species found co-occurring the number of co-occurrences was generally low (Fig from AC and KW). Among the species which did sometimes interact when co-occurring, the incidence of interaction was actually low(TO COMPUTE) (freq histogram Fig from AC and KW). Thus, even in the most extensive data set that we could think of, limited sampling is clearly a major source of uncertainty.

The obvious rule of thumb derived from the above example will be “sample more”, but we note that there are limits to the utility of this motto. Sampling more will clearly reduce uncertainty regarding the upper bound of the probability of interaction, and it will also increase the probability of detecting unlikely interactions (i.e. interactions occurring with a low probability). Yet, since the probability of observing the co-occurrence of two species will always be higher than the probability of observing their interaction (since the probability of interaction is conditional on both interaction partners being present), we will accumulate observations of co-occurrences quicker than we will accumulate observations of interactions. Thus, the more we sample, the more holes will appear in our interaction matrix, which may seem like a counter-intuitive outcome.

As a solution towards deciding whether unobserved interactions were undetected due to sampling, or whether they truly do not occur, Weinstein et al. (2017) used daily repeated sampling rounds to estimate the daily probability of detecting a hummingbird interaction, and to thereby model the observation and process mechanisms (Weinstein, B. G., & Graham, C. H. (2017). On comparing traits and abundance for predicting species interactions with imperfect detection. Food Webs 11; 17-25: https://doi.org/10.1016/j.fooweb.2017.05.002). While conceptually attractive, this approach is unsuitable for interactions occurring over longer time scales (like associations between hosts and parasitoids with a single generation per year), or very rare interactions (since no matter how frequently and extensively we sample, there will still be some rare interactions lurking around). What is worse, the problem persists that if a given interaction is not observed on a given day, then it may still be either because it was impossible that day ((P(L|co-occurrence of A and B)=0), because interaction between the two did occur but was not observed, or from any combination of the two. Thus, from a conceptual perspective, this approach will fail to satisfactorily separating between all sources of uncertainty. An interaction not observed on day t may have gone unobserved either because there were constraints on the process (i.e. the probability was really zero), because of chance variation in the realized incidence of an event associated with a finite probability. Most importantly, if during a series of days, two species are simply never observed co-occurring, then we still have not learnt a thing about their probability of interacting should they do so. In other words, if the two interaction partners do not co-occur, we will still gain no information.

An added complication is that not all sourced of uncertainty are proportional to sample size. To score an interaction between A and B, we will need to identify both partners correctly (a non-trivial problem in many food webs; e.g. Kaartinen et al. 2011 Ecol Entomol; Roslin and Majaneva 2016) and be able to resolve all interactions with a similar likelihood. For both molecular (ref ref) and rearing techniques, given types of interactions may go unnoticed due to technical challenges.

The bottom line is that separating between different sources of uncertainty is difficult indeed. In the best of all possible worlds, we might then use an experimental approach to estimate detection uncertainty: we might create replicate sets of cases where the interaction is really there, then evaluating them and examining the fraction of cases scoring positive. Yet, as anyone attempting these experiments will know, most interaction partners are proving notoriously unwilling to collaborate. Gallers refuse to lay eggs on their host plants (ref ref), parasitoids to attack their hosts when experimentally introduced (Gariepy 2017; ref ref). If we introduce only one of the components (like in the cases where we expose a set of hosts to parasitism; ref ref; Gripenberg et al. xxx) then we are already confounding multiple levels of uncertainty in the outcome – that of interaction uncertainty (whether the species will interact once both there), process uncertainty (whether the interaction will occur if and since the probability of interaction is below one), and detection uncertainty (i.e. whether we will observed the interaction once realized). To perform these experiments in a comprehensive and reliable manner, we will then need to expose a large number of interactions in a comprehensive experiment across space. This type of “cafeteria experiments in space” is not only unfeasible, but also undermining our original objective: If the local occurrence of interactions is uninformative regarding the underlying probabilities of occurrence, then we should be doing something else than wasting a monumental effort on collecting local interaction matrices. <deep sigh and forget that section? > 

As a tentative solution to disentangling observation and process mechanisms, we propose that some insights regarding the detectability of interactions between species not found co-occurring may be gained from data on other species, for which it is known that the interaction is feasible. If we use this information obtain the joint probability of detection and process (e.g. to glean information regarding at how many sites the species are found interacting across the entire dataset), and assuming that most of this pattern is due to variation in detection rate, then insights into the incidence of interactions between species may be gleaned from the accumulation rate of positive interactions at sites were interaction is possible (i.e. with at least one observation of a positive interaction) [this reasoning to be further formalized]






\section*{Bayesian approach to infer interaction probabilities}
=======
 \section*{Bayesian approach to infer interaction probabilities}
>>>>>>> b092309e49105fb62f2da1532121863ddd275eac

    \subsection*{Posterior distribution of the interaction probability}

  We here adopt a Bayesian approach to estimate the distribution of the parameter $\theta$. According to Bayes principle, the posterior distribution of $\theta$ is:

  \begin{equation}
    \underbrace{P(\theta|X,n)}_{Posterior} = \frac{\overbrace{P(X|\theta,n)}^{Likelihood}\overbrace{P(\theta)}^{Prior}}{\underbrace{P(X|N)}_{Normalizer}} .
    \label{posterior}
  \end{equation}

  According to the above description, the likelihood is simply the binomial distribution (Eq.~\ref{likelihood}). Since $\theta$ is a probability it is bounded between 0 and 1 and consequently the most appropriate prior distribution is the beta:

    \begin{equation}
      \theta \sim Beta(\alpha,\beta) , \label{prior}
    \end{equation}

  \noindent which has two shape parameters, $\alpha$ and $\beta$. 

 In some cases it can be complicated to compute the normalizer, but fortunately in our case it exists an analytical solution. The beta-binomial distribution is a conjugate distribution of the binomial distribution. This allows us to analytically compute the posterior distribution of a binomial model with a beta prior distribution. We can re-write the posterior distribution of $\theta$ as:

  \begin{equation}
    P(\theta|k,n) = \frac{\theta^{\alpha+k-1}(1-\theta)^{\beta+n-k-1}}{B(\alpha+k,\beta+n-k)} , \label{posterior}
  \end{equation}

  \noindent where the function $B$ is the beta function:

  \begin{equation}
    Beta(\alpha+k,\beta+n-k) = \frac{\Gamma(\alpha+k)\Gamma(\beta+n-k)}{\Gamma(\alpha+\beta+n)} . \label{betafunction}
  \end{equation}

  The posterior distribution of $\theta$ therefore follows the beta distribution with new parameters $\alpha'= \alpha+k$ and $\beta'=\beta+n-k$. The weight of the prior on the posterior distribution is understood from these definition of the parameters: the difference between the posterior and the prior will increase with $k$ and $n-k$. When plotted, we find the shape of the distribution gets narrower with $k$ and $n$ (see Fig X). 
%
%  The posterior distribution of $\theta$ could be computed with R with the following command:
%
%
%  \vspace{12pt}
%  \noindent\emph{dbeta(x = theta, shape1 = alpha+k, shape1 = beta+n-k)}
%  \vspace{12pt}

  \subsection*{Moments and other properties}

  The fact that the posterior distribution of $\theta$ follows a beta distribution makes it straightforward to compute moments and other properties. 

  The \textbf{average} of $\theta$ is: 
      \begin{equation}
        \bar{\theta} = \frac{\alpha+k}{\alpha+\beta+n} ,
        \label{mean}
      \end{equation}

    and its \textbf{variance} is:  
      \begin{equation}
        Var(\theta|k) = \frac{(\alpha + k)(\beta + n - k)}{(\alpha + \beta + n)^{2}(\alpha + \beta + n +1)}
        \label{variance}
      \end{equation}

    The \textbf{mode} of the distribution is:
      \begin{equation}
        \hat{\theta} = \frac{\alpha + k - 1}{\alpha + \beta + n - 2} .
        \label{mode}
      \end{equation}

  \subsection*{The prior distribution}    
  Parameters $\alpha$ and $\beta$ determine the shape of the prior distribution, which follows a beta distribution. These are called hyper parameters. Below we identify four ways to formulate the prior distribution of $\theta$. 

    \subsubsection*{Uninformative prior}
      
      In absence of any external information, an uniformative prior is the most conservative 
      hypothesis for the distribution of $\theta$. The beta distribution is in this case 
      a uniform distribution  for $Beta(\alpha=1,\beta=1)$. 

    \subsubsection*{Distribution of connectance}
      
      In the literature of ecological networks there is a solid collection of data for which know network connectance, and we can thereby define the connectance distribution. Connectance is measured as $C = L/S^2$, where $L$ is the number of interactions and $S$ is the number of species. It measures the filling of an interaction matrix and thereby expresses the average probability that any two species interact with each other. If we know only the mean $\overline{C}$ and the variance $\sigma_C^2$ of the distribution of $C$, then the beta parameters could be computed as follows using the method of moments:

  \begin{equation}
    \alpha = \overline{C}(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) ,
  \end{equation}

  \begin{equation}
    \beta = (1-\overline{C})(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) .
  \end{equation}
  
%  It is also possible to compute maximum likelihood estimates for a sample of the distribution of $C$.
%  
%   The following piece of R code provides an example: 
%
%  \vspace{12pt}
%  \noindent\emph{
%    library(MASS)\\
%    pars = fitdistr(x = vecC, "beta", start = list(shape1 = 1, shape2 = 1))\$estimate
%  }
%  \vspace{12pt}
%
%
%  Where $vecC$ is a vector of known connectances for a set of networks. 


  \subsubsection*{Degree distribution for the species in the network}.
%
The degree of a node in a network is defined as the number of interactions it has to other nodes. The degree distribution of a network is then the probability distribution of these degrees over the whole network. Connectance is an average property for a complete given network, and it represents the expected
degree (expected number of interactions per species) standardized by the number of species in the network. The standardized degree could therefore be interpreted as an interaction probability. It is consequently possible to
use the degree distribution to inform the prior distribution. The degree distribution could
come from several networks, from a similar network (e.g. a known network at slightly different location) or from the network of interest if interaction probabilities for some species are already documented. The latter approach allows us to apply information from known, abundant species to the rarest species for which interactions are less
frequently documented. The procedure for the estimation of the hyper parameters follows
the same approach as described above for connectance except that each
measurement is at the individual species level instead of the network level.

  \subsubsection*{Trait-matching function}. 
  It is possible to estimate the probability of interaction between a pair of species if there is knowledge of their traits and some functions relating trait matching to interaction probability (Morales-Castilla2015). There are several techniques available to perform this inferrence of interaction probability (REFS). Note that in this case the prior might not be beta distribution and numerical methods might be required to compute the posterior distribution.  

\section*{A quantitative example}
%Perhaps we want to also have a trait matching example in addition to the degree distribution example below?
The framework can be illustrated with a simple quantiative example. Suppose we have $n = 10$ observations of co-occurrence between speices $i$ and species $j$ in a given time interval and area, and $X = 3$ observations of interactions. The maximum likelihood estimate of the interaction probability is simply $\theta_{MLE} = 3/10 = 0.3$. 
% We should probabaly have a value  on the interaction probablitity that differs from the average of the degree distrbution
 Now consider we know that species $i$ is known to interact with 10 other species, which have the following standardized degrees:

\vspace{12pt}
\noindent\emph{
   degree = c(0.66, 0.09, 0.06, 0.08, 0.04, 0.16, 0.06, 0.38, 0.03, 0.02)
    }.
  \vspace{12pt}

The mean of these standardized degrees is 0.158, approximately half the $\theta_{MLE}$ obtained from the observed data. We can use these standardized degrees to inform our prior expectation of the 
distribution of interaction probabilities. With some simple R code (function calculate_parameters, \emph{Appendix S2}), we obtain prior parameters $\alpha$=0.7559544
and $\beta$=3.6710277. Using these priors in equations~\ref{mean} 
and~\ref{variance} above (or in the R function calculate_distribution in \emph{Appendix S2}), we find a prior mean interaction probability of 0.1707607 and a prior variance of 0.0319860.


Adding the observed data (n=10, k=3) and using the same code,
we obtain posterior hyper parameters $\alpha'$=3.755954 and $\beta'$=10.671028 and a posterior mean 0.2603423 and variance 0.0133475. Comparing the posterior distribution to the prior, we see that the posterior is closer to the observed data and that the additional data has reduced the variance.


We may also wish to calculate a credible interval (analogous to the frequentist confidence interval). This is also quite straightforward (see function credible_interval in \emph{Appendix S2}). In this case, a 95\% credible interval for the mean of theta is (0.07755119, 0.50557509).


Now, consider the case where the two species have never been observed interacting across $n$ trials. The question is then ``what is the probability these two species do not interact''? Since it is not possible to prove that the two species could never interact, given the framework above we must fix a threshold below which we consider that there is no interaction. We call this threshold probability $\theta*$. We then use the cumulative distribution function to estimate $P(\theta<\theta*|X=0,n)$. The 
function plot_precision in \emph{Appendix S2} calculates distribution function for 

following script illustrates this probability for an increasing number of trials and $\theta*$=0.1:

  \vspace{12pt}
\noindent\emph{
    \noindent n = seq(0,100,1)
    \\\noindent X = 0
    \\\noindent theta\_star = 0.1
    \\\noindent cdf = pbeta(theta\_star, shape1 = alpha+X, shape2 = beta+n-X)
    \\\noindent plot(n,cdf, type = "l", xlab = "n", ylab = "Cumulative distribution")
    \\\noindent abline(h = 0.95,lty = 3)}.
  \vspace{12pt}

The exercise exemplified above yields a surprising result: it requires \textgreater30 [[or 23??]] observations of no interactions to be 95\% sure that the interaction probability is smaller than 0.1. Note the special case where there is no observation of the two species co-occurring and failing to interact, $n = 0$. In this situation, the posterior distribution converges to the prior distribution. 


\section*{Scaling up uncertainty from pairwise interactions to networks}

It is fairly straigthforward to compute most of network metrics when the different $\lambda$ of the adjacency matrix are known, without variance (Poisot et al. 2015). Several of these metrics derive directly from quantitative indices of network structure. It is not as easy however to understand how the uncertainty in these estimates do influence network metrics. There are multiple non-linearities in the computation of these metrics and that, because of Jensen's inequality (the principle stating that the average of non-linear function of a stochastic variable differs from the function of the average of that variable), any uncertainty could bias the average estimate of the metric and influence its variance as well. For instance, among all of the pairs of species for which only few co-occurrences are observed, many of them are truly interacting. If we consider all of these as having no links, then correcting for these false absence would inflate the number of links and therefore influence metrics such as connectance, nestedness and degree distribution. Computing network properties from probabilistic networks is one thing, but then computing them with uncertainties in these probabilities is another problem, far more challenging. Unfortunately, for now we could only rely on computer simulations to get an answer to this problem. In the following section, we will provide an example with the Salix dataset and show how the uncertainty arising from both absences of co-occurrences and false absences of interactions impact these metrics. We find uncertainty influences both the average and the variance of network metrics, putting in perspective traditional network comparison studies where these metrics are assumed fixed entities. 

\section*{Case study: estimating the uncertainty of a plant-herbivore network}

    \subsection*{Description of the data}

      \emph{Salix}-galler-parasitoid meta-network, here focusing on the smaller \emph{Salix}-galler network. The meta-network consists of interactions between 52? \emph{Salix} species and 222 species of gall-forming insects, sampled from 374 locations in Europe ranging from Sicily to the Arctic. In total, 4295 unique interactions were observed. Each of the 374 locations can be considered as a network in its own right, but here we consider each network as an independent sample from which to build the meta-network.


  \subsection*{Finding the maximum likelihood estimate}

      In a strict Bayesian framework, we wish to use a prior distribution that does not rely on any information from the study at hand. To that end, we use data from another well-described \emph{Salix} galler-parasitoid system (doi: 10.1073/pnas.1513633113). Note that this study used several genotypes of \emph{S. hookeriana} rather than different \emph{Salix} species. We estimated frequencies of  \emph{S. hookeriana} genotype-galler and galler-parasitoid interactions [[host-parasitoid still to-do]] based on the normalized degree of each species in each network component (see \emph{Appendix S1} for details and code).


      Using this prior distribution of galler-\emph{Salix} interaction frequencies, we can obtain parameters for the prior distribution of $\lambda$ in our dataset. Specifically, we obtain $\alpha$=2.807855, $\beta$=2.342815. We are then able to use these priors to estimate the posterior distriution of interaction probabilities given the additional information in our dataset.


    \subsection*{Computing the posterior distribution}

      [[add references to formulae]]

      For species where no co-occurances were observed, we can calculate the MLE estimates for the mean and variance of $\lambda_{ij}$ directly from this prior. These are:
      $\hat{\lambda_{ij}}$=0.5451437, var($\lambda$)=0.0481417.
      This is consistent with the prior data, where the average interaction probability based on the degree distributions of Salix genotypes and gallers was 0.541. [[What's the connectance of our dataset, of we call greys 0?]] This probability does, however, seem rather high for our dataset. This discrepancy may be because~\citep{Balbour2016} were considering genotypes of a single \emph{Salix} species and only four gallers from a single family rather than multiple \emph{Salix} species and galler families as is the case in our dataset.


      For a pair of species where some co-occurances were observed, we can update the prior distribution with these data. If we consider only pairs of species which were observed to co-occur but not to interact, $k_{ij}$ is always 0 and only $n_{ij}$ will vary between species pairs. Thus $\alpha'$=$\alpha$ and $\beta'$=$\beta + n$. At the most extreme case, for a pair of species which co-occurred at all 374 sites and was never observed to interact, our distribution would become:


      $\hat{\lambda_{ij}}$=7.405645 $\times$ 10$^{-3}$, var($\lambda_{ij}$)=1.938755 $\times$ 10$^{-5}$.
      
      With species $i$ and $j$ co-occurring at all 374 sites and never being observed to interact, the maximum likelihood expectation for the probability of an interaction $ij$ is very close to 0 and the variance about this estimate is very narrow. In most cases, however, species $i$ and $j$ did not co-occur at so many sites and our posterior mean and variance retain some influence of the prior.


      Realistic values for n when k=0, based on a sample of 20 random sites:
      n=1: 0.4565121 0.0403385
      n=2: 0.39267022 0.03335076
      n=3: 0.34449379 0.02770543
      n=4: 0.30684696 0.02324331


      [[Plot distribution of interaction probabilities at some reasonable values of n]]


  \subsection*{Computing the credible interval around a probability estimate}

      As well as obtaining posterior means and variances, it is possible to calculate a 95\% credible interval about the posterior mean. 


  \subsection*{How many samples are required to reach a minimal precision}


    - Have code for graphing or returning sample size set up.
    - Plot Increase in sample sizes with decreasing threshold, increasing confidence.




  [[What if we have only one site? Can we use the number of observations of a pair of species interacting with any partners as the number of times they co-occur, and the number of interactions within the pair as k? This will be sort-of valid for insects but not for plants when researchers camp out by plant individuals... ]]


\clearpage

    \bibliographystyle{ecollett} 
    \bibliography{manual_abbrev} % Abbreviate journal titles.


\end{document}


