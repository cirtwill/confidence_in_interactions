\documentclass[12pt]{article} 
\usepackage{amsmath} 
\usepackage[dvips]{graphicx}
\usepackage{multirow} 
\usepackage{geometry} 
\usepackage{pdflscape}
\usepackage[labelfont=bf]{caption} 
\usepackage{setspace}
\usepackage[running]{lineno} 
% \usepackage[numbers,sort]{natbib}
\usepackage[round]{natbib} 
\usepackage{array}

\newcommand{\methods}{\textit{Materials \& Methods}}
\newcommand{\SI}{\textit{Appendix}~}

\topmargin -1.5cm % 0.0cm 
\oddsidemargin 0.0cm % 0.2cm 
\textwidth 6.5in
\textheight 9.0in % 21cm
\footskip 1.0cm % 1.0cm

\usepackage{authblk}

\title{???A quantitative framework for investigating the reliability of network construction}


\author{Dominique Gravel, \& Alyssa R. Cirtwill$^{1}$, Anna Ekl\"{o}f, Tomas Roslin, Kate Wootton}
\date{\small$^1$Department of Physics, Chemistry\\ 
and Biology (IFM)\\ 
Link\"{o}ping University\\
Link\"{o}ping, Sweden\\
% \medskip
% $^\dagger$ Corresponding author:\\
% alyssa.cirtwill@gmail.com\\
% +46 723 158464\\
 }

\renewcommand\Authands{ and }

\begin{document} 
\maketitle 
\raggedright
\setlength{\parindent}{15pt} 


\section*{Abstract}

% A quantitative framework for investigating the reliability of network construction
% D. Gravel, D. Carstensen, T. Poisot, D. Stouffer, A. Cirtwill

\section*{Introduction}

    % Present Salix data with holes as an example of uncertainty in data. Focus just on the white and grey, ignore uncertainty in the blacks


    Ecological networks-- which include antagonistic food webs and host-parasite networks as well as plant-pollinator and plant-frugivore mutualist networks --are usually considered to be static representations of the communities and interactions they describe. That is, whether the network is assembled based on aggregated data, a single intensive "snapshot" sample, or expert knowledge, interactions are assumed to occur at constant frequencies~\citep{Olesen2011a}. This assumption conflicts with known variation in interactions over time~\citep{Kitching1987,Olesen2011a} and space~\citep{Kitching1987,Baiser2012} and between individuals of a given species~\citep{Pires2011a,Fodrie2015,Novak2015}. Taking the variation in interaction frequencies into account would therefore represent a substantial increase in the realism of ecological networks as representations of ecological communities.


    Efforts to account for variance in interaction frequencies are complicated by the fact that not only interaction frequencies but network structure vary over space and time. Community composition and species abundances vary from site to site~\citep{Baiser2012} and over time within a site~\citep{Olesen2011a}. The removal of a species from a site will obviously also remove its interactions. Interactions can also be lost, however, if participating species remain present but do not co-occur temporally or are too rare to detect each other~\citep{Tylianakis2010}, or through changes to individual preferences~\citep{Fodrie2015}. Several researchers have pointed to the importance of sampling intensity for the assessment of network structure (e.g.,~\citealp{Martinez1999,Bluthgen2006,XX}). Despite this, the acknowledgement that insufficient sampling effort limits our ability to describe variation in ecological networks has not yet led to a quantitative framework to deal with the uncertainty of ecological interactions and of sampling.


    The main objective of this study is to develop analytical tools that could be used to better represent the uncertainty in the estimation of pairwise interaction probability. We start with the description of a new Bayesian approach to estimate ecological interactions and of a related R package. [[We first illustrate the framework with a simple quantitative example. Next, we use the framework to provide analytical criteria for improving the sampling of rare interations. Finally, we discuss the implications of uncertainty in the estimation of pairwise interactions on the properties of ecological networks.]] Through these efforts, we demonstrate both the utility of our approach and the importance of acknowledging the uncertainty inherent in ecological networks.
    % List of sections may not be accurate any more. Update when paper reaches its final form.


\section*{Different uncertainties in computing a network}

THIS SECTIONS BUILDS ON THE SALIX DATA TO ILLUSTRATE THE GAPS THERE ARE IN THE METHOD. DESPITE THE INTENSITY OF THE SAMPLING, THERE ARE SEVERAL HOLES.



\section*{A naive qunatification of interaction probability and uncertainty}

  It is getting more and more common to represent interactions as probabilities in theoretical models of network structure. For example, the minimum potential model introduces gaps in the feeding niche of predators by sampling based on the likelihood of each interaction~\citep{Allesina2008}, while a gaussian probability function is used to represent the niche by~\citet{Williams2010}. \citet{Eklof2013} also introduced variability  in the computation of network dimensions, allowing the absence of interactions within the n-dimension niche of every species. Empirical investigation of trait-matching constraints often consider the occurrence of interactions as binomial process (e.g.,~\citealp{Rohr2016}). There are also ways to perform analysis of probabilistic networks, with almost all metrics having a probabilistic version~\citep{Poisot2016}. But there is not yet consensus on what an interaction probability between a pair of species means, and this is definitely a problem when comes time to estimate the uncertainty of both pairwise interactions and entire networks. 


  As a start, we will consider how we could naively quantify intetraction probability and its associated uncertainty for an interaction that has not yet been observed. We consider that a pair of species have been observed $n$ times co-occurring at one location, and the number of times they have been observed interacting is $k = 0$. We aim to evaluate the uncertainty of this interaction. The occurrence of an interaction is a Bernoulli trial. Consequently, the number of success $k$ over $n$ trials will follow a binomial distribution: 
      
      \begin{equation}
        X \sim Bin(n,\lambda) ,
      \end{equation}

      \noindent and 

      \begin{equation}
         P(X = k|\lambda,n) = {n \choose k}\lambda^k(1-\lambda)^{n-k} . 
         \label{likelihood}
      \end{equation}

  \noindent The parameter $\lambda$, the probability of observing an interaction over an infinite time interval and area, is the quantity we want to estimate from empirical data. 
  The maximal likelihood estimate (MLE) of $\lambda$ is straightforward to find given $k$ and $n$. It is simply equal to:

      \begin{equation}
        \theta_{MLE} = \frac{k}{n}  .
        \label{theta_MLE}
      \end{equation}

  The variance of a Bernoulli experiment is simply $n\lambda$(1-$\lambda$). It is important to remember this variance reports the variability of the number of success $k$ for $n$ trials and is not the variance associated with the estimation of $\lambda$.
  Given this variance, it is possible to compute the confidence interval for the MLE of $\lambda$ using any of several methods, including the \emph{Wilson score interval}, the \emph{Clopper-Pearson interval}, and the \emph{Agresti-Coull Interval}. Finding this estimate is therefore quite straightforward, but it nonetheless has two drawbacks. First, $\lambda$ is a random variable with a given uncertainty and whose distribution is unknown, it is not a single point estimate. This means that even if $k = 0$ in a given sample, this does not necessarily imply that the two species will never interact. It means that no interaction is the most likely situation but there is nonetheless a significant chance that the two species could interaction. In contrast with the situation where $k>0$, when we are sure that an interaction is feasible, 
  % (in which case, the ratio $k/n$ is smaller than $n$ because of detection and process uncertainty),  % This parenthetical makes the sentence very long. Is it necessary?
  we are not sure that absence of interactions is caused by $L=0$. Second, and most importantly, the number of trials $n$ might be very low in many instances (and some pairs of species might even not be documented once). Consequently, the uncertainty in the estimation of $\lambda$ might be considerable. We illustrated in Fig. X how the estimate of $\lambda$ could vary with sampling size using the Clopper-Pearson interval. It shows that the 95\% confidence interval requires a signifcant amount of sampling in order to be sure that species are not interacting. 
  % Is the Clopper-Pearson interval the one in Dom's code snippets? If so, this is Fig.~\ref{Salix_cdfs}


  The situation where $k = 0$ is also problematic because we have very little information with which to estimate $\lambda$, in particular when $n$ is also small. We therefore propose a Bayesian approach to solve this problem, building on two relevant features of such statistics : posterior distribution of parameter estimates and usage of prior information. Before moving to this direction, we will first take time to better describe what is exactly meant by an interaction probability and appropriately define sources of uncertainty.


  So many sources of interaction pooled into a single entity; hard to estimate.

  MLE is zero if no interactions detected, but there may still be a substantial probability of interaction should the two species co-occur. [This is particularly important in the context of a changing world, where species not co-occurring today – or species not detected co-occurring today – may well do so tomorrow, forming complex interactions.]


\section*{Why do some interactions not occur?}

  What does this question mean exactly? We consider that there are three nested levels of uncertainty making the occurance of any interaction a stochastic process:  


    \subsection*{Interaction uncertainty} 

    First, and most fundamentally, we do not know whether or not a pair of species have the appropriate characteristics to interact. We define the probability of an interaction $L$ as $P(L)=\lambda$. Obviously, because $k=0$, it is very likely that they cannot interact even if there were no time or environmental constraints preventing the interaction. But it is nonetheless possible that the interaction is a rare phenomenon that has never been documented before. This source of uncertainty is the one documented by trait-matching models~\citep{}. It arises because every model is imperfect and lacks information (i.e. traits) about the constraints on the interaction. In other words, with sufficient sampling and all information accessible, this interaction probability should either tend to 0 or to 1 and the uncertainty vanish.  


    \subsection*{Process uncertainty} 

    It could be that the interaction is feasible, i.e. $L=1$, but that it does not occur at a given location or moment in time because there are local constraints preventing it from occurring. We define the realization of the interaction process $X$ given that the interaction is feasible as a stochastic process with associated probability $P(X|L)=\chi$. This phenomenon of interaction contingencies is usually not considered in network studies, but there is a rich literature in community ecology about the contingencies of interactions~\citep{}. We imagine for instance that an interaction between a gall and a parasitoid might not be recorded at a location because it was the wrong time of the year and the gall had not yet formed (phenological constraints), a late frost killed the larvae (an abiotic environmental constraint), another parasitoid species competitively excluded the parasitoid species of interst (a biotic environmental constraint) or simply the parasitoid is too rare to interact with all of its viable hosts (an abundance constraint). 


    \subsection*{Detection uncertainty} 

    Lastly, measurement errors are always source of uncertainty in the observation of ecological processes. We define the detection of an interaction $D$, given an interaction is feasible and occurs in the local conditions, as a stochastic process with associated probability $P(D|X,L)=\delta$. Detection failure could happen for several reasons, for instance if the rearing of a parasitoid fails with inappropriate lab conditions or because of species mis-identification. Some sources of detection error could be minimized with appropriate sampling effort ($\delta$ will converge to one with increasing number of collected galls), but other sources are often difficult to reduce (e.g. the occurrence of cryptic species might require molecular analysis for appropriate taxonomic identification).


    \subsection*{What is an observation of "no interaction"?} 

    The combination of these three sources of uncertainty together leads to many potential explanations for the observation of an absence of interaction, but only the situation where $L = 0$ (a true absence) is relevant for the investigation of networks. While the observation of an interaction is straightforward to interpret, absence of interactions must be decomposed in different quantities. It is particularly important to rule out the situations where $D=0 \cup X = 1 \cup L=1$, i.e. the interaction occurred at the location but was not observed, and $D=1 \cup X = 0 \cup L =1$, the interaction is feasible and would have been detected but did not occur at the local site. 


  It is important to keep in mind that for network analysis, ecologists seek to measure the occurrence of true absences, which is the joint event $L=0 \cup X=1 \cup D=1$), but in reality they measure the marginal probability $P(L) = k/n$. % I'm pretty sure this should be L=0 but X=1 and D=1: interaction not feasible but site and detection perfect.


\section*{Estimating detection and process uncertainty}

  For the ecologist working on collecting network data, and on later interpreting these data, the considerations above raise a major challenge: how may we infer whether unobserved interactions went undetected due to sampling, or whether they truly do not occur. How then may we refine our sampling approaches to reduce uncertainties, and to gain insights into the impact of multiple processes on field observations? Importantly, some sources can be minimized with appropriate sampling design and efforts, while other sources are difficult or impossible to reduce – since they are generated by chance variation created by the very process in which we are interested.


  The basic information that we are collecting consists of matrices of interaction partners. Our count of interactions between species A and species B reflects uncertainty with respect to whether two species interact when co-occurring at a given site, chance variation in whether the interaction is realized, and uncertainty with respect to whether it is detected when realized. In this case, what can we do to pin down any of these different types of variation?


  A simple example will illustrate the problem: assume that we want to infer the probability of an interaction between two species, A and B. Now assume that in reality, interaction between A and B is completely impossible (i.e. the true $\lambda$= 0). Given no added detection error in observing the incidence of the interaction, then a single observation of species co-occurrence will reveal (very) little regarding the probability of the interaction – the confidence limits for one observation essentially spans from 0 to 1 (see following section). For 5 observations, this confidence limit will still extends to 0.5. Only with thirty observations will it shrink to 0.1. Thus, adding (many) more observations is certainly useful in controlling uncertainty due to stochasticity inherent in the process itself.

  \begin{figure}
    \caption{This figure illustrates the upper bound (solid black line) of a 95\% confidence interval for the interaction probability $\lamba$ when there is no observation of an interaction ($k = 0$) and $n$ observations of the two species co-occurring at a given location. The confidence interval is based on the Clopper-Pearson derivation from the beta distribution. A threshold interaction probability of 0.1 is indicated by the dotted red line.}
    \label{upper_limits}
    \includegraphics*[width=.8\textwidth]{figures/upper_limit_DG.eps}
  \end{figure}


  The pattern of Fig.~\ref{upper_limits} should be compared to the frequency of co-occurrence of taxa in the Salix-galler data set. Here, most (3986 out of 4992) pairs of species are never found co-occurring, and for species found co-occurring the number of co-occurrences was generally low (Fig.~\ref{histograms}A). Among the species which did sometimes interact when co-occurring, the incidence of interaction was actually low. Only 141 pairs of species were observed interacting: of these, 26 were observed interacting only once and 48.2\% were observed interacting five or fewer times (Fig.~\ref{histograms}B). Thus, even in the most extensive data set that we could think of, limited sampling is clearly a major source of uncertainty.


  \begin{figure}
    \caption{\textbf{A)} Most pairs of \emph{Salix} and galler species were never observed co-occurring despite the high levels of replication in our example dataset. For those that were observed together at least once, the number of observed co-occurances was generally small (\textless10). Here we show a histogram of the number of pairs of species observed co-occurring at least once. 3986 pairs of species were never observed co-occurring: this is represented by the upwards triangle at 0. \textbf{B)} Most pairs of species that were observed at the same site were never observed interacting. Here we show a histogram of the number of observed interactions within pairs of co-occurring species.}
    \label{histograms}
    \includegraphics*[width=.8\textwidth]{figures/Salix_Galler_histogram.eps}
    \end{figure}


  The obvious rule of thumb derived from the above example is “sample more”, but we note that there are limits to the utility of this motto. Sampling more will clearly reduce uncertainty regarding the upper bound of the probability of interaction, and it will also increase the probability of detecting unlikely interactions (i.e. interactions occurring with a low probability). Yet, since the probability of observing the co-occurrence of two species will always be higher than the probability of observing their interaction (since the probability of interaction is conditional on both interaction partners being present), we will accumulate observations of co-occurrences faster than we will accumulate observations of interactions. Thus, the more we sample, the more zeros will appear in our interaction matrix, which may seem like a counter-intuitive outcome.

  As a solution towards deciding whether unobserved interactions were undetected due to sampling, or whether they truly do not occur,~\citet{Weinstein2017} used daily repeated sampling rounds to estimate the daily probability of detecting a hummingbird interaction, and to thereby model the observation and process mechanisms~\citep{Weinstein2017}. While conceptually attractive, this approach is unsuitable for interactions occurring over longer time scales (e.g., associations between hosts and parasitoids with a single generation per year), or very rare interactions (since no matter how frequently and extensively we sample, there will still be some interactions lurking around). What is worse, the problem persists that if a given interaction is not observed on a given day, this could be either because it was impossible that day despite being otherwise feasible (P($X|L=1$=0), because interaction between the two did occur but could not be observed (P($D|X$=1,L=1)=0), or from any combination of the two. From a conceptual perspective, this approach will thus fail to satisfactorily distinguish between sources of uncertainty. An interaction not observed on day $t$ may have gone undetected either because there were constraints on the process (i.e. the probability $\lambda$ was really zero) or because of chance variation in the realized incidence of an event associated with a finite probability. Most importantly, if two species are never observed co-occurring during several days of sampling then we have learned nothing about their probability of interacting if they should ever co-occur. In other words, there is no information without co-occurance.


  An added complication is that not all sources of uncertainty are proportional to sample size. To record an interaction between A and B, we need to identify both partners correctly (a non-trivial problem in many food webs; e.g.~\citet{Kaartinen2011,Roslin2016}) and be able to resolve all interactions with a similar likelihood. For both molecular~\citep{} and rearing~\citep{} techniques, certain types of interactions may go unnoticed due to technical challenges. This can bias the set of recorded interactions.


  The bottom line is that separating different sources of uncertainty is difficult indeed. In the best of all possible worlds, we might use an experimental approach to estimate detection uncertainty by creating replicate cases where the interaction really occurs and then evaluating the fraction of cases where the interaction is detected. Yet, as anyone attempting these experiments will know, most interaction partners are notoriously unwilling to collaborate. Gallers refuse to lay eggs on their host plants in captivity (ref ref) and parasitoids decline to attack their hosts when experimentally introduced (Gariepy 2017; ref ref). If we introduce only one of the components (as in the cases where we expose a set of hosts to parasitism; ref ref; Gripenberg et al. xxx) then we are already confounding multiple levels of uncertainty since it is not certain whether the interaction will occur or whether we can detect it. To perform these experiments in a comprehensive and reliable manner, we will then need to replicate a large number of interactions in a comprehensive experiment across space. This type of “cafeteria experiments in space” is not only unfeasible, but also undermines our original objective: If the local occurrence of interactions is uninformative regarding the underlying probabilities of occurrence, then is not likely to be worthwhile collecting these local interaction matrices in the first place. <deep sigh and forget that section? > 


  As an alternative to abandoning empirical networks or continuing to ignore the uncertainty inherent in undetected observations, we propose that some insight regarding the detectability of interactions between species not found co-occurring may be gained from data on other species between which interactions are known to be feasible. If we use this information obtain the joint probability of detection and process (e.g. to glean information regarding at how many sites the species are found interacting across the entire dataset), and assuming that most of this pattern is due to variation in detection rate, then insights into the incidence of interactions between species may be gleaned from the accumulation rate of positive interactions at sites were interaction is possible (i.e. with at least one observation of a positive interaction) [this reasoning to be further formalized]


\section*{Bayesian approach to infer interaction probabilities}

    \subsection*{Posterior distribution of the interaction probability}

      We here adopt a Bayesian approach to estimate the distribution of the parameter $\theta$. According to Bayes principle, the posterior distribution of $\theta$ is:

      \begin{equation}
        \underbrace{P(\theta|X,n)}_{Posterior} = \frac{\overbrace{P(X|\theta,n)}^{Likelihood}\overbrace{P(\theta)}^{Prior}}{\underbrace{P(X|N)}_{Normalizer}} .
        \label{posterior}
      \end{equation}

      According to the above description, the likelihood is simply the binomial distribution (Eq.~\ref{likelihood}). Since $\theta$ is a probability it is bounded between 0 and 1 and consequently the most appropriate prior distribution is the beta:

      \begin{equation}
        \theta \sim Beta(\alpha,\beta) , \label{prior}
      \end{equation}

      \noindent which has two shape parameters, $\alpha$ and $\beta$. 

     In some cases it can be complicated to compute the normalizer, but fortunately in our case an analytical solution exists. The beta-binomial distribution is a conjugate distribution of the binomial distribution. This allows us to analytically compute the posterior distribution of a binomial model with a beta prior distribution. We can re-write the posterior distribution of $\theta$ as:

      \begin{equation}
        P(\theta|k,n) = \frac{\theta^{\alpha+k-1}(1-\theta)^{\beta+n-k-1}}{B(\alpha+k,\beta+n-k)} , \label{posterior}
      \end{equation}

      \noindent where the function $B$ is the beta function:

      \begin{equation}
        Beta(\alpha+k,\beta+n-k) = \frac{\Gamma(\alpha+k)\Gamma(\beta+n-k)}{\Gamma(\alpha+\beta+n)} . \label{betafunction}
      \end{equation}

      The posterior distribution of $\theta$ therefore follows the beta distribution with new parameters $\alpha'= \alpha+k$ and $\beta'=\beta+n-k$. The weight of the prior on the posterior distribution is understood from these definition of the parameters: the difference between the posterior and the prior will increase with $k$ and $n-k$. When plotted, we find the shape of the distribution gets narrower with $k$ and $n$ (Fig.~\ref{Salix_pdfs}). 
      %
      %  The posterior distribution of $\theta$ could be computed with R with the following command:
      %
      %
      %  \vspace{12pt}
      %  \noindent\emph{dbeta(x = theta, shape1 = alpha+k, shape1 = beta+n-k)}
      %  \vspace{12pt}

      \begin{figure}[ht]
        \label{Salix_pdfs}
        \caption{Using a prior distribution based on the \emph{Salix}-galler network in~\citet{Barbour2016}, we can calculate posterior distributions for the probability of interaction ($\lambda$) between two species that have not yet been observed interacting. Here we show posterior distributions for $\lambda$ ranging from the prior distribution (N=0 observed co-occurances) to the distribution obtained when the pair of species has been observed co-occurring 50 times. The distribution narrows and approaches zero as the sample size increases, but never includes zero.}
        \includegraphics*[width=.8\textwidth]{figures/Salix_Galler_pdfs_increasing_N.eps}
        \end{figure}


    \subsection*{Moments and other properties}

      The fact that the posterior distribution of $\theta$ follows a beta distribution makes it straightforward to compute moments and other properties. 

      The \textbf{average} of $\theta$ is: 
          \begin{equation}
            \bar{\theta} = \frac{\alpha+k}{\alpha+\beta+n} ,
            \label{mean}
          \end{equation}

        and its \textbf{variance} is:  
          \begin{equation}
            Var(\theta|k) = \frac{(\alpha + k)(\beta + n - k)}{(\alpha + \beta + n)^{2}(\alpha + \beta + n +1)}
            \label{variance}
          \end{equation}

        The \textbf{mode} of the distribution is:
          \begin{equation}
            \hat{\theta} = \frac{\alpha + k - 1}{\alpha + \beta + n - 2} .
            \label{mode}
          \end{equation}

    \subsection*{The prior distribution}    

      Parameters $\alpha$ and $\beta$ determine the shape of the prior distribution, which follows a beta distribution. These are called hyper parameters. Below we identify four ways to formulate the prior distribution of $\theta$. 


      \subsubsection*{Uninformative prior}
        
          In absence of any external information, an uniformative prior is the most conservative hypothesis for the distribution of $\theta$. The beta distribution is in this case a uniform distribution  for $Beta(\alpha=1,\beta=1)$. 

      \subsubsection*{Distribution of connectance}
        
          In the literature of ecological networks there is a solid collection of data for which know network connectance and from which we can define the connectance distribution. Connectance is measured as $C = L/S^2$, where $L$ is the number of interactions and $S$ is the number of species. It measures the filling of an interaction matrix and thereby expresses the average probability that any two species interact with each other. If we know only the mean $\overline{C}$ and the variance $\sigma_C^2$ of the distribution of $C$, then the beta parameters could be computed as follows using the method of moments:

          \begin{equation}
          \alpha = \overline{C}(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) ,
          \end{equation}

          \begin{equation}
          \beta = (1-\overline{C})(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) .
          \end{equation}
    
          %  It is also possible to compute maximum likelihood estimates for a sample of the distribution of $C$.
          %  
          %   The following piece of R code provides an example: 
          %
          %  \vspace{12pt}
          %  \noindent\emph{
          %    library(MASS)\\
          %    pars = fitdistr(x = vecC, "beta", start = list(shape1 = 1, shape2 = 1))\$estimate
          %  }
          %  \vspace{12pt}
          %
          %
          %  Where $vecC$ is a vector of known connectances for a set of networks. 


      \subsubsection*{Degree distribution for the species in the network - or - Interaction probabilities in a similar network}.

          [[Should we still have this? At the workshop we talked about how interaction probabilities depend on the degrees of both species and so I'm using predicted interaction probabilities (degreeA*degreeB) in the galler example. A writeup for that process follows the original text:]]
          The degree of a node in a network is defined as the number of interactions it has to other nodes. The degree distribution of a network is then the probability distribution of these degrees over the whole network. Connectance is an average property for a complete given network, and it represents the expected degree (expected number of interactions per species) standardized by the number of species in the network. The standardized degree could therefore be interpreted as an interaction probability. It is consequently possible to use the degree distribution to inform the prior distribution. The degree distribution could come from several networks, from a similar network (e.g. a known network at slightly different location) or from the network of interest if interaction probabilities for some species are already documented. The latter approach allows us to apply information from known, abundant species to the rarest species for which interactions are less frequently documented. The procedure for the estimation of the hyper parameters follows the same approach as described above for connectance except that each measurement is at the individual species level instead of the network level.

         
          If our focal network describes a similar system to that in a known network, we can use the distribution of interaction probabilities in that network to inform our prior. The probability of any interaction $L_ij$ depends on the degrees of species $i$ and $j$. The degree of a node is defined as the number of interactions it has with other nodes. Connectance, as the average number of links per species in the whole network, is thus also the expected degree for any given species normalized by the number of species in the network. Using normalized degrees $\Delta_i$ and $\Delta_j$ (i.e., degrees divided by the number of species in the network), we can obtain the probability of interaction $L_ij$=$\Delta_i$\times$\Delta_j$. The distribution of these interaction probabilities derived from a similar network or a suite of networks can be used to establish a prior distribution before any data from the focal network are collected. We could also use this approach to build a prior distribution using known interaction probabilities for some species in the focal network. The latter approach allows us to apply information from known, abundant species to the rarest species for which interactions are less frequently documented. The procedure for the estimation of the hyper parameters follows the same approach as described above for connectance except that each measurement is at the individual interaction level instead of the network level.


      \subsubsection*{Trait-matching function}. 

          It is possible to estimate the probability of interaction between a pair of species if there is knowledge of their traits and some functions relating trait matching to interaction probability~\citep{Morales-Castilla2015}. There are several techniques available to perform this inferrence of interaction probability~\citep{} (REFS). Note that in this case the prior might not be beta distribution and numerical methods might be required to compute the posterior distribution.  


\section*{A quantitative example}

  %Perhaps we want to also have a trait matching example in addition to the degree distribution example below?
  % Are degree distributions valid priors for interaction probabilities in a unipartite web? For the Salix-gall dataset we're using interaction probabilities as priors (since the degree of both Salix and galler matter)... maybe we should rephrase this to predict the degree of species $i$ based on the degrees of 10 other species in the network?
  The Bayesian framework can be illustrated with a simple quantiative example. Suppose we have $n = 10$ observations of co-occurrence between species $i$ and species $j$ in a given time interval and area, and $X = 3$ observations of interactions. The maximum likelihood estimate of the interaction probability is simply $\theta_{MLE} = 3/10 = 0.3$. 
  % We should probabaly have a value  on the interaction probablitity that differs from the average of the degree distrbution
   Now consider we know that species $i$ is known to interact with 10 other species, which have the following normalized degrees:

    \vspace{12pt}
    \noindent\emph{
       degree = c(0.66, 0.18, 0.12, 0.16, 0.84, 0.32, 0.12, 0.76, 0.06, 0.04)
        }.
      \vspace{12pt}

    If the network has 20 species total, then species $i$ has a normalized degree of 0.5 and
    we can use this to obtain the following set of interaction probabilities for species $i$ and each of its interaction partners:

    \vspace{12pt}
    \noindent\emph{
       int_probs = c(0.33, 0.09, 0.06, 0.08, 0.42, 0.16, 0.06, 0.38, 0.03, 0.02)
        }.
      \vspace{12pt}


    The mean of these interaction probabilities is 0.163, approximately half the $\theta_{MLE}$ obtained from the observed data. We can use the distribution of these interaction probabilities as our prior distribution and estimate the uncertainty surrounding our $\theta_{MLE}$. With some simple R code (function calculate\_parameters, \emph{Appendix S2}), we obtain prior parameters $\alpha$=1.050830
    and $\beta$=5.365892. Using these priors in equations~\ref{mean} 
    and~\ref{variance} above (or in the R function calculate\_distribution in \emph{Appendix S2}), we find a prior mean interaction probability of 0.16376436 and a prior variance of 0.02134199.


    Adding the observed data (n=10, k=3) and using the same code,
    we obtain posterior hyper parameters $\alpha'$=4.05083 and $\beta'$=12.36589 and a posterior mean 0.247 and variance 0.011 for the probability of. Comparing the posterior distribution to the prior, we see that the posterior is closer to the observed data and that the additional data has reduced the variance.


    We may also wish to calculate a credible interval (analogous to the frequentist confidence interval). This is also quite straightforward in R (see function credible\_interval in \emph{Appendix S2}). In this case, a 95\% credible interval for the mean of theta is (0.077, 0.474).


    Now, consider the case where the two species have never been observed interacting across $n$ trials. The question is then ``what is the probability these two species do not interact''? Since it is not possible to prove that the two species could never interact, given the framework above we must fix a threshold below which we consider that there is no interaction. We call this threshold probability $\theta*$. We then use the cumulative distribution function to estimate $P(\theta<\theta*|X=0,n)$ for different $n$. The 
    function plot\_precision in \emph{Appendix S2} calculates distribution function for $\theta*$ with an increasing number of trials. The figure below illustrates this distribution for $\theta*$=0.1.


    The exercise exemplified above yields a surprising result: it requires \textgreater24 observations of no interactions to be 95\% sure that the interaction probability is smaller than 0.1. Note the special case where there is no observation of the two species co-occurring and failing to interact, $n = 0$. In this situation, the posterior distribution converges to the prior distribution. 


\section*{Scaling up uncertainty from pairwise interactions to networks}

    It is fairly straigthforward to compute most of network metrics when the different $\lambda$ of the adjacency matrix are known, without variance~\citep{Poisot2016}. Several of these metrics derive directly from quantitative indices of network structure which are equivalent to $\lambda$; the remainder, originally defined for binary networks, can be adjusted to account for interaction probabilities between zero and one. It is not as easy, however, to understand how the uncertainty in these estimated interaction probabilities influences network metrics. Computation of these metrics involves non-linear functions and therefore, because of Jensen's inequality (which states that the average of non-linear function of a stochastic variable differs from the function of the average of that variable), any uncertainty in $\lambda$s could bias both the mean and variance of a network metric. For instance, assume that among all pairs of species with few observed co-occurances there are many pairs which truly interact.    If we begin with no observed links for these pairs, then correcting for these false absences will inflate the number of links and consequently influence metrics such as connectance, nestedness, and degree distribution. While we can, as described above, calculate these network metrics using fixed estimates for $\lambda$ no analytical solution currently exists for uncertain $\lambda$. Instead we must rely on computer simulations. In the following section, we will provide an example with the Salix dataset and show how the uncertainty arising from both absences of co-occurrences and false absences of interactions impact these metrics. We find uncertainty influences both the average and the variance of network metrics, putting in perspective traditional network comparison studies where these metrics are assumed fixed entities. 

\section*{Case study: estimating the uncertainty of a plant-herbivore network}

    \subsection*{Description of the data}

      [[Kate, can you expand this?]]
      \emph{Salix}-galler-parasitoid meta-network, here focusing on the smaller \emph{Salix}-galler network. The meta-network consists of interactions between 52? \emph{Salix} species and 222 species of gall-forming insects, sampled from 374 locations in Europe ranging from Sicily to the Arctic. In total, 4295 unique interactions were observed. Each of the 374 locations can be considered as a network in its own right, but here we consider each network as an independent sample from which to build the meta-network.


    \subsection*{Finding the maximum likelihood estimate}

      [[Do we want the host-parasitoid site too, or is the plant-galler enough? This is feeling long already.]]
      In a strict Bayesian framework, we wish to use a prior distribution that does not rely on any information from the study at hand. To that end, we use data from another well-described \emph{Salix} galler-parasitoid system~\citep{Barbour2016,Barbour2016Dryad}. Note that this study used several genotypes of \emph{S. hookeriana} rather than different \emph{Salix} species. We estimated frequencies of  \emph{S. hookeriana} genotype-galler interactions based on the normalized degree of each species in each network component (see \emph{Appendix S1} for details and code).


      Using this prior distribution of galler-\emph{Salix} interaction frequencies, we can obtain parameters for the prior distribution of $\lambda$ in our dataset. Specifically, we obtain $\alpha$=2.807855, $\beta$=2.342815. We are then able to use these priors to estimate the posterior distriution of interaction probabilities given the additional information in our dataset.


    \subsection*{Computing the posterior distribution}

      For species where no co-occurances were observed, we can 
      calculate the MLE estimates for the mean and variance of 
      $\lambda_{ij}$ directly from this prior following 
      equations~\ref{mean} and~\ref{variance} 
      (see \emph{Appendix S2} for R implementation). The prior 
      distribution we obtain based on~\citet{Barbour2016,Barbour2016Dryad} is:
      $\hat{\lambda_{ij}}$=0.545, var($\lambda$)=0.048.
      This is consistent with the prior data, where the average 
      interaction probability based on the degree distributions of Salix genotypes and gallers was 0.541. [[What's the connectance of our dataset, if we call greys 0?]] This probability does, however, seem rather high for our dataset. This discrepancy may reflect the differences in scale between a network containing different genotypes of a single \emph{Salix} species and four gallers from a single family and a network containing many \emph{Salix} species and gallers from many families as is the case in our dataset.


      For a pair of species where some co-occurances were observed, we can update the prior distribution with these data. If we consider only pairs of species which were observed to co-occur but not to interact, $k_{ij}$ is always 0 and only $n_{ij}$ will vary between species pairs. Thus $\alpha'$=$\alpha$ and $\beta'$=$\beta + n$. At the most extreme case, for a pair of species which co-occurred at all 374 sites and was never observed to interact, our distribution would become:


      $\hat{\lambda_{ij}}$=7.405645 $\times$ 10$^{-3}$, var($\lambda_{ij}$)=1.938755 $\times$ 10$^{-5}$.
      
      With species $i$ and $j$ co-occurring at all 374 sites and never being observed to interact, the maximum likelihood expectation for the probability of an interaction $ij$ is very close to 0 and the variance about this estimate is very narrow. In most cases, however, species $i$ and $j$ did not co-occur at so many sites and our posterior mean and variance retain some influence of the prior. Nevertheless, as the number of observed co-occurances increases, the posterior mean becomes closer to zero and the posterior variance decreases (Fig.~\ref{Salix_pdfs}).


  \subsection*{Computing the credible interval around a probability estimate}

      As well as obtaining posterior means and variances, it is possible to calculate a 95\% credible interval about the posterior mean. This is again straightforward to do in R (see the function "credible interval" in \emph{Appendix S2}). Calculating the 95\% credible intervals for species pairs with 0 to 50 observed co-occurrances without any observed interaction (as in Fig.~\ref{Salix_pdfs}), we see that the interval narrows dramatically as the number of observations increases. In no case, however, does the confidence interval include 0. Even for a pair of species which appeared together in all 374 sites but were never observed interacting, the confidence interval (0.001, 0.018) comes close to, but does not include zero (Table~\ref{interval_table}). 


      \begin{table}[h]
        \caption{95\% credible intervals for the interaction probability of two species that co-occur in $N$ sites but are never observed to interact, obtained using prior information from the \emph{Salix}-galler network in~\citet{Barbour2016,Barbour2016Dryad}.}
        \label{interval_table}
        \begin{tabular}{l | c c}
        N & Lower bound & Upper bound \\
        \hline
        0   & 0.157 & 0.901 \\
        2   & 0.099 & 0.743 \\
        4   & 0.072 & 0.621 \\
        6   & 0.057 & 0.530 \\
        8   & 0.047 & 0.462 \\
        10 & 0.040 & 0.408 \\
        14 & 0.031 & 0.331 \\
        20 & 0.023 & 0.258 \\
        30 & 0.016 & 0.188 \\
        40 & 0.012 & 0.148 \\
        50 & 0.010 & 0.122 \\
        \hline
        374 & 0.001 & 0.018 \\
        \hline
        \end{tabular}
        \end{table}


  \subsection*{How many samples are required to reach a minimal precision}

      Rather than calculating confidence intervals for a posterior distribution after collecting data, we may wish to know how many data points are necessary to obtain a given level of confidence that two co-occurring species do not interact. The number of samples needed will depend on both our desired level of confidence and the threshold below which we assume that two species are unlikely to ever interact. If we want to be 95\% confident that the interaction probability for two species in the \emph{Salix}-galler system is below 0.5, 0.1, or 0.01, we would need six, 54, and 114 observed co-occurrances with no observed interaction (Fig.~\ref{Salix_cdfs}; see function samples\_required in~\emph{Appendix S2}). Given the low levels of replication in most network studies, this implies that we should have fairly low confidence in many "non-interacting" pairs of species. Even in the extensively replicated \emph{Salix}-galler dataset very few species pairs were observed co-occurring frequently enough to reach these thresholds (173/4992 pairs were observed at least six times, two pairs were observed at least 54 times, and no pair was observed more than 114 times). Discounting potential interactions, then, requires either a stronger prior expectation of no interaction (e.g., we can be highly confident that a palm tree will not predate upon a leopard no matter how many times the two species are observed together) or very extensive sampling.


      \begin{figure}[ht]
        \caption{The number of samples required to achieve a given level of confidence that an interaction probability is below a given threshold varies with both parameters. With a low threshold, our confidence that $\omega_{ij}$ is below the threshold increases rapidly with repeated observation of co-occurance without interaction. Here we show the cumulartive density functions for thresholds probabilities of 0.5 (solid line), 0.25 (dashed line), 0.1 (dash-dot line), and 0.05 (dotted line) as well as the points at which the cdf reaches 0.90 (orange square), 0.95 (red circle), and 0.975 (blue diamond) for each threshold value. The large ticks along the x-axis indicate the number of samples associated with each of these points.}
        \label{Salix_cdfs}
        \includegraphics[width=.8\textwidth]{figures/Salix_Galler_samples_and_cdfs.eps}

        \end{figure}


  \subsection*{Scaling up to network metrics}


  % [[What if we have only one site? Can we use the number of observations of a pair of species interacting with any partners as the number of times they co-occur, and the number of interactions within the pair as k? This will be sort-of valid for insects but not for plants when researchers camp out by plant individuals... ]]


\clearpage

    \bibliographystyle{ecollett} 
    \bibliography{MyCollection} % Abbreviate journal titles.


\end{document}


