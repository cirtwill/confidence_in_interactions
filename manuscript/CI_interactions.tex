\documentclass[12pt]{article}
\usepackage{amsmath} 
\usepackage[dvips]{graphicx}
\usepackage{multirow} 
\usepackage{geometry} 
\usepackage{pdflscape}
\usepackage[labelfont=bf]{caption} 
\usepackage{setspace}
\usepackage[running]{lineno} 
% \usepackage[numbers,sort]{natbib}
\usepackage[round]{natbib} 
\usepackage{array}
\usepackage{hyperref}
\usepackage{float}
\makeatletter


% this creates a custom and simpler ruled box style
\newcommand\floatc@simplerule[2]{{\@fs@cfont #1 #2}\par}
\newcommand\fs@simplerule{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@simplerule
  \def\@fs@pre{\hrule height.8pt depth0pt \kern4pt}%
  \def\@fs@post{\kern4pt\hrule height.8pt depth0pt \kern4pt \relax}%
  \def\@fs@mid{\kern8pt}%
  \let\@fs@iftopcapt\iftrue}

% this code block defines the new and custom floatbox float environment
\floatstyle{simplerule}
\newfloat{floatbox}{thp}{lob}
\floatname{floatbox}{Box}

\newcommand{\methods}{\textit{Materials \& Methods}}
\newcommand{\SI}{\textit{Appendix}~}

\topmargin -1.5cm % 0.0cm 
\oddsidemargin 0.0cm % 0.2cm 
\textwidth 6.5in
\textheight 9.0in % 21cm
\footskip 1.0cm % 1.0cm

\usepackage{authblk}

\title{A quantitative framework for investigating the reliability of network construction}

% DG : if ok with all of you, I would appreciate being last author
% AC : Makes sense to me since Dom was the originator of this ms and laid a lot of the groundwork.

% AC : Assuming I'm going to be corresponding author on this but happy to let anyone else step in if you're eager

\author{Alyssa R. Cirtwill$^{1\dagger}$, \&  Anna Ekl\"{o}f$^{1}$, Tomas Roslin$^{2,3}$, Kate Wootton$^{2}$, Dominique Gravel$^{4}$}
\date{\small$^1$Department of Physics, Chemistry\\ 
and Biology (IFM)\\ 
Link\"{o}ping University\\
Link\"{o}ping, Sweden\\
\medskip $^2$ Department of Ecology\\ P.O. Box 7044, Swedish University of Agricultural Sciences \\ SE-750 07 Uppsala, Sweden \\
\medskip $^3$ Spatial Foodweb Ecology Group\\ Department of Agricultural Sciences \\ PO Box 27 (Latokartanonkaari 5)\\ FI-00014 University of Helsinki, Finland \\
\medskip$^4$ D\'{e}partement de biologie\\ 
Universit\'{e} de Sherbrooke\\ 
Sherbrooke, Canada\\ 
\medskip
$^\dagger$ Corresponding author:\\
alyssa.cirtwill@gmail.com\\
+46 723 158464\\
}

\renewcommand\Authands{ and }

\begin{document} 
\maketitle 
\raggedright
\setlength{\parindent}{15pt} 

% Main text can be up to 7500 words, 10 fig., tables, boxes

\section*{Abstract}

  Descriptions of ecological networks typically assume that the same interspecific interactions occur wherever and whenever a community is observed. This contrasts with the known stochasticity of ecological communities: community composition, species abundances, and link structure all vary in space and time. On top of this, finite sampling will generate variation in the set of interactions that are actually observed. Despite recognising these challenges, we lack the quantitative methodology to deal with the uncertainty generated by “true” spatiotemporal variation in ecological interactions or by incomplete sampling. Here we develop analytical tools to capture the uncertainty in the estimation of pairwise interactions. To define the problem, we identify the different contributions to the uncertainty of an interaction and discuss the implications of this uncertainty in the estimation of network properties. We then develop a framework to explicitly quantify the uncertainty around each interaction. We illustrate this framework using the most extensively sampled network to date, demonstrating the universal uncertainty in network studies. Finally, we offer tangible recommendations for improving descriptions of ecological networks and for better sampling of rare interactions. Through these efforts, we demonstrate both the utility of our approach and the importance of acknowledging the uncertainty inherent in network studies.

  % Can be up to 200 words. This is 200 exactly.
  % Word count can be up to 7500, we're at about 5700 without the boxes. Should be grand.

%DG: Eco Lett proposed the new format for methods papers, but I think they are nonetheless looking for conceptual contributions. We might have to tweak just a little bit the abstract to show that our proposition also help formalizing the idea that interactions should be described probabilistically. This is not only technical, it is fundamental as well.

\linenumbers
\begin{spacing}{2.0}
\section*{Introduction}

    Representating an assemblage of species as a network offers a convenient summary of how the community is constructed as it simultaneously accounts for species composition and interactions between species. A tabulation of the nodes (species) and their relative abundances forms the basis for traditional metrics of community composition. To move from these simpler metrics to a network framework, the tabulation of nodes is combined with interactions (links between nodes) so that networks provide additional, higher-order information on community structure. While this additional information is useful (as, for example, interactions can affect changes in species abundances over time), empirical descriptions of ecological networks are still limited because they are usually considered to be static representations of the communities and interactions they describe. That is, whether the network is assembled based on aggregated data, a single intensive ``snapshot" sample, or expert knowledge, interactions are assumed to occur deterministically wherever and whenever the community is observed~\citep{Olesen2011a}. 


    The assumption of static communities contrasts significantly with the widely recognized stochasticity of ecological communities~\citep{Gotelli2000}. Community composition and species abundances vary from site to site~\citep{Baiser2012} and over time within a site~\citep{Olesen2011a}. Likewise, interactions vary over space~\citep{Kitching1987,Baiser2012}, time~\citep{Kitching1987,Olesen2011a}, and between individuals of a given species~\citep{Pires2011a,Fodrie2015,Novak2015}. Moreover, variability in community composition and interactions may or may not be closely related. The removal of a species from a site will obviously also remove its interactions but, conversely, the co-occurrence of potentially interacting species does not in itself guarantee that they will interact at a given place and time. Interactions can be lost if the interaction partners remain present but are separated in time or are too rare to detect each other~\citep{Tylianakis2010}. Interactions can also fail to occur because of environmental contingencies~\citep{Poisot2015}, or through changes to individual preferences~\citep{Fodrie2015}. 


    Beyond ``true" variation in network structure, several researchers have pointed to the importance of sampling intensity for the assessment of network structure (e.g.,~\citealp{Martinez1999,Bluthgen2006,Bluthgen2007}). An assessment of the accumulation of interactions with increasing sampling effort suggests that it is even more challenging to document interactions than species~\citep{Poisot2012}. As a result, it has been proposed that interactions should be described probabilistically and network metrics computed accordingly~\citep{Poisot2016}. Yet, to date, we lack the quantitative methodology to deal with the uncertainty generated by spatiotemporal variation in ecological interactions and by sampling. Even in extremely well-sampled networks, uneven sampling across species (or pairs of species) can lead to the erroneous inference that some species do not interact because they co-occur rarely or have not yet been observed together - even if they do interact when they do co-occur (see Box 1 for an example). Nearly all network studies will thus neglect some interactions, necessitating an approach that acknowledges this uncertainty.


    In this study, we develop analytical tools to capture the uncertainty in the estimation of pairwise interactions. We focus on binary interactions as a first step, but the framework could be expanded to deal with interaction frequencies and strength. To define the problem, we first identify the different contributions to the uncertainty of an interaction and discuss the implications of each source of uncertainty for the properties of ecological networks. Next, we develop an analytical framework to quantify the uncertainty around interactions in an empirical web. We illustrate this framework using the most extensively sampled network to date (Box 1).  Finally, we offer tangible recommendations for improved descriptors of ecological interactions [[double-check that we do this]]. Through these efforts, we demonstrate both the utility of our approach and the importance of acknowledging the uncertainty inherent in network studies.


\section*{Why do some interactions \emph{not} occur?}

  To define the problems associated with quantifying ecological interaction networks, we will start from the perspective of an empirical community ecologist faced with the task of describing a previously unknown interaction network. This ecologist will be interested in generating a description of the species/nodes present, and the links between them~\citep{Roslin2016}.  Importantly, the information sought is conveyed by both the presence and \emph{absence} of links. The two types of information are not, however, equally certain. An observed link will always remain an observed link, but there are multiple reasons why a given link may not be observed. Thus, the detection of any interaction is a stochastic process. We define three nested levels of uncertainty contributing to this stochasticity:

    \subsection*{Interaction uncertainty} 

    First, and most fundamentally, we do not know whether or not a pair of species have the appropriate characteristics (or traits) to interact. We define the probability of an interaction $L$ given those characteristics $\mathbf{T}$ as $P(L | \mathbf{T})=\lambda$. Obviously, if $k$ (the number of observed interactions) is 0, it is possible that the two species could not interact even if there were no external constraints (e.g., temporal or environmental separation) preventing the interaction from occurring. As a simple example, a prey species may be too large to be consumed by a particular predator. In such cases, $\lambda$ would take a value of 0 and there would be no uncertainty. 
    Nevertheless, it is also possible that the interaction is a rare phenomenon with $\lambda>0$ that has not yet been documented. This source of uncertainty is the one documented by trait-matching models~\citep{Bartomeus2016}. It arises because every model is imperfect and lacks information (i.e. about traits) that could be used to define constraints on the interaction. In other words, with sufficient sampling and all information accessible, this interaction probability $\lambda$ should either tend to 0 or to 1 and the uncertainty should vanish. 


    \subsection*{Process uncertainty} 

    Even when an interaction is feasible, i.e. $L=1$, it may not occur at a given location or moment in time because of local constraints such as inclement weather or the lack of suitable habitat. We define the realisation of the interaction process with the variable $X$, given that the interaction is feasible, as a stochastic process with associated probability $P(X|L=1)=\chi$. This phenomenon of interaction contingencies is usually not considered in network studies, but there is a rich literature in community ecology about the contingencies of interactions. Phenological matching~\citep{MillerRushing2010,Gezon2016}, species preferences~\citep{Pires2011,Novak2015,Coux2016}, and fear effects of other species~\citep{Luttbeg2005,Wirsing2008} are just some of the factors contributing to variation in the frequency of interactions between a given pair of species.
    % We imagine for instance that an interaction between a gall and a parasitoid might not be recorded at a location because it was the wrong time of the year and the gall had not yet formed (phenological constraints), a late frost killed the larvae (an abiotic environmental constraint), another parasitoid species competitively excluded the parasitoid species of interest (a biotic environmental constraint) or simply the parasitoid is too rare to interact with all of its viable hosts (an abundance constraint). 

    \subsection*{Detection uncertainty} 

    Lastly, measurement errors are a pervasive source of uncertainty in the observation of ecological processes. Given that an interaction with the variable $D$, given an interaction is feasible and occurs under the local conditions, we may define the detection of an interaction, $D$, as a stochastic process with the associated probability $P(D|X=1,L=1)=\delta$. Detection failure could happen for several reasons, for instance if the rearing of a parasitoid fails with inappropriate lab conditions, because of species mis-identification, or because the interaction is very rare (see~\citet{Wirta2014} for examples of some of these difficulties and partial solutions to them). Some sources of detection error can be minimised with appropriate sampling effort ($\delta$ will converge to one with increasing number of samples), but other sources are often difficult to reduce (e.g. the occurrence of cryptic species might require molecular analysis for appropriate taxonomic identification as in~\citealt{Wirta2014,Frost2016}).


\section*{Estimating detection and process uncertainty}

    Together, the combination of these three sources of uncertainty --interaction uncertainty, process uncertainty, and detection uncertainty-- results in a range of potential explanations for the observation of an absence of interaction ($D$, $X$, and/or $L = 0$). The ecologist wanting to describe the network, however, is specifically interested in the situation where $L = 0$ (i.e., in true absences). Thus, while there is have no difficulty interpreting the observation of an interaction, the observation of an absence of an interaction offers more of a challence since it must be decomposed into different quantities. It is particularly important to rule out the situations where $D=0 \cup X = 1 \cup L=1$, i.e. where the interaction occurred at the location but was not observed, and $D=1 \cup X = 0 \cup L =1$, when the interaction is feasible and would have been detected but did not occur at the local site. The occurrence of a true absence, our quantity of interest, corresponds to the joint event $L=0 \cup X=1 \cup D=1$, but in reality an empirical ecologist will measure the marginal probability $P(L) = k/n$ where $k$ is again the number of observed interactions and $n$ the number of observed co-occurrences.


    The considerations above raise a major challenge: when faced with empirical data, how may we infer whether unobserved interactions went undetected due to sampling or whether they truly do not occur? How then may we refine our sampling approaches to reduce uncertainties, and do we gain insights into the impact of multiple processes on field observations? Importantly, some sources of uncertainty can be minimised with appropriate sampling design and efforts while other sources are difficult or impossible to reduce since they are generated by chance variation created by the very process in which we are interested.

%DG: I do understand Tomas' point about the following, but I really appreciate it ! Keep in mind the suggestion to drop the following paragraph was made when there was much more material above. Perhaps we should revisit this suggestion, given the actual material that will follow. To me this is fairly important for the non-technical people. There are some important things, such as the "the more sample the more zeros will appear in the interaction matrix"

%AE: I agree with Dom here, as I think the paragraphs below are good for getting a bit deeper into the width of the problem we are addressing. Could possibly be shortened if needed?

  [[Tomas suggests removing the following because it slows down procedings, Anna and Dom want it back. Shortening sounds like a good middle ground:]]
  The basic information that we are collecting consists of matrices of interaction partners. Our count of interactions between two species reflects uncertainty with respect to whether two species are capable of interacting when co-occurring at a given site ($\lambda$), chance variation in whether the interaction is realised ($\chi$),  and uncertainty with respect to whether it is detected when realised ($\delta$). In this case, what can we do to pin down any of these different types of variation?


  The obvious rule of thumb is to ``sample more" (see Fig.~\ref{upper_limits} for a demonstration of the power of increasing sample size), but we note that there are limits to the utility of this motto. Sampling more will clearly reduce uncertainty regarding the upper bound of the probability of interaction, and it will also increase the probability of detecting unlikely interactions (i.e. interactions occurring with a low probability). Yet, since the probability of observing the co-occurrence of two species will always be higher than the probability of observing their interaction (since the probability of interaction is conditional on both interaction partners being present; see Fig.~\ref{histograms}E-F), we will accumulate observations of co-occurrences faster than we will accumulate observations of interactions. Thus, the more we sample, the more zeros will appear in our interaction matrix, which may seem like a counter-intuitive outcome. 


  As a solution towards deciding whether unobserved interactions were undetected due to sampling, or whether they truly do not occur,~\citet{Weinstein2017} used repeated sampling rounds to estimate the daily probability of detecting a hummingbird interaction, and to thereby model the observation and process mechanisms. While conceptually attractive, this approach is unsuitable for interactions occurring over longer time scales (e.g., associations between hosts and parasitoids with a single generation per year), or very rare interactions which might not occur on any of the sampling days or might involve individuals of a species that are not under observation. What is worse, the problem persists that if a given interaction is not observed on a given day, this could be either because it was impossible that day despite being otherwise feasible [$P(X|D=1,L=1)=0$], because interaction between the two did occur but could not be observed [$P(D|X=1,L=1)=0$], or from any combination of the two. From a conceptual perspective, this approach will thus fail to satisfactorily distinguish between sources of uncertainty. Most importantly, if two species are never observed co-occurring during several days of sampling then we have learned nothing about their probability of interacting if they should ever co-occur. In other words, there is no information about interactions without co-occurrence.


  An added complication is that not all sources of uncertainty are proportional to sample size. To record an interaction between A and B, we need to identify both partners correctly (a non-trivial problem in many food webs; e.g.~\citealp{Kaartinen2011,Roslin2016}) and be able to resolve all interactions with a similar likelihood. For both molecular and rearing techniques, certain types of interactions may go unnoticed due to technical challenges~\citep{Wirta2014}. This can bias the set of recorded interactions. The bottom line is that separating different sources of uncertainty is difficult indeed. As an alternative to abandoning empirical networks or continuing to ignore the uncertainty inherent in undetected observations, we propose that some insight regarding the detectability of interactions between species not found co-occurring may be gained from data on other species between which interactions are known to be feasible. 


\section*{A naive quantification of interaction probability and uncertainty}

%%AE: I think the section that is commented  below not should be placed here, but when reading the pdf without this part in it I really thoght that this was missing. One option is to move this part to the Introduction, where it would fit better.


   [[Move this paragraph to intro?]] It is getting more and more common to represent interactions as probabilities in theoretical models of network structure. For example, the minimum potential model introduces gaps in the feeding niche of predators by sampling based on the likelihood of each interaction~\citep{Allesina2008}, while a gaussian probability function is used to represent the niche by~\citet{Williams2010}. \citet{Eklof2013} also introduced variability  in the computation of network dimensions, allowing the absence of interactions within the n-dimension niche of every species. Empirical investigation of trait-matching constraints often consider the occurrence of interactions as binomial process (e.g.,~\citealp{Rohr2016}). There are also ways to perform analysis of probabilistic networks, with almost all metrics having a probabilistic version~\citep{Poisot2016}. But there is not yet consensus on what an interaction probability between a pair of species means, and this is definitely a problem when comes time to estimate the uncertainty of both pairwise interactions and entire networks. 


  To progressively dissect the different contributions to uncertainty, we will start by considering how we could naively quantify interaction probability and its associated uncertainty \emph{for an interaction that has not yet been observed}. We consider the case where a pair of species have been observed co-occurring $n$ times, of which they have been observed to interact in $k = 0$ cases. We now aim to evaluate the uncertainty of this interaction. We consider the occurrence of an interaction as a Bernoulli trial. Consequently, the number of successes $k$ over $n$ trials will follow a binomial distribution: 
      
      \begin{equation}
        X \sim Bin(n,\lambda) ,
      \end{equation}


      \begin{equation}
         P(X = k|\lambda,n) = {n \choose k}\lambda^k(1-\lambda)^{n-k} . 
         \label{likelihood}
      \end{equation}

  \noindent The parameter $\lambda$, the probability of observing an interaction over an infinite time interval and area, is the quantity we want to estimate from empirical data. 
  The maximal likelihood estimate (MLE) of $\lambda$ is straightforward to find given $k$ and $n$:

      \begin{equation}
        \lambda_{MLE} = \frac{k}{n}  .
        \label{theta_MLE}
      \end{equation}

  The variance of a Bernoulli experiment is $n\lambda$(1-$\lambda$). It is important to remember that this variance describes the variability of the number of successes $k$ for $n$ trials and is not the variance associated with the estimation of $\lambda$. Given this variance, it is possible to compute the confidence interval for the MLE of $\lambda$ using any of several methods, including the \emph{Wilson score interval}, the \emph{Clopper-Pearson interval}, and the \emph{Agresti-Coull interval} (for details, see [\citealp{Brown2001}]). Finding this estimate is therefore quite straightforward, but it nonetheless has two drawbacks. First, $\lambda$ is not a single point estimate but rather a random variable with a given uncertainty, the distribution of which is unknown. This means that even if $k = 0$ in a given sample, this does not necessarily imply that the two species will never interact. Rather, $k = 0$ implies that `no interaction' is the most likely outcome when the species do co-occur but there is nonetheless a substantial chance that the two species \emph{could} interact. In the situation where $k>0$, in contrast, we are sure that the interaction is feasible ($L = 1$) but still cannot be sure of the cause if the interaction is not observed at some sites/times (i.e., we cannot say why $k<n$). There may be local constraints ($X=0$) or we might simply not observe the interaction in every sample ($D<1$). 


  Second, where the number of samples $n$ is very low (some pairs of species may never have been documented as co-occurring), there will be considerable uncertainty around our estimate of $\lambda$. In Fig.~\ref{upper_limits} and Box~\ref{box2}, we derive the Clopper-Pearson interval to explore how the estimate of $\lambda$ varies with sample size. At a small sample size, the 95\% confidence interval spans all values of $\lambda$. To establish that species are not interacting with any acceptable certainty requires tens of observations of the two species co-occurring but not interacting. As most data sets will lack such extensive sampling across all species pairs, we can use a Bayesian approach to supplement what data we do have with other sources of information.


\section*{Bayesian approach to infer interaction probabilities}

    \subsection*{Posterior distribution of the interaction probability}

      Here we adopt a Bayesian approach to estimate the posterior distribution of the parameter $\lambda$ :

      \begin{equation}
        \underbrace{P(\lambda|k,n)}_{Posterior} = \frac{\overbrace{P(k|\lambda,n)}^{Likelihood}\overbrace{P(\lambda)}^{Prior}}{\underbrace{P(k|N)}_{Normaliser}} .
        \label{posterior}
      \end{equation}

      According to the above description, the likelihood is simply the binomial distribution (Eq.~\ref{likelihood}). Since $\lambda$ is a probability, it is bounded between 0 and 1 and the most appropriate prior distribution is the beta:

      \begin{equation}
        \lambda \sim Beta(\alpha,\beta) , \label{prior}
      \end{equation}

      \noindent which has two shape parameters, $\alpha$ and $\beta$. 

     The beta-binomial distribution is a conjugate distribution of the binomial distribution. This allows us to analytically compute the posterior distribution of a binomial model with a beta prior distribution. We can re-write the posterior distribution of $\lambda$ as:

      \begin{equation}
        P(\lambda|k,n) = \frac{\lambda^{\alpha+k-1}(1-\lambda)^{\beta+n-k-1}}{B(\alpha+k,\beta+n-k)} , \label{posterior}
      \end{equation}

      
      \noindent where the function $B$ is the beta function. The posterior distribution of $\lambda$ therefore follows the beta distribution with new parameters $\alpha'= \alpha+k$ and $\beta'=\beta+n-k$. The weight of the prior on the posterior distribution can be understood from these parameter definitions: the difference between the posterior and the prior will increase with $k$ and $n-k$. In other words, the distribution of $\lambda$ for better-sampled pairs of species will rely less on the information used to build the prior distribution and depend more on the observed data.
      When plotted, we find the shape of the distribution gets narrower with $k$ and $n$ (Fig.~\ref{Salix_pdfs}). 

      %  The posterior distribution of $\theta$ could be computed with R with the following command:
      %
      %
      %  \vspace{12pt}
      %  \noindent\emph{dbeta(x = theta, shape1 = alpha+k, shape1 = beta+n-k)}
      %  \vspace{12pt}


    \subsection*{Moments and other properties}

      It is common to preform analyses that require calculating higher-order network properties in interaction networks. The fact that the posterior distribution of $\lambda$ follows a beta distribution makes it straightforward to compute moments and other properties needed for this. 
%%AE: Should we give examples of these higher-order properties?    
% AC: How do you mean? Examples of averages/variances/modes or of "other properties" ?

      The \textbf{average} of $\lambda$ is: 
          \begin{equation}
            \bar{\lambda} = \frac{\alpha+k}{\alpha+\beta+n} ,
            \label{mean}
          \end{equation}

        and its \textbf{variance} is:  
          \begin{equation}
            Var(\lambda|k) = \frac{(\alpha + k)(\beta + n - k)}{(\alpha + \beta + n)^{2}(\alpha + \beta + n +1)}
            \label{variance}
          \end{equation}

        The \textbf{mode} of the distribution is:
          \begin{equation}
            \hat{\lambda} = \frac{\alpha + k - 1}{\alpha + \beta + n - 2} .
            \label{mode}
          \end{equation}

    \subsection*{The prior distribution}    

      Parameters $\alpha$ and $\beta$ determine the shape of the prior distribution, which follows a beta distribution. These are called hyper parameters. Below we identify four ways to formulate the prior distribution of $\lambda$. 

      \subsubsection*{Uninformative prior}
        
          In the absence of any external information, an uninformative prior is the most conservative hypothesis for the distribution of $\lambda$. The beta distribution is in this case a uniform distribution, specified with hyper parameters $\alpha=1$ and $\beta=1$. 

      \subsubsection*{Distribution of connectance}
        
          The ecological network literature boasts a solid collection of networks for which connectance has been calculated and for which we can thus define the connectance distribution. Connectance is measured as $C = L/S^2$, where $L$ is the number of interactions and $S$ is the number of species. It measures the filling of an interaction matrix and thereby expresses the average probability that any two species interact with each other. If we know only the mean $\overline{C}$ and the variance $\sigma_C^2$ of the distribution of $C$,
          % [[from the literature or from our network? Has to be from the literature - if it was our network we'd know way more than just C]] 
          then the beta parameters could be computed as follows using the method of moments:

          \begin{equation}
          \alpha = \overline{C}(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) ,
          \end{equation}

          \begin{equation}
          \beta = (1-\overline{C})(\frac{\overline{C}(1-\overline{C})}{\sigma_C^2}-1) .
          \end{equation}
    
          %  It is also possible to compute maximum likelihood estimates for a sample of the distribution of $C$.
          %  
          %   The following piece of R code provides an example: 
          %
          %  \vspace{12pt}
          %  \noindent\emph{
          %    library(MASS)\\
          %    pars = fitdistr(x = vecC, "beta", start = list(shape1 = 1, shape2 = 1))\$estimate
          %  }
          %  \vspace{12pt}
          %
          %
          %  Where $vecC$ is a vector of known connectances for a set of networks. 


      \subsubsection*{Degree distribution or interaction probabilities}

          The degree of a node in a network is defined as its number of connections to other nodes. The degree distribution of a network is then the probability distribution of these degrees over the whole network and the standardised degree could therefore be interpreted as an interaction probability. It is consequently possible to use the degree distribution to inform the prior distribution. The degree distribution could come from several networks, from a similar network (e.g. a known network at slightly different location) or from the network of interest if interaction probabilities for some species are already documented. The latter approach allows to apply information from known, abundant species to the rarest species for which interactions are less frequently documented. 


          If our focal network describes a system similar to that in a known network, we can use the distribution of interaction probabilities in that network to inform our prior. The probability of any interaction $L_{ij}$ depends on the degrees of species $i$ and $j$. Using normalised degrees $\Delta_i$ and $\Delta_j$ (i.e., degrees divided by the number of species in the network), we can obtain the probability of interaction $L_{ij}$=$\Delta_i\times\Delta_j$. Similar to the procedure for degree distribution, the distribution of these interaction probabilities derived from a similar network or a suite of networks can be used to establish a prior distribution before any data from the focal network are collected. For distributions of either degrees or interaction probabilities, the procedure for the estimation of the hyper parameters follows the same approach as described above for connectance except that each measurement is at the individual interaction level instead of the network level.


      \subsubsection*{Trait-matching function} 

          As a fourth and final approach to obtain the prior distribution of $\lambda$, we envisage using the outcome of a trait-matching model, provided such a model has been documented using external data and relevant traits are available. In such as case, the prior distribution would follow the function $P(\lambda|\mathbf{T})=f(\mathbf{T})$ based on a set of traits for both species $\mathbf{T}$. There are several techniques available to perform this inference of interaction probability, some of which are Bayesian, and we refer to~\citet{Bartomeus2016} and~\citet{Weinstein2017} for recent reviews about this topic. Note that in this case the prior might not be beta-distributed and numerical methods might be required to compute the posterior distribution.  


\section*{A quantitative example}

  The Bayesian framework can be illustrated with a simple quantitative example. Suppose we have $n = 10$ observations of co-occurrence between species $i$ and species $j$ in a given time interval and area, and $k = 3$ observations of interactions. The maximum likelihood estimate of the interaction probability (Box~\ref{Box2}) is simply $\lambda_{MLE} = 3/10 = 0.3$. 
  

  Now consider we know that species $i$ is known to interact with 10 species (other than species $j$), which have the following degrees:

    \vspace{12pt}
    \noindent\emph{
      degree=c(14, 4, 2, 3, 17, 6, 2, 15, 1, 1)
        }.
      \vspace{12pt}

    If the network has 20 species total, this gives the normalised degrees:

    \vspace{12pt}
    \noindent\emph{
      norm\_degree=c(0.65, 0.20, 0.10, 0.15, 0.85, 0.30, 0.10, 0.75, 0.05, 0.05)}.
      \vspace{12pt}

    Species $i$ has a normalised degree of 0.55 (it interacts with species $j$ and 10 other species). We can combine the normalised degree of $i$ with the normalised degrees of its interaction partners to obtain the following set of interaction probabilities for species $i$ and each of its interaction partners:

    \vspace{12pt}
    \noindent\emph{
       int\_probs = c(0.358, 0.110, 0.055, 0.082, 0.468, 0.165, 0.055, 0.412, 0.028, 0.028) }.
      \vspace{12pt}

    The mean of these interaction probabilities is 0.176, approximately two-thirds the $\lambda_{MLE}$ obtained from the observed data. We can use the distribution of these interaction probabilities as our prior distribution and estimate the uncertainty surrounding our $\lambda_{MLE}$. With some simple R code (function ``calculate\_parameters", \emph{Appendix S1}), we obtain prior parameters $\alpha$=0.998 and $\beta$=4.63. Using these priors in equations~\ref{mean} and~\ref{variance} above (or in the R function ``calculate\_distribution" in \emph{Appendix S1}), we find a prior $\bar\lambda$=0.177 and var($\lambda$)=0.026. Adding the observed data ($n=10$, $k=3$) and using the same code, we obtain posterior parameters $\alpha'$=4.00 and $\beta'$=11.6 and a posterior $\bar\lambda$=0.256 and var($\lambda$)=0.012. Comparing the posterior distribution to the prior, we see that the posterior is closer to the observed data and that the additional data about interactions between species $i$ and $j$ has reduced the variance. We may also wish to calculate a credible interval (analogous to the frequentist confidence interval). This is also quite straightforward in R (see function ``credible\_interval" in \emph{Appendix S1}). In this case, a 95\% credible interval for $\bar\lambda$ is (0.080, 0.491).


    Now, consider the case where the two species have never been observed interacting across $n$ trials, i-e. $k=0$. The question is then ``what is the probability that these two species do not interact''? Since it is not possible to prove that the two species could never interact (strictly speaking, in a Bayesian approach $\lambda=0$ is impossible), we must fix a threshold below which we consider that there is no interaction ($\lambda \sim 0$). We call this threshold probability $\lambda*$. We then use the cumulative distribution function to estimate $P(\lambda<\lambda*|L=0,n)$ for different $n$. The function ``samples\_for\_threshold" in \emph{Appendix S1} calculates distribution function for $\lambda*$ with an increasing number of trials. This yields a surprising result: it requires \textgreater24 observations of no interactions to be 95\% sure that the interaction probability is smaller than $\lambda*$=0.1 (recall Fig.~\ref{upper_limits}, Box~\ref{box2}). Note the special case where there is no observation of the two species co-occurring, $n = 0$.  In this situation, the posterior distribution converges to the prior distribution since the data include no information on the probability with which species might interact should they co-occur.


\section*{Scaling up uncertainty from pairwise interactions to networks}

    [[check that all the figs are with Zillis]]

    %It is fairly straightforward to compute most of network metrics when the different $\lambda$ of the adjacency matrix are known, without variance~\citep{Poisot2016}. Several of these metrics derive directly from quantitative indices of network structure which are equivalent to $\lambda$. The remainder, originally defined for binary networks, can be adjusted to account for interaction probabilities between zero and one. It is not as easy, however, to understand how the uncertainty in these estimated interaction probabilities influences network metrics. Computation of these metrics involves non-linear functions. Since Jensen's inequality states that the average of a non-linear function of a stochastic variable differs from the function of the average of that variable, any uncertainty in the values of $\lambda$ could bias both the mean and variance of a network metric. For instance, assume that among the pairs of species with few observed co-occurrences there are many pairs which truly interact. If we %begin with no observed links for these pairs, then correcting for these false absences will inflate the number of links and consequently influence metrics such as connectance, nestedness, and degree distribution. While we can, as described above, calculate these network metrics using fixed estimates for $\lambda$, no analytical solution currently exists for uncertain $\lambda$. Instead we must rely on computer simulations. 
    In the following section, we will provide an empirical example based on the well-sampled system of \emph{Salix}  plants, herbivorous gallers, and their natural enemies described by~\citet{Kopelke2017}; see Box~\ref{box1} or \emph{Appendix S2} for a description). 
    %This tripartite network can be examined as two bipartite networks, namely \emph{Salix}-galler and galler-natural enemy networks. 
    We will show how the uncertainty arising from both absences of co-occurrences and false absences of interactions impact these metrics. %We find uncertainty influences both the average and the variance of network metrics, putting in perspective traditional network comparison studies where these metrics are assumed to be fixed entities. 

%DG: I dropped pieces of the above paragraph because it was bizarre to get back at the posterior distribution, and then to the computer simulations. This section is first and foremost an empirical example. But then, an introduction about the scaling up was missing, so I moved part of the paragraph below

% AC : Maybe we should change the section title to highlight that this is an empirical example and covers the effect of uncertainty on network-level properties

  \subsection*{Computing the posterior distribution}

      In a strict Bayesian framework, we wish to use a prior distribution that does not rely on any information from the study at hand. Network data for a similar study system may, however, not be available. In that case, one might use the first subnetwork collected as ``training data" to guide future sampling. To simulate this situation, we created priors using a single subnetwork from the middle of the geographical distribution of the~\citep{Kopelke2017} dataset (Zillis subweb). To demonstrate how the use of a data from a different system can affect the prior distribution and conclusions based on it, we repeated our analyses using priors derived from a much smaller \emph{Salix}-galler-natural enemy system~\citep{Barbour2016,Barbour2016Dryad}. This smaller system was much more densely-connected than that described in~\citet{Kopelke2017} and provided unreasonable distributions for interaction probabilities (\emph{Appendix SX}). 


      To obtain the priors based on the Zillis subweb, we estimated frequencies of \emph{Salix}-galler interactions based on the normalised degree of each species in each network component (see \emph{Appendix S3} for details and code). Specifically, we obtained prior parameters of $\alpha$=8.72, $\beta$=305 for the \emph{Salix}-galler component and $\alpha$=0.700, $\beta$=8.49 for the galler-natural enemy components of the network. After calculating these prior parameters, we were then able to estimate the posterior distribution of interaction probabilities given the additional information in our dataset.
  

      For species where no co-occurrences were observed ($n=0$), we can calculate the estimates for the mean and variance of $\lambda_{ij}$ directly from the prior parameters following equations~\ref{mean} and~\ref{variance} (see \emph{Appendix S1} for R implementation). For the \emph{Salix}-galler network, the prior distribution  was: $\bar\lambda$=0.028, var($\lambda$)=8.60$\times$10$^{-5}$. The prior distribution for the galler-natural enemy network was: $\bar\lambda$=0.076, var($\lambda$)=0.008. The posterior interaction probabilities obtained based on the Zillis subweb were much lower than those obtained based on~\citet{Barbour2016}; this emphasises the importance of using an appropriate study system when constructing a prior (\emph{Appendix SX}).


      For a pair of species with some observed co-occurrences ($n>0$), we can update the prior distribution with these data. If we consider only pairs of species which were observed to co-occur but not to interact, $k_{ij}$ is always 0 and only $n_{ij}$ will vary between species pairs, giving $\alpha'$=$\alpha$ and $\beta'$=$\beta + n_{ij}$. As the most extreme case, consider a pair of species which co-occurred at all 374 sites and was never observed to interact. Using the priors described above, our distribution for the \emph{Salix}-galler network would become $\bar\lambda_{ij}$=1.27 $\times$ 10$^{-2}$, var($\lambda_{ij}$)=1.82 $\times$ 10$^{-5}$ while our distribution for the galler-natural enemy network would become $\bar\lambda_{ij}$=1.83 $\times$ 10$^{-3}$, var($\lambda_{ij}$)=4.76. Distributions for both network components were very close to 0 with small variance about our estimate of $\lambda$; species $i$ and $j$ are extremely unlikely to interact at sites or times not included in our sample.


      For most pairs of species $i$ and $j$, however, $n_{ij}$ was much less than 374 and our posterior mean and variance therefore retain more of the influence of the prior. We can see this in the increasing means and variances as we decrease $n_{ij}$ (Fig.~\ref{Salix_pdfs}). The change in distribution as $n_{ij}$ decreases can also be shown  by calculating 95\% credible intervals for $\lambda$ (see the function ``credible\_interval" in \emph{Appendix S2}). The 95\% credible interval around the estimate of $\lambda$ also widens as $n_{ij}$ decreases from (0.001, 0.017) and (\textless0.001, 0.11) for hypothetical \emph{Salix}-galler and galler-natural enemy pairs that might be observed co-occurring at all 374 sites without any observed interaction to (0.152,0.931) and (0.008, 0.364) for \emph{Salix}-galler and galler-natural enemy pairs that were never observed co-occurring. The 95\% credible interval for hypothetical \emph{Salix}-galler pairs widened from (0.006, 0.022) if the pair co-occurred at all sites to (0.013, 0.049) if they co-occurred at none. The 95\% credible interval for hypothetical galler-natural enemy pairs, meanwhile, widened from (0.00001, 0.008) to (0.0005, 0.304).


  \subsection*{How many samples are required to reach a minimal precision}


      Rather than calculating credible intervals for a posterior distribution after collecting data, we may wish to know how many data points are necessary to obtain a given level of confidence that two co-occurring species do not interact. The number of samples needed will depend on both our desired level of confidence and the threshold below which we assume that two species are unlikely to ever interact (Fig.~\ref{Salix_cdfs}; see function samples\_for\_threshold in~\emph{Appendix S1}). In our dataset, the entire 95\% credible interval was (0.013, 0.049). We may therefore be 95\% confident that the interaction probability for \emph{Salix} and galler species that have not been observed cooccurring is below 0.05. To be 95\% confident that the interaction probability for these species is below 0.01 would require 139 observed co-occurrences with no interaction.


      The number of samples required to be 95\% confident that the interaction probability between galler and natural enemy species is below a threshold also increases quickly as the threshold decreasesy. The 95\% credible interval is (0.0005, 0.303) for the probability of interaction between two species observed to co-occur but never interact. To be 95\% confident that the probability of interaction is below 0.1, 0.05, or 0.001 would require 15, 39, and 229 observed co-occurrances, respectively.


      Given the low levels of replication in most network studies, this implies that we should have fairly low confidence in many ``non-interacting" pairs of species. Even in the extensively replicated \emph{Salix}-galler-natural enemy dataset very few species pairs were observed co-occurring frequently enough to reach these thresholds.  Regardless of our choice of prior, no species pairs were observed to co-occur frequently enough to reach the threshold for an interaction probability of 0.01. Discounting potential interactions, then, requires either a stronger prior expectation of no interaction (e.g. for forbidden interactions) or very extensive sampling. For all we know, most links absent from current descriptions of network structure may be so not because the species do not interact, but because we have not sampled deeply enough to detect them.


  \subsection*{Scaling up to network metrics}
  [[Haven't added NODF or checked this yet.]]

  %DG: here is where I moved material from aboce 

    It is fairly straightforward to compute most of network metrics when the different $\lambda$ of the adjacency matrix are known, without variance~\citep{Poisot2016}. Several of these metrics derive directly from quantitative indices of network structure which are equivalent to $\lambda$. The remainder, originally defined for binary networks, can be adjusted to account for interaction probabilities between zero and one. It is not as easy, however, to understand how the uncertainty in these estimated interaction probabilities influences network metrics. Computation of these metrics involves non-linear functions. Since Jensen's inequality states that the average of a non-linear function of a stochastic variable differs from the function of the average of that variable, any uncertainty in the values of $\lambda$ could bias both the mean and variance of a network metric.

    Using the prior distributions and procedures described above, we calculated posterior probability distributions for \emph{Salix}-galler or galler-natural enemy pairs that were not observed interacting. Using these posterior distributions and assuming probabilities of 1 for pairs of species that were observed interacting, we created a suite of 100 webs of each network type by randomly sampling from each posterior distribution. After obtaining these posterior networks, we calculated the connectance of each web, as well as the number of links per resource (\emph{Salix} in the \emph{Salix}-galler networks or galler in the galler-natural enemy networks) and links per consumer. To demonstrate how these network metrics will be affected by detection uncertainty, we then created a suite of filtered networks for each posterior network. Networks were filtered by randomly sampling 99\%, 95\%, 90\%, 80\%, 70\%, 60\%, and 50\% of the interactions included in each posterior network. This gradient is akin to a gradient of sampling effort. For each level of detection accuracy, we created 100 randomly-sampled networks per posterior-probability network (giving 100 posterior networks and 1000 detection-filtered networks each for the \emph{Salix}-galler and galler-natural enemy networks). We then calculated the same network properties as described above.

%DG: the different posterior connectance are the results of different samples of the posterior distribution, righ ? 
%Yes

    We find, perhaps not surprisingly, that the posterior webs for the Salix-galler network all had much higher connectance than the original, observed web (C=0.028 for the observed web and 0.528$\leq$C$\leq$0.568 for the posterior webs; Fig.~\ref{posterior_webs}A). Likewise, the number of links per \emph{Salix} and galler species in the observed web ($L_{\emph{Salix}}$=2.71 and $L_{galler}$=1.47, respectively) were much lower than those predicted in the posterior webs (27.4$\leq L_{\emph{Salix}} \leq$29.5 and 50.6$\leq L_{galler} \leq $54.5, respectively; Fig.~\ref{posterior_webs}C,E), even when filtering with a detection probability of only 50\%. There are two possible explanations for this discrepancy: either the data of~\citet{Barbour2016} is simply too different from that of~\citet{Kopelke2017} to offer an appropriate prior for our dataset, or the true detection probability for links between \emph{Salix} and galler species is much less than 50\%. As the scale of the two datasets is quite different (genotypes of a single \emph{Salix} species in~\citet{Barbour2016}, various \emph{Salix} species in our dataset), we suspect the former is more likely.
%    [[This is a little boring. Tomas has ideas for people with potentially better priors - may require another co-author. Also maybe could use one site as a prior like ``training data"?]]
% DG: not so sure, I find it very useful because it simply illustrates the point. Nestedness will be a nice complement with lest trivial results
%%AE: If we are doing a complement here (I agree it is a bit boring) I think option c) from Alyssas mail is the most straight forward option. 

    Considering the galler-natural enemy networks, the connectance, mean links per galler, and mean links per natural enemy were also much lower in the observed web (C=0.078, $L_{galler}$=9.99, and $L_{natural enemy}$=7.45, respectively) than in the posterior webs (0.183$\leq$ C $\leq$ 0.196, 17.5 $\leq L_{galler} \leq$ 18.9, and 23.0 $\leq L_{natural enemy} \leq$ 24.8). When the detection probability was relatively low (i.e., 50\%), however, the properties of randomised networks became similar to those in the observed webs (Fig.~\ref{posterior_webs}B,D,F). The~\citet{Barbour2016} network likely provides a better prior here than for the \emph{Salix}-galler networks, as both networks included different galler and natural enemy species. Although the two networks differ vastly in scale, and the inclusion of multiple \emph{Salix} species likely causes structural differences from~\citet{Barbour2016} despite the similar resolution of gallers and natural enemies, this result nevertheless suggests that even such a large and well-replicated network as that in~\citet{Kopelke2017} is missing many interactions. This should be a strong warning to researchers comparing structural characteristics between networks - small structural differences are likely to be masked by substantial noise resulting from sampling uncertainty.


\section*{Conclusions/recommendations}

  Real interaction networks vary over several dimensions~\citep{Kitching1987,Olesen2011a,Pires2011a,Baiser2012,Fodrie2015,Novak2015}, and to capture this variation we must turn from static descriptions of network structure to probabilistic descriptions. In this study, we have developed the analytical tools to capture the uncertainty in the estimation of pairwise interactions, and to partition it into its individual components: interaction uncertainty, process uncertainty and detection uncertainty. The patters unveiled offer tangible recommendations for improved descriptors of ecological interactions. First, our analyses point to detection uncertainty as a major contributor to overall uncertainty of is establishing the absence of interaction. To counter these establish the true absence of interactions will then require comparatively large sample size – on the order of 30-50 observations per species pair. Second, where such extensive sampling is not feasible, researchers should still acknowledge the varying levels of confidence surrounding the presence or absence of interactions between different pairs of species. Including the $n$ and $k$ values for each interaction will clearly indicate which unobserved interactions are most likely to be observed with further sampling and which estimates are more reliable. Third, the uncertainty around interactions (especially interactions that were not observed) should be incorporated in calculations of network properties like connectance or nestedness. Re-sampling networks based on a probabilistic understanding of networks is straightforward and gives distributions for network properties rather than point estimates. This not only acknowledges the fact that interactions vary over time and space but will also facilitate comparisons between networks. With confidence intervals around network metrics, we can not only say that one network is more connected than another but also whether the networks are more different than we would expect based on imperfect sampling of interactions. To facilitate these recommendations, we provide all code used in this paper in the supplementary material. 



  % [Here we need to be very hands-on and remember the invitation letter form Ecol Letters:
  % As a contribution primarily to methodology, the manuscript will not be considered for ``Ideas \& Perspectives". (Please recall my message concerning your past presubmission inquiry.) However, Ecology Letters is entertaining the idea of a new section for ``Novel Methods". As we have not advertised this, I would ask you to keep that information in confidence. If acceptable to an Associate Editor and reviewers, your paper could be the first, or one of the first, contributions to this new section. Accordingly, the work would be subject to considerable scrutiny and I would urge you to make the paper as strong as you can. This would include demonstrating the need for this new method (i.e. outlining how this is different than other approaches currently in use and how they fail at some important task), documenting the robustness and accuracy of the approach, performing case study, and making robust high-quality code freely available.]
\end{spacing}

\section*{Boxes and figures}


\begin{floatbox}{}

    \indent As a case study, we use an extensively sampled \emph{Salix}-galler-natural enemy meta-network. This dataset consists of a single community type sampled across Europe: willow (\emph{Salix}) species, willow-galling sawflies, and their natural enemies. The data were collected over 29 years at 374 unique locations across Europe, with a total of 641 site visits. Each site visit can be considered as a network in its own right or as an independent sample from which to build the meta-network. The meta-network consists of 1,173 different interactions between 52 \emph{Salix} nodes, 92 herbivore nodes, and 126 natural enemy nodes. The high spatiotemporal resolution of this network and the unusually high sampling effort implemented at the site level makes this dataset particularly well suited for illustrating the difficulties in completely sampling a network and testing Bayesian approaches to overcome these difficulties.\\
    \indent We may begin by comparing the frequency of co-occurences for pairs of species in each part of the network to reveal the challenge of having sufficient sampling to be confident that an interaction does not occur. Most pairs of species (3986/4992 \emph{Salix}-galler pairs and  9794/12096 galler-natural enemy pairs) are never found co-occurring and, even for species that did occur, the total number of co-occurrences was generally low (mean=4.24, variance=36.3 for \emph{Salix}-galler pairs; mean=3.87, variance=28.8 for galler-natural enemy pairs; Fig.~\ref{histograms}A-B). The bulk of these co-occurring species pairs were never observed to interact: only 2.82\% of \emph{Salix}-galler pairs and 7.76\% of galler-natural enemy pairs were observed interacting at one or more sites. Of those pairs that did interact, the incidence of interaction was also low (mean=12.0, variance=155 for \emph{Salix}-galler pairs; mean=4.04, variance=29.3 for galler-natural enemy pairs; Fig.~\ref{histograms}C-D). Thus, even in the most extensive data set that we could find, there was very little empirical data for each species pair. This suggests that limited sampling is a major source of uncertainty. This dataset also illustrates the potential for increased sampling to not necessarily reveal more interactions as a pair of species that interacts in some cases may not be observed interacting in all cases (Fig.~\ref{histograms}E-F).
  \caption{\emph{Salix} dataset}
  \label{box1}
\end{floatbox}

%%AE: I think Box 2 is nice to have in as a hands-on example.
\begin{floatbox}{}
  
  Here we describe the derivation of the Clopper-Pearson credible interval for the estimated probability of interaction $\lambda$ of a pair of species observed co-occurring $n$ times and interacting $k$ times. As we are most interested in the probability of interaction between species pairs that have never been observed co-occurring, we consider only the case where $k=0$ over a variety of $n$. This is straightforward to do in R (see the function ``credible\_interval" in \emph{Appendix S1}). 


  First, we must obtain the $\alpha$ and $\beta$ parameters for the prior distribution. In this study we obtained these parameters using the R~\citep{R} function fitdist from the package fitdistrplus~\citep{fitdistrplus}. Once $\alpha$ and $\beta$ are known, we can update them using our observed data. Specifically, we are interested in $\alpha'=\alpha+k$ and $\beta'=\beta+n-k$. These parameters can then be used to calculate a credible interval using the R~\citep{R} function qbeta. In the table below, we present the 95\% credible intervals for \emph{Salix}-galler and galler-natural enemy paris with different numbers of observed co-occurrences ($n$) and no observed interactions ($k=0$). Both sets of intervals rely on prior information from the network in~\citet{Barbour2016,Barbour2016Dryad}.

      % # R code to make the table:
      % output=matrix(nrow=length(ns),ncol=5)
      % ns=c(0,1,2,5,10,15,20,25,50,100,150,200,374)
      % output[,1]=ns
      % for(r in 1:nrow(output)){
      %   interval1=credible_interval(calculate_parameters(sg_int_probs,ns[r],0),0.025,0.975)    
      %   interval2=credible_interval(calculate_parameters(gp_int_probs,ns[r],0),0.025,0.975)    
      %   output[r,2:3]=interval1
      %   output[r,4:5]=interval2
      % }

        \begin{tabular}{l  c c  c c }
        \multirow{2}{*}{$n$} & \multicolumn{2}{c}{\emph{Salix}-galler} & \multicolumn{2}{c}{galler-natural enemy}\\
         & Lower bound & Upper bound \\
        \hline
        0   & 0.152 & 0.931 & 0.008 & 0.364 \\
        1   & 0.110 & 0.843 & 0.007 & 0.337 \\
        2   & 0.087 & 0.760 & 0.006 & 0.313 \\
        5   & 0.053 & 0.573 & 0.005 & 0.258 \\
        10  & 0.033 & 0.400 & 0.004 & 0.200 \\
        15  & 0.023 & 0.306 & 0.003 & 0.163 \\
        20  & 0.018 & 0.247 & 0.003 & 0.137 \\
        25  & 0.015 & 0.208 & 0.002 & 0.119 \\
        50  & 0.008 & 0.115 & 0.001 & 0.071 \\
        100 & 0.004 & 0.061 & 0.001 & 0.039 \\
        150 & 0.003 & 0.041 & \textless0.001 & 0.027 \\
        200 & 0.002 & 0.031 & \textless0.001 & 0.021 \\
        \hline
        374 & 0.001 & 0.017 & \textless0.001 & 0.011 \\
        \hline
        \end{tabular}

  \caption{Calculating the credible interval around a probability estimate}
  \label{box2}
\end{floatbox}


%DG: be careful : occurrence, not occurance on the figures
    \begin{figure}
      \caption{\textbf{A-B)} Most pairs of \emph{Salix} and gallers or gallers and natural enemies were never observed co-occurring despite the high levels of replication in our example dataset. For those pairs that were observed together at least once ($n_{ij}>0$), the number of observed co-occurrences was generally small (\textless10). Here we show a histogram of the number of pairs of species observed co-occurring at least once. 3986 \emph{Salix}-galler and 9794 galler-enemy pairs were never observed co-occurring: these pairs are omitted from the histogram. \textbf{C-D)} Most pairs of species that were observed at the same site were never observed interacting. Here we show a histogram of the number of observed interactions within pairs of co-occurring species. \textbf{E-F)} Here we show, for each species pair, the number of observed interactions plotted against the number of observed co-occurrences. \emph{Salix}-galler pairs either are never observed interacting or interact almost every time they co-occur, while galler-enemy pairs had more variable frequencies of interaction. In panels E and F the red, dashed line indicates a 1:1 relationship between interactions and co-occurrences.}
      \label{histograms}
      \includegraphics*[width=.8\textwidth]{figures/Salix_Galler_histogram.eps}
      \end{figure}

%DG: I really appreciate this figure, it makes the point so clear. 



% DG: it's bizarre to present here the outcome of the naive binomial formulation, while the reasoning is provided later. My solution is to move the following section on the binomial model along with the figure within a box. It's not central, but formalizes the problem. It would respect the order of appearance and better emphasize the bayes section.
% AC: I couldn't figure out how to put a figure inside a text box, so instead (following an e-mail suggestion) I moved the naive binomial outcome to the figure caption.

  \begin{figure}[h!]
    \caption{A simple example will illustrate the problem of imperfect detection of interactions (the full reasoning is provided below). Assume that we want to infer the probability of an interaction between two species, $i$ and $j$. Now assume that in reality, interaction between $i$ and $j$ is completely impossible (i.e. the true $\lambda=0$), but the observer does not know this and seeks to estimate this interaction probability ($\lambda$). The number of observed interactions will follow a binomial distribution, with number of interactions $k$ and number of observations $n$. Using this distribution, we can compute the credible interval of the estimated probability $\lambda$. Assuming no added detection error in observing the incidence of the interaction, a single observation of species co-occurrence will reveal very little regarding the probability of the interaction as the credible interval for a pair of species with one observation essentially spans from 0 to 1. Only with thirty observations will the upper limit of the credible interval be lowered to 0.1. Thus, adding more observations is certainly useful in controlling uncertainty, but the number of observations nonetheless needs to be very high. Here we show the upper bound (solid black line) of a 95\% Clopper-Pearson true credible interval for $\lambda$ when $k=0$ ($i$ and $j$ have not been observed interacting) for a variety of $n$ (observed co-occurences of $i$ and $j$). A threshold interaction probability of 0.1 is indicated by the dotted red line.    }
    \label{upper_limits}
    \includegraphics*[width=.8\textwidth]{figures/upper_limit_DG.eps}
  \end{figure}


%DG :  I think we should add the MLE estimate along with the binomial confidence interval on the figure in order to better illustrate the impact of the prior (obviously only for one N). You may draw it with a line to contrast with polygons.
% Done, think it works for all N

%DG: otherwise the difference between the two interaction types is very interesting and useful to show the effect of the priors. Bravo ! 
[[Update these two figs with Zillis data.]]
      \begin{figure}[ht]
        \caption{Using prior distribution based on the \emph{Salix}-galler and galler-natural enemy networks in~\citet{Barbour2016}, we can calculate posterior distributions for the probability of interaction ($\lambda$) between two species that have not yet been observed interacting. Here we show posterior distributions for each $\lambda$ in each network ranging from the prior distribution ($n=0$ observed co-occurrence) to the distribution obtained when the pair of species has been observed co-occurring 100 times. The distribution narrows and approaches zero as the sample size increases. Likewise, the maximum likelihood estimator for the mean probability of interaction (diamonds at top of each panel) approaches zero and the 95\% credible interval (lines at top of each panel) narrows as sample size increases. \textbf{A)} The posterior distributions for the \emph{Salix}-galler component are always wider and farther from zero than those for \textbf{B)} the galler-natural enemy component. This is likely because the prior distribution for the galler-natural enemy component of the network was both narrower and had a mean closer to that in the~\citet{Kopelke2017} data than did the \emph{Salix}-galler component.}
        \label{Salix_pdfs}
        \includegraphics*[width=.8\textwidth]{figures/Salix_Galler_pdfs_increasing_N_Zillis.eps}
        \end{figure}



      \begin{figure}[ht]
        \caption{The number of samples required to achieve a given level of confidence that an interaction probability $\lambda_{ij}$ is below a given threshold varies with both parameters. With a low threshold, our confidence that $\lambda_{ij}$ is below the threshold increases rapidly with repeated observation of co-occurrence without interaction. Here we show the cumulative density functions for threshold probabilities of 0.5 (solid line), 0.25 (dashed line), 0.1 (dash-dot line), and 0.05 (dotted line) as well as the points at which the cdf reaches 0.90 (orange square), 0.95 (red circle), and 0.975 (blue diamond) for each threshold value. The large ticks along the x-axis indicate the number of samples associated with each of these points. Note that the number of samples required to reach any given threshold is larger for \textbf{A)} the \emph{Salix}-galler network than for \textbf{B)} the galler-natural enemy network. In the galler-natural enemy network, the credible interval for a pair of species with no observed co-occurrances was 0.364. All pairs of species therefore have $\lambda$\textless0.5.}
        \label{Salix_cdfs}
        \includegraphics[width=.8\textwidth]{figures/Salix_Galler_samples_and_cdfs_Zillis.eps}

        \end{figure}


    % \begin{figure}[ht]
    % \caption{Here we show the mean connectance, links per resource (\emph{Salix} in the \emph{Salix}-galler networks and gallers in the galler-natural enemy networks), and links per consumer for networks assembled using posterior distributions based on a smaller, North American \emph{Salix}-galler-natural enemy system~\citep{Barbour2016,Barbour2016Dryad}. We created 100 ``posterior-sampling" networks and then, for each of these, created 100 ``detection-filter" networks by randomly sampling 50\%-99\% of the interactions included in the posterior-sampling network. This simulates imperfect detection of interactions in the field. Each point represents the mean network property (e.g., connectance) obtained from a set of 100 detection-filter networks, plotted against the value of the network property in the posterior-sampling network used to create the detection-filter networks. For each property and both network types, the posterior-sampling networks cover a relatively small range of network properties than the range covered by networks with varying detection probabilities. The value of each property decreases with the proportion of links included in the detection-filter networks.}
    % \label{posterior_webs}    
    % \includegraphics[width=.8\textwidth]{Figures/Salix_Galler_posterior_properties.eps}
    % \end{figure}

    \begin{figure}[ht]
    \caption{Here we show the mean connectance, links per resource (\emph{Salix} in the \emph{Salix}-galler networks and gallers in the galler-natural enemy networks), and links per consumer for networks assembled using posterior distributions based on a single subweb in the~\citet{Kopelke2017} dataset (Zillis). We created 100 ``posterior-sampling" networks and then, for each of these, created 100 ``detection-filter" networks by randomly sampling 50\%-99\% of the interactions included in the posterior-sampling network. This simulates imperfect detection of interactions in the field. Each point represents the mean network property (e.g., connectance) obtained from a set of 100 detection-filter networks, plotted against the value of the network property in the posterior-sampling network used to create the detection-filter networks. For each property and both network types, the posterior-sampling networks cover a relatively small range of network properties than the range covered by networks with varying detection probabilities. The value of each property decreases with the proportion of links included in the detection-filter networks.}
    \label{posterior_webs}    
    \includegraphics[width=.8\textwidth]{Figures/Salix_Galler_posterior_properties_Zillis.eps}
    \end{figure}

  % [[What if we have only one site? Can we use the number of observations of a pair of species interacting with any partners as the number of times they co-occur, and the number of interactions within the pair as k? This will be sort-of valid for insects but not for plants when researchers camp out by plant individuals... ]]


\clearpage

    \bibliographystyle{ecollett} 
    \bibliography{MyCollection} % Abbreviate journal titles.


\end{document}


